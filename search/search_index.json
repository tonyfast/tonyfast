{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Home","text":""},{"location":"index.html#i-about-tonyfast","title":"\u2139\ufe0f about tonyfast","text":"<p>tonyfast is a freelance developer, designer, and scientist with significant experience in open source and scientific software. he is a distinguished project jupyter contributor advocating for computational literacy, equity, and digital accessibility in scientific technologies.</p> <ul> <li>\ud83d\udcd3 notebooks</li> <li>\ud83d\udc80 deathbeds</li> <li>\ud83d\udcbb github</li> <li>\ud83d\udcbc linkedin </li> </ul>"},{"location":"index.html#current-projects","title":"\ud83d\udee0\ufe0f current projects","text":"<ul> <li>notebooks for all collaboration with Space Telescope Science Institute improving the accessibility of static notebooks through collaboration with designers and compensated disabled testers.</li> <li>project jupyter accessibility working group, jupyter triage, and jupyter community calls</li> <li>writing experiments with literate programs and computational essays on my blog.</li> <li><code>pidgy</code>, <code>midgy</code>, and <code>importnb</code></li> </ul> \u2795 more \u2753 about this repository"},{"location":"index.html#events-and-media","title":"\ud83d\udcbf events and media","text":"<ul> <li>writers workshop</li> <li>quirkshops</li> <li>open source directions</li> <li>jupyter accessibility workshops part 1</li> <li>alt text events</li> <li>scipy alt text scavenger hunt</li> <li>atlanta jupyter user group</li> <li>pydata atlanta</li> <li>deathbeds blog</li> <li>jupyter day triangle</li> <li>jupyter days atlanta 2016</li> </ul>"},{"location":"index.html#presentations","title":"\ud83d\udcfd\ufe0f presentations","text":"<ul> <li>ten pounds of \ud83d\udca9</li> <li>reincarnation of the notebook</li> <li>powers often</li> <li>ten things 'bout jupyter</li> <li>notebookism</li> <li>the materials data scientist</li> </ul>"},{"location":"index.html#organizations","title":"\ud83d\udc68\u200d\ud83c\udfed organizations","text":"<ul> <li>Quansight, LLC</li> <li>PyData Atlanta</li> <li>Bastille Networks</li> <li>Anaconda Inc</li> <li>Georgia Tech</li> <li>University of California Santa Barbara</li> </ul>"},{"location":"index.html#the-tonyfast-distribution","title":"the <code>tonyfast</code> distribution","text":"<p>this repository is one of github's special repositories for my personal profile. i wanted to do more with than just a readme so i'm using it as a place to package my computational essays or literate programs as a python distribution. </p> <p>currently this project features:</p> <ul> <li> blogs, essays, notebooks and markdown re-used as python source code</li> <li> <p> a python project called <code>tonyfast</code> that uses <code>hatch</code> for most development tasks (see <code>pyproject.toml</code>)</p> <pre><code>pip install -e. # for development mode\n</code></pre> </li> <li> <p> github actions to deploy my content on github pages. the documentation is made of:</p> </li> <li> <p> <code>mkdocs</code> documentation with my own notebook customizations. (see <code>mkdocs.yml</code>)</p> </li> <li> <p> a no-install, in-the-browser <code>jupyterlite</code> demo so myself and others can try out the code themselves</p> </li> <li> <p> some things i'd like to do:</p> </li> <li> <p> add cron for some posts</p> </li> <li> add tests for some posts</li> <li> build a solid binder to run heavier demos that might not work in <code>jupyterlite</code></li> </ul>"},{"location":"2023-02-05-pipings.html","title":"pipes are common sugar","text":"<p>the <code>|</code> is a common operator in programming languages. in pidgy, we find the <code>|</code> operator in <code>jijnja2</code> filters.</p> <p>here we adds pipes to markdown strings used in <code>pidgy</code>.</p>"},{"location":"2023-02-05-pipings.html#the-pipe-classes","title":"the <code>pipe</code> classes","text":"<p>make it possible chain markdown and python.</p> <pre><code>    class pipe(functools.partial):\n        def __or__(self, object):\n            if isinstance(object, str): return super().__call__(object)\n            if callable(object): return pipe(lambda x: object(super().__call__(x)))\n            raise NotImplementedError(F\"not implemented for {type(object)}\")\n\n        def __ror__(self, object):\n            if isinstance(object, str): return super().__call__(object)\n            if callable(object): return pipe(lambda x: super().__call__(object(x)))\n\n    class do(pipe):\n        def __call__(self, *args, **kwargs):\n            super().__call__(*args, **kwargs)\n            object, *_ = args + (None,)\n            return object\n</code></pre> <p><code>pipe</code> can used as a decorator</p> <pre><code>    @pipe\n    def strip_fence(body):\n        lines = body.splitlines(1)[1:]\n        if lines[-1].startswith((\"```\", \"~~~\")):\n            lines.pop()\n        return \"\".join(lines)\n</code></pre> <p>maybe we want a pipeable version of <code>print</code></p> <pre><code>    print = do(print)\n    print | \"asdf\"\n</code></pre> <pre><code>    x=(\n```test\ncrap\n```\n\n    )| strip_fence | do(print)\n</code></pre>"},{"location":"regexs.html","title":"regexes","text":"<pre><code>    import re\n</code></pre>"},{"location":"regexs.html#find-blocks-in-jinja-templates","title":"find blocks in jinja templates","text":"<p>used in xxii/2022-12-31-markdownish-notebook.ipynb</p> <pre><code>    jinja_block = re.compile(\n        \"\\\\s*\".join(\"(?P&lt;block&gt;\\\\{\\\\%-? block (?P&lt;name&gt;\\\\S+)(\\\\s+scoped)? -?\\\\%\\\\}(?P&lt;inner&gt;[\\\\S|\\r?\\n]*)\\\\{\\\\%-? endblock (?P=name) -?\\\\%\\\\})\".split()), re.MULTILINE\n    )\n</code></pre> <pre><code>\n</code></pre>"},{"location":"xxii/2022-11-12-async-import.html","title":"asynchronous imports in python","text":"<p>lets say we have a python module with a top level await statement. this is valid in javascript and ipython, but not python due to the ambiguity of the top level await. we'll start digging into what it takes to have async imports in python</p> <p>https://gist.github.com/Rich-Harris/0b6f317657f5167663b493c722647221</p> <p><code>dream</code> is a our <code>async</code> function and <code>catcher</code> is a value we have access to</p> <pre><code>    async def dream():\n        await __import__(\"asyncio\").sleep(1)\n        return \"dream on\"\n    print(catcher := await dream())\n</code></pre> <pre>dream on\n</pre> <p>by default, importing modules with top level await is a fail because <code>await</code> can't be outside a function.</p> <pre><code>    try: \n        with __import__(\"importnb\").Notebook(): import __\n    except SyntaxError as error: assert \"'await' outside function\" == error.args[0], error\n</code></pre> <pre><code>    # boiler plate\n    import importnb, ast; from IPython import get_ipython\n    shell = get_ipython(); \n</code></pre> <p>we're about to do some nasty nested <code>async</code> business when we are working interactively. below we ask <code>IPython</code> to prefer to the <code>trio</code> thread when we execute code cells this way we can own the <code>asyncio</code> event loop.</p> <pre><code>    if \"__file__\" not in locals(): \n        __import__('nest_asyncio').apply()\n        shell.loop_runner  =__import__(\"IPython\").core.async_helpers._trio_runner\n</code></pre> <p>luckily there is a flag for top level awaits  thanks to matthias and his hard work on <code>IPython</code>.</p> <p>https://docs.python.org/3/library/ast.html#ast.PyCF_ALLOW_TOP_LEVEL_AWAIT</p> <p>we'll make an importer that includes the <code>PyCF_ALLOW_TOP_LEVEL_AWAIT</code> flag and executes the module through an asynchronous version of <code>eval</code> </p> <pre><code>    class ANotebook(importnb.Notebook):\n        def exec_module(self, module):\n            code = self.get_code(self.name)\n            return __import__(\"asyncio\").run(eval(code, vars(module)))\n\n        def source_to_code(self, nodes, path, *, _optimize=-1):\n            if not isinstance(nodes, ast.Module):\n                nodes = self.parse(nodes)\n            return compile(self.visit(nodes), path, \"exec\", optimize=_optimize, flags=ast.PyCF_ALLOW_TOP_LEVEL_AWAIT)\n</code></pre> <pre><code>    with ANotebook(): import __11_12_async_import as anb\n    assert anb.catcher == \"dream on\"\n</code></pre> <pre>dream on\n</pre> <p>we haven't done anything fancy with asyncing the reading the and decoding of the source. we'll get there though. this is just opening the can of worms. the jokes should follow.</p> <pre><code>\n</code></pre>"},{"location":"xxii/2022-11-12-pluggy-experiments.html","title":"fumbling around with <code>pluggy</code>","text":"<p>https://pluggy.readthedocs.io/</p> <ul> <li>register/unregister plugins</li> <li>define specs and implementations at the same time.</li> </ul> <pre><code>    import pluggy\n</code></pre> <p>we're going to think about a sample <code>PROG</code>ram that has an interface.</p> <pre><code>    PROG = \"sample-program\"\n</code></pre> <p>the <code>specification</code> decorates the functions and signatures of our interface. the <code>implementation</code> uses the <code>specification</code> for consistency when it actually defines computational work.</p> <pre><code>    implementation, specification = pluggy.HookimplMarker(PROG), pluggy.HookspecMarker(PROG)\n</code></pre> <p><code>PROG</code>s <code>specification</code> for <code>my_plugin</code> provides a default interface.</p> <pre><code>    @implementation\n    @specification(firstresult=False)\n    def my_plugin(a, b, c): return \"\".join(map(str, (a,b,c)))\n</code></pre> <p>we register the <code>specifaction</code> onto a plugin <code>manager</code></p> <pre><code>    manager = pluggy.PluginManager(PROG)\n</code></pre> <p>our <code>specification</code> lives in the <code>import __main__</code> or <code>MAIN</code> namespace.</p> <pre><code>    manager.add_hookspecs(__main__ := __import__(__name__))\n    assert \"my_plugin\" in dir(manager.hook), \"the plugin is registered\"\n</code></pre> <p>now we can add our <code>implementation</code> of <code>my_plugin</code> in the <code>__main__</code> module</p> <pre><code>    manager.register(__main__);\n</code></pre> <p>now we can execute our <code>manager.hook.my_plugin</code> method</p> <pre><code>    manager.hook.my_plugin(a=10, b=20, c=30)\n</code></pre> <pre>['102030']</pre> <p>let's add another implementation. we can't name it <code>my_plugin</code> otherwise we'll lose the scope of our previous method.  here we name our method whatever we want and explicitly define the <code>implementation:specname</code> it refers to.</p> <pre><code>    @implementation(specname=\"my_plugin\")\n    def another_plugin(a, b): return (a, b)    \n</code></pre> <p>now seems like a good time test what <code>async</code> functions do</p> <pre><code>    @implementation(specname=\"my_plugin\", trylast=True)\n    async def async_my_plugin(a, b): return (a, b)    \n</code></pre> <p>reregistering the <code>__main__</code> gives an error because <code>pluggy</code> doesn't allow someone register the module twice</p> <pre><code>    try: manager.register(__main__); assert False, \"can't register the module twice\"\n    except ValueError: assert True\n</code></pre> <p>the proper registration requires we unregister the module first.</p> <pre><code>    manager.unregister(__main__)\n    manager.register(__main__);\n</code></pre> <p>now our invocation finds both implementations.</p> <pre><code>    (results := manager.hook.my_plugin(a=10, b=20, c=30))\n</code></pre> <pre>['102030', (10, 20), &lt;coroutine object async_my_plugin at 0x7feab0168040&gt;]</pre> <p><code>async_my_plugin</code> evaluates to a coroutine that we'd have to handle properly.</p> <pre><code>    assert __import__(\"inspect\").iscoroutine(results[-1])\n</code></pre>"},{"location":"xxii/2022-11-17-assignment-expression-display.html","title":"using assignment expressions to display and assign in <code>IPython</code>","text":"<p>not all notebok users are aware that there are different implicit display conditions that can be configured with <code>IPython</code> with the <code>ast_node_interactivity</code> option</p> <pre><code>    shell = get_ipython()\n</code></pre> <p>by default, <code>shell.ast_node_interactivity</code> displays the last expressions</p> <pre><code>    shell.ast_node_interactivity\n</code></pre> <pre>'last_expr'</pre> <p>the other 5 options follow the code below</p> <pre><code>    shell.traits()[\"ast_node_interactivity\"].values\n</code></pre> <pre>['all', 'last', 'last_expr', 'none', 'last_expr_or_assign']</pre> <p>sometimes when i am debugging i want to store a variable and display it at the same. the <code>IPython</code> approach set <code>shell.ast_node_interactivity = \"last_expr_or_assign\"</code>. admittedly, i never choose this because i don't want it all the time, just while debugging.</p> <p>what i do instead is set the variable and append an implicit display at the end.</p> <pre><code>    my_variable = 42; my_variable\n</code></pre> <pre>42</pre> <p>i've shifted from this approach to using assignment expressions with make more sense.</p> <pre><code>    (my_variable := 42)\n</code></pre> <pre>42</pre> <p>it feels lispy and i like it.</p> <pre><code>    (button := __import__(\"ipywidgets\").Button(description=\"a butt\"))\n</code></pre> <pre>Button(description='a butt', style=ButtonStyle())</pre>"},{"location":"xxii/2022-11-23-better-dask-shape.html","title":"unravel directories of notebooks with <code>dask</code>","text":"<p>this is another pass at using <code>dask</code> to load notebooks with the ultimate intent to search them. in searching-notebooks, i first approach this task with some keen <code>pandas</code> skills that we not so kind in the <code>dask</code> land. this document takes another pass at using clearer expressions to ravel a bunch of notebooks to <code>dask.dataframe</code></p> <p>taking care to load notebooks as <code>dask.dataframe</code>s offers the power to apply direct queries, export to parquet, export to sqlite, export to duckdb, arrow..</p> <pre><code>    import pandas, json, jsonpointer, orjson, dask.dataframe; from pathlib import Path\n    from toolz.curried import *\n    XXX = __name__ == \"__main__\" and \"__file__\" not in locals()\n</code></pre>"},{"location":"xxii/2022-11-23-better-dask-shape.html#if-you-know-the-shape-then-define-it","title":"if you know the shape then define it","text":"<p><code>dask</code> truly prefers explicit dtypes while <code>pandas</code> is more flexible. <code>meta</code> holds our shape information for the cells, outputs, and displays</p> <pre><code>    class meta: \n        O = \"object\"\n        ANY = None, O\n        NB = [(\"cells\", O), (\"metadata\", O), (\"nbformat\", int), (\"nbformat_minor\", int)]\n        CELL = [\n            (\"cell_type\", str), (\"execution_count\", int), (\"id\", str),\n            (\"metadata\", O), (\"outputs\", O), (\"source\", str), (\"cell_ct\", int),]\n        OUTPUT = [\n            (\"data\", O), (\"metadata\", O), (\"ename\", str), (\"evalue\", str),\n            (\"text\", str), (\"execution_count\", int), (\"output_type\", str), (\"output_ct\", int)]\n        DISPLAY = [(\"type\", str), (\"value\", str)]        \n        new_nb = pandas.Series(index=map(first, NB), dtype=\"O\")\n        new_cell = pandas.Series(index=map(first, CELL), dtype=\"O\")\n        new_output = pandas.Series(index=map(first, OUTPUT), dtype=\"O\")\n        new_display = pandas.Series(index=map(first, DISPLAY), dtype=\"O\")\n    def enumerate_list(x, key=\"cell_ct\"): return [{key: i, **y} for i, y in enumerate(x)]    \n\n    def get_series(data, key=\"text\", new=meta.new_output):\n        if key in data:\n            data[key] = \"\".join(data[key])\n        s = new.copy()\n        return s.update(data) or s\n</code></pre> <p>off to the races as we load some data from our local files.</p> <pre><code>    WHERE = Path(\"oct\")\n</code></pre> <p>the files we include start and remain our index. in prior iterations, there were a few set index operations, but we don't want to be opening files to do this cause that is costly. we'll store other metadata on the dataframe as we unpack the notebook shapes.</p> <pre><code>    def get_files(WHERE=WHERE):\n        return dask.bag.from_sequence(\n            dict(file=str(x)) for x in WHERE.glob(\"*.ipynb\")\n        ).to_dataframe().set_index(\"file\")\n    XXX and (files := get_files())\n</code></pre> Dask DataFrame Structure: npartitions=20 oct/2022-10-05-dask-search.ipynb oct/2022-10-06-github-open-source-stats.ipynb ... oct/2022-11-21-1.ipynb oct/test_nbconvert_html5.ipynb Dask Name: sort_index, 8 graph layers <p><code>contents</code> loads our files in to a dataframe containg real cell contents. each row is a file.</p> <pre><code>    def get_contents_from_files(files):\n        return  files.index.to_series().apply(\n            compose_left(Path, Path.read_text, orjson.loads, partial(\n                get_series, new=meta.new_nb)), meta=meta.NB)\n    XXX and (contents := get_contents_from_files(files))\n</code></pre> Dask DataFrame Structure: cells metadata nbformat nbformat_minor npartitions=20 oct/2022-10-05-dask-search.ipynb object object int64 int64 oct/2022-10-06-github-open-source-stats.ipynb ... ... ... ... ... ... ... ... ... oct/2022-11-21-1.ipynb ... ... ... ... oct/test_nbconvert_html5.ipynb ... ... ... ... Dask Name: apply, 11 graph layers <p>the <code>cells</code> are built by exploding the rows of the <code>contents</code></p> <pre><code>    def get_cells_from_contents(contents):\n        cells = contents.cells\n        cells = cells.apply(enumerate_list, meta=meta.ANY)\n        return cells.explode().apply(get_series, key=\"source\", new=meta.new_cell, meta=meta.CELL)\n    if XXX:\n        cells = get_cells_from_contents(contents)    \n        meta_cells = cells[\"metadata cell_ct\".split()]; cells.pop(\"metadata\"); display(cells)\n</code></pre> Dask DataFrame Structure: cell_type execution_count id outputs source cell_ct npartitions=20 oct/2022-10-05-dask-search.ipynb object int64 object object object int64 oct/2022-10-06-github-open-source-stats.ipynb ... ... ... ... ... ... ... ... ... ... ... ... ... oct/2022-11-21-1.ipynb ... ... ... ... ... ... oct/test_nbconvert_html5.ipynb ... ... ... ... ... ... Dask Name: drop_by_shallow_copy, 16 graph layers <p>new we deal will outputs that include display_data, stdout, and stderr.</p> <pre><code>    def get_outputs_from_cells(cells):\n        outputs = cells[\"outputs cell_ct\".split()].dropna(subset=\"outputs\")\n        outputs.outputs = outputs.outputs.apply(enumerate_list, key=\"output_ct\", meta=meta.ANY)\n        outputs = outputs.explode(\"outputs\").dropna(subset=\"outputs\")\n        return dask.dataframe.concat([\n            outputs.pop(\"outputs\").apply(get_series, key=\"text\", new=meta.new_output, meta=meta.OUTPUT),\n            outputs\n        ], axis=1)\n    if XXX:\n        outputs = get_outputs_from_cells(cells)\n        meta_display = outputs[\"metadata cell_ct output_ct\".split()]; outputs.pop(\"metadata\"); display(outputs)\n</code></pre> Dask DataFrame Structure: data ename evalue text execution_count output_type output_ct cell_ct npartitions=20 oct/2022-10-05-dask-search.ipynb object object object object int64 object int64 int64 oct/2022-10-06-github-open-source-stats.ipynb ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... oct/2022-11-21-1.ipynb ... ... ... ... ... ... ... ... oct/test_nbconvert_html5.ipynb ... ... ... ... ... ... ... ... Dask Name: drop_by_shallow_copy, 2 graph layers <p>separating the different standard out/error displays from the rich display data. there is probably more to for managing the different types of outputs from the different reprs.</p> <pre><code>    def get_display_data_from_outputs(outputs):\n        display_data = outputs[\"data execution_count output_type cell_ct output_ct\".split()].dropna(subset=\"data\")\n        display_data[\"data\"] = display_data[\"data\"].apply(compose_left(dict.items, list), meta=meta.ANY)\n        display_data = display_data.explode(\"data\").dropna(subset=\"data\")\n        return dask.dataframe.concat([\n            display_data.pop(\"data\").apply(\n                compose_left(\n                    partial(zip, meta.new_display.index), dict, \n                    partial(get_series, key=None, new=meta.new_display)\n                ), meta=meta.DISPLAY), display_data], axis=1)\n    XXX and (display_data := get_display_data_from_outputs(outputs)).compute()\n</code></pre> type value execution_count output_type cell_ct output_ct file oct/2022-10-05-dask-search.ipynb text/plain [\"the expected cell keys are ['attachments', '... 3.0 execute_result 7 0 oct/2022-10-05-dask-search.ipynb text/html [&lt;div&gt;&lt;strong&gt;Dask DataFrame Structure:&lt;/stron... NaN display_data 15 1 oct/2022-10-05-dask-search.ipynb text/plain [Dask DataFrame Structure:\\n,               at... NaN display_data 15 1 oct/2022-10-05-dask-search.ipynb text/html [&lt;div&gt;\\n, &lt;style scoped&gt;\\n,     .dataframe tbo... NaN display_data 17 0 oct/2022-10-05-dask-search.ipynb text/plain [path                                       ..... NaN display_data 17 0 ... ... ... ... ... ... ... oct/2022-11-21-1.ipynb application/vnd.jupyter.widget-view+json {'model_id': 'cd4f96b3078c4adf851d419b9c8e7885... NaN display_data 4 1 oct/2022-11-21-1.ipynb text/plain [HTML(value='&lt;pre&gt;&lt;code&gt;importlib._bootstrap_e... NaN display_data 4 1 oct/test_nbconvert_html5.ipynb text/plain [([], 1)] 4.0 execute_result 5 0 oct/test_nbconvert_html5.ipynb text/plain [([], 16)] 5.0 execute_result 7 0 oct/test_nbconvert_html5.ipynb text/plain [([], 5)] 6.0 execute_result 9 0 <p>173 rows \u00d7 6 columns</p>"},{"location":"xxii/2022-11-23-better-dask-shape.html#where-to-go-from","title":"where to go from","text":"<ul> <li>extend to other files. the notebook format is a hypermedia document format.</li> <li>save to different formats. initially we think about parquet, while in theory from this dataframe we could go further an imagine it being the seed for documentation.</li> </ul> <pre><code>    XXX and display(*(x.sample(frac=.1).compute().sample(5) for x in (cells, outputs, display_data)))\n</code></pre> cell_type execution_count id outputs source cell_ct file oct/2022-10-29-metadata-formatter.ipynb markdown NaN 50d9dcf9-18f4-4eb7-9a9a-cc3e14b3b2e2 NaN #### dataframes 16 oct/2022-10-06-github-open-source-stats.ipynb code 197.0 af8301f0-8a28-4350-87fa-a728867ccf67 [] %reload_ext doit 6 oct/2022-10-21-markdown-future.ipynb code 5.0 21fa2ad9-23f9-4868-9cb7-3bb87b69c542 [{'data': {'text/markdown': ['# tangle (code) ... # tangle (code) and weave (display)\\n\\n    kni... 7 oct/2022-10-19-mobius-text.ipynb code NaN 55228766-71c2-48f0-819f-afab637a4867 [] 18 oct/2022-10-27-axe-core-playwright-python.ipynb code 17.0 6e7cb333-6cc3-4c73-b256-382bcb3e9c2c [] async def injectAxe(page): \\n    await page.ev... 9 data ename evalue text execution_count output_type output_ct cell_ct file oct/2022-10-21-markdown-future.ipynb {'text/markdown': ['i'm not saying importing m... NaN NaN NaN NaN display_data 0 17 oct/2022-11-17--Copy1.ipynb {'application/vnd.jupyter.widget-view+json': {... NaN NaN NaN NaN display_data 0 6 oct/2022-10-21-markdown-future.ipynb {'text/markdown': ['```mermaid ', 'flowchart L... NaN NaN NaN NaN display_data 1 16 oct/2022-10-29-.ipynb NaN AttributeError 'dict' object has no attribute 'breaks' NaN NaN error 1 12 oct/2022-10-21-pidgy-displays.ipynb {'application/vnd.jupyter.widget-view+json': {... NaN NaN NaN NaN display_data 0 17 type value execution_count output_type cell_ct output_ct file oct/2022-10-05-dask-search.ipynb text/html [&lt;div&gt;\\n, &lt;style scoped&gt;\\n,     .dataframe tbo... NaN display_data 19 0 oct/2022-11-21-1.ipynb text/plain [HTML(value='&lt;pre&gt;&lt;code&gt;__&lt;/code&gt;&lt;/pre&gt;\\n')] NaN display_data 2 1 oct/2022-10-29-.ipynb application/vnd.jupyter.widget-view+json {'model_id': 'fa05bd5e43cc4785834b4b87ec154fbe... NaN display_data 11 0 oct/2022-11-17--Copy1.ipynb text/plain [HTML(value='&lt;pre&gt;&lt;code&gt;notebooks = pandas.con... NaN display_data 5 0 oct/2022-10-21-markdown-future.ipynb text/markdown [## literate computing with literary machines ... NaN display_data 5 0 <pre><code>    from dataclasses import dataclass, field\n    @dataclass\n    class Contents:\n        dir: Path = field(default_factory=Path.cwd)\n        contents: dask.dataframe.DataFrame = None\n\n        def __post_init__(self):\n            self.contents = get_contents_from_files(get_files(self.dir))\n            self.cells = get_cells_from_contents(self.contents)\n            self.outputs = get_outputs_from_cells(self.cells)\n            self.display_data = self.get_display_data_from_outputs(self.outputs)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"xxii/2022-11-26-package-mimic-and-rel-imports.html","title":"making <code>__main__</code> a <code>__package__</code>","text":"<p>to make an interactive computing session, or a python module generally, appear like a package we need to set two varaiables.</p> <pre><code>    import pytest; from pathlib import Path\n</code></pre> <p>there is a python file one directory up called <code>mkdocs.py</code>. we should be able to get at this file, and we will.</p> <p>our first transgression is not being a package.</p> <pre><code>    with pytest.raises(ImportError, match=\"attempted relative import with no known parent package\"):\n        from . import mkdocs\n</code></pre> <p>to be a package we need <code>__package__</code> and <code>__path__</code></p> <pre><code>    __package__, __path__ = __name__, [\"\"]\n</code></pre> <p>the <code>__path__</code> contains the lookup directories for parts of the package; this is a feature of namespace packages  AND where shit gets weird.</p> <p>now that we quack like a package we can attempt relative imports, but <code>mkdocs.py</code> is still out of reach.</p> <pre><code>    with pytest.raises(ImportError, match=\"cannot import name 'mkdocs' from '__main__' \\(unknown location\\)\"):\n        from . import mkdocs\n</code></pre> <p>append the parent to the <code>__path__</code></p> <pre><code>    __path__ += [\"..\"]\n</code></pre> <p>and boom!</p> <pre><code>    from . import mkdocs#!\n</code></pre>"},{"location":"xxii/2022-11-26-package-mimic-and-rel-imports.html#how-is-this-different-from-syspaths","title":"how is this different from <code>sys.paths</code>","text":"<p>it is probably not much different, but more a cheat code you can abuse at your own \u26a0</p>"},{"location":"xxii/2022-12-05-markdown-to-doctest.html","title":"formatting markdown it tokens as python <code>doctests</code>","text":"<p><code>midgy</code> is a tool i've been crafting that translates markdown to valid python. this concept might sound perculiar from a programming perspective, but it was designed as a [literate programming] tool.</p> <p>to avoid feature creep, <code>midgy</code> tries to stick fairly close to the commonspec when tokenizing markdown. <code>midgy</code> adds a doctest token to the parser. we make this addition because <code>doctest</code> is a [literate programming] considered in the core python language.</p> <p>in this document, we convert the <code>markdown_it</code> tokens into valid <code>doctest.DocTest</code> runners.</p> <pre><code>    import midgy, doctest, unittest, typing\n    from textwrap import dedent\n</code></pre> <p>write some sample doctests to parse</p> <pre><code>    def a_testable_function():\n\"\"\"\n        &gt;&gt;&gt; range(1)\n        range(0, 1)\n\n        &gt;&gt;&gt; assert False\n        Traceback (most recent call last):\n        ...\n        AssertionError\n        \"\"\"\n</code></pre> <p>verify that these tests pass. <code>doctest.testmod</code> runs <code>doctest</code> on the <code>__main__</code> module.</p> <pre><code>    doctest.testmod(optionflags=doctest.ELLIPSIS)\n</code></pre> <pre>TestResults(failed=0, attempted=2)</pre> <p>make some <code>markdown_it</code> tokens from the doctests.</p> <pre><code>    (tokens := (parser := midgy.Python()).parse(a_testable_function.__doc__))\n</code></pre> <pre>[Token(type='code_block', tag='code', nesting=0, attrs={}, map=[1, 3], level=0, children=None, content='    &gt;&gt;&gt; range(1)\\n    range(0, 1)\\n', markup='', info='', meta={'first_indent': 4, 'last_indent': 4, 'min_indent': 4, 'is_magic': False, 'is_doctest': True, 'input': [1, 2], 'output': [2, 3]}, block=True, hidden=False),\n Token(type='code_block', tag='code', nesting=0, attrs={}, map=[4, 8], level=0, children=None, content='    &gt;&gt;&gt; assert False\\n    Traceback (most recent call last):\\n    ...\\n    AssertionError\\n', markup='', info='', meta={'first_indent': 4, 'last_indent': 4, 'min_indent': 4, 'is_magic': False, 'is_doctest': True, 'input': [4, 5], 'output': [5, 8]}, block=True, hidden=False)]</pre> <p><code>get_example_from_token</code> translates a markdown token to a <code>doctest</code></p> <pre><code>    def get_example_from_token(token) -&gt; typing.Iterable[doctest.Example]:\n        m = doctest.DocTestParser._EXAMPLE_RE.match(token.content)\n        want = dedent(m.group(\"want\"))\n        exc = doctest.DocTestParser._EXCEPTION_RE.match(want)\n        source = \"\".join(x.lstrip()[4:] for x in m.group(\"source\").splitlines(1))\n        yield doctest.Example(\n            source=source, want=want, lineno=token.map[0],\n            exc_msg=exc.group(\"msg\") if exc else None, indent=len(m.group(\"indent\"))\n        )\n</code></pre> <p><code>get_examples_from_tokens</code> aggregates the <code>doctest.Example</code>s</p> <pre><code>    def get_examples_from_tokens(tokens) -&gt; typing.Iterable[doctest.Example]:\n        for token in tokens:\n            if token.meta.get(\"is_doctest\"):\n                yield from get_example_from_token(token)\n</code></pre> <p>finally we generate a <code>unittest.TestSuite</code></p> <pre><code>    def get_suite_from_tokens(tokens) -&gt; unittest.TestSuite:\n        suite = unittest.TestSuite()            \n        for example in get_examples_from_tokens(tokens):\n            suite.addTest(doctest.DocTestCase(\n                doctest.DocTest([example], globals(), __name__, None, example.lineno, None),\n                optionflags=doctest.ELLIPSIS\n            ))\n        return suite\n</code></pre> <pre><code>    def run_suite(suite=(suite:=get_suite_from_tokens(tokens))) -&gt; unittest.TestResult:\n        suite.run(result:= unittest.TestResult())\n        return result\n</code></pre> <p>run our generated <code>doctest</code> suite to verify that it doesn't fail.</p> <pre><code>    run_suite(suite)\n</code></pre> <pre>&lt;unittest.result.TestResult run=2 errors=0 failures=0&gt;</pre>"},{"location":"xxii/2022-12-09-pyproject-analysis.html","title":"exploring many <code>pyproject.toml configs</code>","text":"<p>i composed the following query using github's graphql explorer because it has completion which helps in the composition. i also refered to  GitHub GraphQL - Get files in a repository  for some ideas about how to compose my query.</p> <ul> <li>this work is my first time interacting with graphql for data analysis. i really preferred the iGraphQl experiences that provides completion otherwise i would have been totally lost.</li> <li>it uses <code>requests</code> to retreieve the results, and <code>requsts_cache</code> for caching.</li> <li>at the end, we start looking at some dataframes for our requests.</li> </ul> <pre><code>    from typing import *; from toolz.curried import *; import pandas, requests, tomli\n</code></pre> <pre><code>    pyproject_query = \"\"\"\n    {\n      search(type: REPOSITORY, query: \"install in:readme language:python stars:&gt;500\", first:100 %s) {\n        pageInfo {\n          hasNextPage endCursor\n        }\n        edges {  \n            node {\n            ... on Repository {\n              url \n              stargazerCount\n              object(expression:\"HEAD:pyproject.toml\") {\n                ... on Blob {\n                  text\n\n                }\n              }\n            }\n          }\n        }\n      }\n    }\"\"\"\n</code></pre> <p>the graqhql query i wanted retrieves the <code>pyproject.toml</code> from a bunch of python projects.  the initial goal of this query is to discover python projects and retrieve their <code>pyproject.toml</code> for comparison.</p> <p>we are looking for <code>pyproject.toml</code> which outlines strict metadata specifications. it would be cool to get a high level view of the python conventions popular projects are using.</p> <p>i'd love suggestions on a better query that finds more repositories with <code>pyproject.toml</code> files.</p>"},{"location":"xxii/2022-12-09-pyproject-analysis.html#paginating-the-requests-to-get-a-bunch-of-data","title":"paginating the requests to get a bunch of data","text":"<p><code>get_one_page</code> makes a <code>POST</code> the github graphql endpoint - https://api.github.com/graphql</p> <pre><code>    def get_one_page(query: str, prior: requests.Response=None, fill: str = \"\") -&gt; requests.Response: \n        if prior and prior.json()[\"data\"][\"search\"][\"pageInfo\"][\"hasNextPage\"]:\n            fill = \"\"\", after: \"%s\" \"\"\" % prior.json()[\"data\"][\"search\"][\"pageInfo\"][\"endCursor\"]\n        return requests.post(\"https://api.github.com/graphql\", json=dict(query=query % fill), **header)\n</code></pre> <p><code>get_pages</code> yields multiple requests if there is pagination the nodes exported.</p> <pre><code>    def get_pages(query: str, prior=None, max=15):\n        for i in range(max):\n            prior = get_one_page(query, prior=prior)\n            yield prior\n            if prior.status_code != 200: break\n            if not prior.json()[\"data\"][\"search\"][\"pageInfo\"][\"hasNextPage\"]: break\n</code></pre> <p><code>gather</code> a few pages into a <code>list</code> of responses</p> <pre><code>    def gather(query: str, max: int=2): return list(get_pages(query, max=max))\n</code></pre>"},{"location":"xxii/2022-12-09-pyproject-analysis.html#analyze-some-actual-data","title":"analyze some actual data","text":"<p>boilerplate to begin the analysis</p> <pre><code>    __import__(\"requests_cache\").install_cache(allowable_methods=['GET', 'POST'])\n    from info import header # this has some api info \n    pandas.options.display.max_colwidth = None\n    \u00d8 = __name__ == \"__main__\" and \"__file__\" not in locals()\n</code></pre> <p>transform the responses in a big <code>pandas</code> dataframe of <code>configs</code></p> <p><code>tidy_responses</code> transforms our query responses into a single dataframe.</p> <pre><code>    def tidy_responses(responses: list[requests.Response]) -&gt; pandas.DataFrame:\n        return pipe(responses, map(\n            compose_left(operator.methodcaller(\"json\"), get(\"data\"), get(\"search\"), get(\"edges\"), pandas.DataFrame)\n        ), partial(pandas.concat, axis=1)).stack()\n</code></pre> <p><code>tidy_configs</code> further shapes the data down to the <code>pyproject.toml</code> data</p> <pre><code>    def tidy_configs(df: pandas.DataFrame) -&gt; pandas.DataFrame:\n        return df.apply(pandas.Series).dropna(subset=\"object\")\\\n        .set_index(\"url\")[\"object\"].apply(pandas.Series)[\"text\"].apply(tomli.loads).apply(pandas.Series)\n</code></pre> <pre><code>    if \u00d8:\n        configs = tidy_configs(df := tidy_responses(responses := gather(pyproject_query, max=15)))\n        print(F\"\"\"we made {len(responses)} requests returning information about a {len(df)} repositories.\n    we retrieved {len(configs)} pyproject configs from this scrape.\"\"\")\n</code></pre> <pre>we made 10 requests returning information about a 1000 repositories.\nwe retrieved 234 pyproject configs from this scrape.\n</pre>"},{"location":"xxii/2022-12-09-pyproject-analysis.html#inspecting-the-build-backend","title":"inspecting the build backend","text":"<pre><code>    if \u00d8:\n        builds = configs[\"build-system\"].dropna().apply(pandas.Series)\n        print(F\"\"\"{len(builds)} projects define a build backends, their specific frequencies are:\"\"\")\n        display(builds[\"build-backend\"].dropna().value_counts().to_frame(\"build-backend\").T)\n</code></pre> <pre>173 projects define a build backends, their specific frequencies are:\n</pre> setuptools.build_meta poetry.core.masonry.api hatchling.build flit_core.buildapi poetry.masonry.api pdm.pep517.api mesonpy poetry_dynamic_versioning.backend build-backend 88 25 15 8 4 2 1 1"},{"location":"xxii/2022-12-09-pyproject-analysis.html#inspecting-the-tools","title":"inspecting the tools","text":"<p>the different tool frequencies</p> <pre><code>    if \u00d8:\n        ranks = configs[\"tool\"].dropna().apply(list).apply(pandas.Series).stack().value_counts()\n        display(ranks[(top := ranks&gt;4)].to_frame(\"top\").T,  ranks[~top].to_frame(\"rest\").T)\n</code></pre> black isort pytest mypy coverage poetry setuptools_scm hatch setuptools pylint towncrier pyright cibuildwheel usort flit top 123 85 67 42 34 32 21 15 14 14 11 10 6 5 5 nbqa flake8 tox ruff pycln pydocstyle autoflake interrogate tbump codespell ... versioningit poe distutils setuptools-git-versioning ufmt hooky bandit versioneer mutmut typeshed rest 4 3 3 3 3 3 2 2 2 2 ... 1 1 1 1 1 1 1 1 1 1 <p>1 rows \u00d7 39 columns</p>"},{"location":"xxii/2022-12-09-pyproject-analysis.html#fin","title":"fin","text":"<p>i think having knowledge at this scope of projects helps making decisions about what to do with your own. if <code>black</code> is the zeigeist why are you stalling?</p>"},{"location":"xxii/2022-12-13-github-api-stats.html","title":"extracting info from the github statistics api","text":"<p>i've wanted to take looks at github repositories over time. what kind of trends are there revealed over the years of projects? what can we infer from past actions that might predicate success?</p> <p>this work is an extension of the <code>pyproject.toml</code> analysis. we use the same list of respositories to generate their statistics.</p> <p><code>doit</code> is likely a suboptimal choice for this, so we'll probably want to try <code>dask</code> later.</p> <pre><code>    with __import__(\"importnb\").Notebook():\n        import __12_09_pyproject_analysis as prior\n    import pandas\n</code></pre> <pre><code>    df = prior.tidy_responses(responses := prior.gather(prior.pyproject_query)).apply(pandas.Series)\n</code></pre> <pre><code>    projects = df.url.str.rsplit(\"/\", 2, expand=True)[[1,2]].apply(\"/\".join, axis=1)\n</code></pre> <pre><code>    from info import header\n    import requests, requests_cache, uritemplate, toolz, operator, doit\n    requests_cache.install_cache()\n    from info import header\n</code></pre> <p>the endpoints we retrieve the stats from</p> <pre><code>    GH = \"https://api.github.com\"\n    STATS = \"code_frequency commit_activity participation\".split()\n    URI = uritemplate.URITemplate(GH + \"/repos/{owner}/{repo}/stats/{stat}\")    \n    RELEASES = uritemplate.URITemplate(GH + \"/repos/{owner}/{repo}/releases\")\n</code></pre> <p><code>get_stats</code> is a function that tries again when a <code>202</code> status is returned.</p> <pre><code>    def get_stats(url):\n        response = requests.get(url, **header)\n        if response.status_code == 202:\n            __import__(\"time\").sleep(1)\n            return get_stats(url)\n        return response.json()\n</code></pre> <pre><code>    @doit.task_params([dict(name=\"project\", type=list, long=\"project\", default=[])])\n    def task_collect_stats(project=projects):\n        for url, owner, repo in get_iterables(project):\n            *_, stat = url.rpartition(\"/\")\n            yield dict(name=\"-\".join((owner, repo, stat)),actions=[(toolz.curried.do(get_stats), [url])])\n</code></pre> <pre><code>    def get_iterables(projects=projects):\n        for owner, repo in (x.split(\"/\") for x in projects):\n            for stat in STATS: yield URI.expand(locals()), owner, repo\n            yield RELEASES.expand(locals()), owner, repo\n</code></pre>"},{"location":"xxii/2022-12-13-github-api-stats.html#retrieve-the-data-with-doit","title":"retrieve the data with <code>doit</code>","text":"<pre><code>    %reload_ext doit\n</code></pre> <pre><code>    projects_args = \" \".join(projects.apply(\"--project %s\".__mod__))\n</code></pre> <pre><code>    %doit run collect_stats $projects_args\n</code></pre> <pre>.  collect_stats:tensorflow-models-code_frequency\n.  collect_stats:tensorflow-models-commit_activity\n.  collect_stats:tensorflow-models-participation\n.  collect_stats:tensorflow-models-releases\n.  collect_stats:mongodb-mongo-python-driver-code_frequency\n.  collect_stats:mongodb-mongo-python-driver-commit_activity\n.  collect_stats:mongodb-mongo-python-driver-participation\n.  collect_stats:mongodb-mongo-python-driver-releases\n.  collect_stats:3b1b-manim-code_frequency\n.  collect_stats:3b1b-manim-commit_activity\n.  collect_stats:3b1b-manim-participation\n.  collect_stats:3b1b-manim-releases\n.  collect_stats:alievk-avatarify-python-code_frequency\n.  collect_stats:alievk-avatarify-python-commit_activity\n.  collect_stats:alievk-avatarify-python-participation\n.  collect_stats:alievk-avatarify-python-releases\n.  collect_stats:python-cpython-code_frequency\n.  collect_stats:python-cpython-commit_activity\n.  collect_stats:python-cpython-participation\n.  collect_stats:python-cpython-releases\n.  collect_stats:ehmatthes-pcc-code_frequency\n.  collect_stats:ehmatthes-pcc-commit_activity\n.  collect_stats:ehmatthes-pcc-participation\n.  collect_stats:ehmatthes-pcc-releases\n.  collect_stats:openai-gym-code_frequency\n.  collect_stats:openai-gym-commit_activity\n.  collect_stats:openai-gym-participation\n.  collect_stats:openai-gym-releases\n.  collect_stats:openai-DALL-E-code_frequency\n.  collect_stats:openai-DALL-E-commit_activity\n.  collect_stats:openai-DALL-E-participation\n.  collect_stats:openai-DALL-E-releases\n.  collect_stats:tweepy-tweepy-code_frequency\n.  collect_stats:tweepy-tweepy-commit_activity\n.  collect_stats:tweepy-tweepy-participation\n.  collect_stats:tweepy-tweepy-releases\n.  collect_stats:google-research-football-code_frequency\n.  collect_stats:google-research-football-commit_activity\n.  collect_stats:google-research-football-participation\n.  collect_stats:google-research-football-releases\n.  collect_stats:pandas-dev-pandas-code_frequency\n.  collect_stats:pandas-dev-pandas-commit_activity\n.  collect_stats:pandas-dev-pandas-participation\n.  collect_stats:pandas-dev-pandas-releases\n.  collect_stats:cupy-cupy-code_frequency\n.  collect_stats:cupy-cupy-commit_activity\n.  collect_stats:cupy-cupy-participation\n.  collect_stats:cupy-cupy-releases\n.  collect_stats:explosion-spaCy-code_frequency\n.  collect_stats:explosion-spaCy-commit_activity\n.  collect_stats:explosion-spaCy-participation\n.  collect_stats:explosion-spaCy-releases\n.  collect_stats:biopython-biopython-code_frequency\n.  collect_stats:biopython-biopython-commit_activity\n.  collect_stats:biopython-biopython-participation\n.  collect_stats:biopython-biopython-releases\n.  collect_stats:shengqiangzhang-examples-of-web-crawlers-code_frequency\n.  collect_stats:shengqiangzhang-examples-of-web-crawlers-commit_activity\n.  collect_stats:shengqiangzhang-examples-of-web-crawlers-participation\n.  collect_stats:shengqiangzhang-examples-of-web-crawlers-releases\n.  collect_stats:sshwsfc-xadmin-code_frequency\n.  collect_stats:sshwsfc-xadmin-commit_activity\n.  collect_stats:sshwsfc-xadmin-participation\n.  collect_stats:sshwsfc-xadmin-releases\n.  collect_stats:facebook-prophet-code_frequency\n.  collect_stats:facebook-prophet-commit_activity\n.  collect_stats:facebook-prophet-participation\n.  collect_stats:facebook-prophet-releases\n.  collect_stats:fogleman-Minecraft-code_frequency\n.  collect_stats:fogleman-Minecraft-commit_activity\n.  collect_stats:fogleman-Minecraft-participation\n.  collect_stats:fogleman-Minecraft-releases\n.  collect_stats:magenta-magenta-code_frequency\n.  collect_stats:magenta-magenta-commit_activity\n.  collect_stats:magenta-magenta-participation\n.  collect_stats:magenta-magenta-releases\n.  collect_stats:AUTOMATIC1111-stable-diffusion-webui-code_frequency\n.  collect_stats:AUTOMATIC1111-stable-diffusion-webui-commit_activity\n.  collect_stats:AUTOMATIC1111-stable-diffusion-webui-participation\n.  collect_stats:AUTOMATIC1111-stable-diffusion-webui-releases\n.  collect_stats:python-telegram-bot-python-telegram-bot-code_frequency\n.  collect_stats:python-telegram-bot-python-telegram-bot-commit_activity\n.  collect_stats:python-telegram-bot-python-telegram-bot-participation\n.  collect_stats:python-telegram-bot-python-telegram-bot-releases\n.  collect_stats:dbcli-mycli-code_frequency\n.  collect_stats:dbcli-mycli-commit_activity\n.  collect_stats:dbcli-mycli-participation\n.  collect_stats:dbcli-mycli-releases\n.  collect_stats:ageitgey-face_recognition-code_frequency\n.  collect_stats:ageitgey-face_recognition-commit_activity\n.  collect_stats:ageitgey-face_recognition-participation\n.  collect_stats:ageitgey-face_recognition-releases\n.  collect_stats:pydantic-pydantic-code_frequency\n.  collect_stats:pydantic-pydantic-commit_activity\n.  collect_stats:pydantic-pydantic-participation\n.  collect_stats:pydantic-pydantic-releases\n.  collect_stats:plotly-plotly.py-code_frequency\n.  collect_stats:plotly-plotly.py-commit_activity\n.  collect_stats:plotly-plotly.py-participation\n.  collect_stats:plotly-plotly.py-releases\n.  collect_stats:p2pool-p2pool-code_frequency\n.  collect_stats:p2pool-p2pool-commit_activity\n.  collect_stats:p2pool-p2pool-participation\n.  collect_stats:p2pool-p2pool-releases\n.  collect_stats:pypa-pipenv-code_frequency\n.  collect_stats:pypa-pipenv-commit_activity\n.  collect_stats:pypa-pipenv-participation\n.  collect_stats:pypa-pipenv-releases\n.  collect_stats:psf-requests-code_frequency\n.  collect_stats:psf-requests-commit_activity\n.  collect_stats:psf-requests-participation\n.  collect_stats:psf-requests-releases\n.  collect_stats:ipython-ipython-code_frequency\n.  collect_stats:ipython-ipython-commit_activity\n.  collect_stats:ipython-ipython-participation\n.  collect_stats:ipython-ipython-releases\n.  collect_stats:amdegroot-ssd.pytorch-code_frequency\n.  collect_stats:amdegroot-ssd.pytorch-commit_activity\n.  collect_stats:amdegroot-ssd.pytorch-participation\n.  collect_stats:amdegroot-ssd.pytorch-releases\n.  collect_stats:apachecn-ailearning-code_frequency\n.  collect_stats:apachecn-ailearning-commit_activity\n.  collect_stats:apachecn-ailearning-participation\n.  collect_stats:apachecn-ailearning-releases\n.  collect_stats:scikit-learn-scikit-learn-code_frequency\n.  collect_stats:scikit-learn-scikit-learn-commit_activity\n.  collect_stats:scikit-learn-scikit-learn-participation\n.  collect_stats:scikit-learn-scikit-learn-releases\n.  collect_stats:pytorch-vision-code_frequency\n.  collect_stats:pytorch-vision-commit_activity\n.  collect_stats:pytorch-vision-participation\n.  collect_stats:pytorch-vision-releases\n.  collect_stats:sympy-sympy-code_frequency\n.  collect_stats:sympy-sympy-commit_activity\n.  collect_stats:sympy-sympy-participation\n.  collect_stats:sympy-sympy-releases\n.  collect_stats:onnx-onnx-code_frequency\n.  collect_stats:onnx-onnx-commit_activity\n.  collect_stats:onnx-onnx-participation\n.  collect_stats:onnx-onnx-releases\n.  collect_stats:Netflix-metaflow-code_frequency\n.  collect_stats:Netflix-metaflow-commit_activity\n.  collect_stats:Netflix-metaflow-participation\n.  collect_stats:Netflix-metaflow-releases\n.  collect_stats:heartexlabs-labelImg-code_frequency\n.  collect_stats:heartexlabs-labelImg-commit_activity\n.  collect_stats:heartexlabs-labelImg-participation\n.  collect_stats:heartexlabs-labelImg-releases\n.  collect_stats:OctoPrint-OctoPrint-code_frequency\n.  collect_stats:OctoPrint-OctoPrint-commit_activity\n.  collect_stats:OctoPrint-OctoPrint-participation\n.  collect_stats:OctoPrint-OctoPrint-releases\n.  collect_stats:wkentaro-labelme-code_frequency\n.  collect_stats:wkentaro-labelme-commit_activity\n.  collect_stats:wkentaro-labelme-participation\n.  collect_stats:wkentaro-labelme-releases\n.  collect_stats:fail2ban-fail2ban-code_frequency\n.  collect_stats:fail2ban-fail2ban-commit_activity\n.  collect_stats:fail2ban-fail2ban-participation\n.  collect_stats:fail2ban-fail2ban-releases\n.  collect_stats:Rapptz-discord.py-code_frequency\n.  collect_stats:Rapptz-discord.py-commit_activity\n.  collect_stats:Rapptz-discord.py-participation\n.  collect_stats:Rapptz-discord.py-releases\n.  collect_stats:guohongze-adminset-code_frequency\n.  collect_stats:guohongze-adminset-commit_activity\n.  collect_stats:guohongze-adminset-participation\n.  collect_stats:guohongze-adminset-releases\n.  collect_stats:threat9-routersploit-code_frequency\n.  collect_stats:threat9-routersploit-commit_activity\n.  collect_stats:threat9-routersploit-participation\n.  collect_stats:threat9-routersploit-releases\n.  collect_stats:ddbourgin-numpy-ml-code_frequency\n.  collect_stats:ddbourgin-numpy-ml-commit_activity\n.  collect_stats:ddbourgin-numpy-ml-participation\n.  collect_stats:ddbourgin-numpy-ml-releases\n.  collect_stats:pallets-flask-code_frequency\n.  collect_stats:pallets-flask-commit_activity\n.  collect_stats:pallets-flask-participation\n.  collect_stats:pallets-flask-releases\n.  collect_stats:modin-project-modin-code_frequency\n.  collect_stats:modin-project-modin-commit_activity\n.  collect_stats:modin-project-modin-participation\n.  collect_stats:modin-project-modin-releases\n.  collect_stats:spesmilo-electrum-code_frequency\n.  collect_stats:spesmilo-electrum-commit_activity\n.  collect_stats:spesmilo-electrum-participation\n.  collect_stats:spesmilo-electrum-releases\n.  collect_stats:iterative-dvc-code_frequency\n.  collect_stats:iterative-dvc-commit_activity\n.  collect_stats:iterative-dvc-participation\n.  collect_stats:iterative-dvc-releases\n.  collect_stats:tgalal-yowsup-code_frequency\n.  collect_stats:tgalal-yowsup-commit_activity\n.  collect_stats:tgalal-yowsup-participation\n.  collect_stats:tgalal-yowsup-releases\n.  collect_stats:Azure-azure-cli-code_frequency\n.  collect_stats:Azure-azure-cli-commit_activity\n.  collect_stats:Azure-azure-cli-participation\n.  collect_stats:Azure-azure-cli-releases\n.  collect_stats:shadowsocksr-backup-shadowsocksr-code_frequency\n.  collect_stats:shadowsocksr-backup-shadowsocksr-commit_activity\n.  collect_stats:shadowsocksr-backup-shadowsocksr-participation\n.  collect_stats:shadowsocksr-backup-shadowsocksr-releases\n.  collect_stats:ranger-ranger-code_frequency\n.  collect_stats:ranger-ranger-commit_activity\n.  collect_stats:ranger-ranger-participation\n.  collect_stats:ranger-ranger-releases\n.  collect_stats:localstack-localstack-code_frequency\n.  collect_stats:localstack-localstack-commit_activity\n.  collect_stats:localstack-localstack-participation\n.  collect_stats:localstack-localstack-releases\n.  collect_stats:MatrixTM-MHDDoS-code_frequency\n.  collect_stats:MatrixTM-MHDDoS-commit_activity\n.  collect_stats:MatrixTM-MHDDoS-participation\n.  collect_stats:MatrixTM-MHDDoS-releases\n.  collect_stats:soimort-you-get-code_frequency\n.  collect_stats:soimort-you-get-commit_activity\n.  collect_stats:soimort-you-get-participation\n.  collect_stats:soimort-you-get-releases\n.  collect_stats:Gameye98-Lazymux-code_frequency\n.  collect_stats:Gameye98-Lazymux-commit_activity\n.  collect_stats:Gameye98-Lazymux-participation\n.  collect_stats:Gameye98-Lazymux-releases\n.  collect_stats:allenai-allennlp-code_frequency\n.  collect_stats:allenai-allennlp-commit_activity\n.  collect_stats:allenai-allennlp-participation\n.  collect_stats:allenai-allennlp-releases\n.  collect_stats:CorentinJ-Real-Time-Voice-Cloning-code_frequency\n.  collect_stats:CorentinJ-Real-Time-Voice-Cloning-commit_activity\n.  collect_stats:CorentinJ-Real-Time-Voice-Cloning-participation\n.  collect_stats:CorentinJ-Real-Time-Voice-Cloning-releases\n.  collect_stats:RasaHQ-rasa-code_frequency\n.  collect_stats:RasaHQ-rasa-commit_activity\n.  collect_stats:RasaHQ-rasa-participation\n.  collect_stats:RasaHQ-rasa-releases\n.  collect_stats:websocket-client-websocket-client-code_frequency\n.  collect_stats:websocket-client-websocket-client-commit_activity\n.  collect_stats:websocket-client-websocket-client-participation\n.  collect_stats:websocket-client-websocket-client-releases\n.  collect_stats:scrapy-scrapy-code_frequency\n.  collect_stats:scrapy-scrapy-commit_activity\n.  collect_stats:scrapy-scrapy-participation\n.  collect_stats:scrapy-scrapy-releases\n.  collect_stats:eriklindernoren-PyTorch-YOLOv3-code_frequency\n.  collect_stats:eriklindernoren-PyTorch-YOLOv3-commit_activity\n.  collect_stats:eriklindernoren-PyTorch-YOLOv3-participation\n.  collect_stats:eriklindernoren-PyTorch-YOLOv3-releases\n.  collect_stats:trustedsec-social-engineer-toolkit-code_frequency\n.  collect_stats:trustedsec-social-engineer-toolkit-commit_activity\n.  collect_stats:trustedsec-social-engineer-toolkit-participation\n.  collect_stats:trustedsec-social-engineer-toolkit-releases\n.  collect_stats:zalando-patroni-code_frequency\n.  collect_stats:zalando-patroni-commit_activity\n.  collect_stats:zalando-patroni-participation\n.  collect_stats:zalando-patroni-releases\n.  collect_stats:aboul3la-Sublist3r-code_frequency\n.  collect_stats:aboul3la-Sublist3r-commit_activity\n.  collect_stats:aboul3la-Sublist3r-participation\n.  collect_stats:aboul3la-Sublist3r-releases\n.  collect_stats:lra-mackup-code_frequency\n.  collect_stats:lra-mackup-commit_activity\n.  collect_stats:lra-mackup-participation\n.  collect_stats:lra-mackup-releases\n.  collect_stats:MrS0m30n3-youtube-dl-gui-code_frequency\n.  collect_stats:MrS0m30n3-youtube-dl-gui-commit_activity\n.  collect_stats:MrS0m30n3-youtube-dl-gui-participation\n.  collect_stats:MrS0m30n3-youtube-dl-gui-releases\n.  collect_stats:Bitwise-01-Instagram--code_frequency\n.  collect_stats:Bitwise-01-Instagram--commit_activity\n.  collect_stats:Bitwise-01-Instagram--participation\n.  collect_stats:Bitwise-01-Instagram--releases\n.  collect_stats:bokeh-bokeh-code_frequency\n.  collect_stats:bokeh-bokeh-commit_activity\n.  collect_stats:bokeh-bokeh-participation\n.  collect_stats:bokeh-bokeh-releases\n.  collect_stats:quantopian-zipline-code_frequency\n.  collect_stats:quantopian-zipline-commit_activity\n.  collect_stats:quantopian-zipline-participation\n.  collect_stats:quantopian-zipline-releases\n.  collect_stats:jupyter-jupyter-code_frequency\n.  collect_stats:jupyter-jupyter-commit_activity\n.  collect_stats:jupyter-jupyter-participation\n.  collect_stats:jupyter-jupyter-releases\n.  collect_stats:dbcli-pgcli-code_frequency\n.  collect_stats:dbcli-pgcli-commit_activity\n.  collect_stats:dbcli-pgcli-participation\n.  collect_stats:dbcli-pgcli-releases\n.  collect_stats:aws-aws-cli-code_frequency\n.  collect_stats:aws-aws-cli-commit_activity\n.  collect_stats:aws-aws-cli-participation\n.  collect_stats:aws-aws-cli-releases\n.  collect_stats:ocrmypdf-OCRmyPDF-code_frequency\n.  collect_stats:ocrmypdf-OCRmyPDF-commit_activity\n.  collect_stats:ocrmypdf-OCRmyPDF-participation\n.  collect_stats:ocrmypdf-OCRmyPDF-releases\n.  collect_stats:apache-airflow-code_frequency\n.  collect_stats:apache-airflow-commit_activity\n.  collect_stats:apache-airflow-participation\n.  collect_stats:apache-airflow-releases\n.  collect_stats:encode-uvicorn-code_frequency\n.  collect_stats:encode-uvicorn-commit_activity\n.  collect_stats:encode-uvicorn-participation\n.  collect_stats:encode-uvicorn-releases\n.  collect_stats:mwaskom-seaborn-code_frequency\n.  collect_stats:mwaskom-seaborn-commit_activity\n.  collect_stats:mwaskom-seaborn-participation\n.  collect_stats:mwaskom-seaborn-releases\n.  collect_stats:NVIDIA-apex-code_frequency\n.  collect_stats:NVIDIA-apex-commit_activity\n.  collect_stats:NVIDIA-apex-participation\n.  collect_stats:NVIDIA-apex-releases\n.  collect_stats:numenta-nupic-code_frequency\n.  collect_stats:numenta-nupic-commit_activity\n.  collect_stats:numenta-nupic-participation\n.  collect_stats:numenta-nupic-releases\n.  collect_stats:wiseodd-generative-models-code_frequency\n.  collect_stats:wiseodd-generative-models-commit_activity\n.  collect_stats:wiseodd-generative-models-participation\n.  collect_stats:wiseodd-generative-models-releases\n.  collect_stats:TeamUltroid-Ultroid-code_frequency\n.  collect_stats:TeamUltroid-Ultroid-commit_activity\n.  collect_stats:TeamUltroid-Ultroid-participation\n.  collect_stats:TeamUltroid-Ultroid-releases\n.  collect_stats:deeppavlov-DeepPavlov-code_frequency\n.  collect_stats:deeppavlov-DeepPavlov-commit_activity\n.  collect_stats:deeppavlov-DeepPavlov-participation\n.  collect_stats:deeppavlov-DeepPavlov-releases\n.  collect_stats:openai-baselines-code_frequency\n.  collect_stats:openai-baselines-commit_activity\n.  collect_stats:openai-baselines-participation\n.  collect_stats:openai-baselines-releases\n.  collect_stats:lyst-lightfm-code_frequency\n.  collect_stats:lyst-lightfm-commit_activity\n.  collect_stats:lyst-lightfm-participation\n.  collect_stats:lyst-lightfm-releases\n.  collect_stats:deezer-spleeter-code_frequency\n.  collect_stats:deezer-spleeter-commit_activity\n.  collect_stats:deezer-spleeter-participation\n.  collect_stats:deezer-spleeter-releases\n.  collect_stats:babysor-MockingBird-code_frequency\n.  collect_stats:babysor-MockingBird-commit_activity\n.  collect_stats:babysor-MockingBird-participation\n.  collect_stats:babysor-MockingBird-releases\n.  collect_stats:tensorlayer-TensorLayer-code_frequency\n.  collect_stats:tensorlayer-TensorLayer-commit_activity\n.  collect_stats:tensorlayer-TensorLayer-participation\n.  collect_stats:tensorlayer-TensorLayer-releases\n.  collect_stats:flask-admin-flask-admin-code_frequency\n.  collect_stats:flask-admin-flask-admin-commit_activity\n.  collect_stats:flask-admin-flask-admin-participation\n.  collect_stats:flask-admin-flask-admin-releases\n.  collect_stats:codelucas-newspaper-code_frequency\n.  collect_stats:codelucas-newspaper-commit_activity\n.  collect_stats:codelucas-newspaper-participation\n.  collect_stats:codelucas-newspaper-releases\n.  collect_stats:dmlc-gluon-nlp-code_frequency\n.  collect_stats:dmlc-gluon-nlp-commit_activity\n.  collect_stats:dmlc-gluon-nlp-participation\n.  collect_stats:dmlc-gluon-nlp-releases\n.  collect_stats:python-poetry-poetry-code_frequency\n.  collect_stats:python-poetry-poetry-commit_activity\n.  collect_stats:python-poetry-poetry-participation\n.  collect_stats:python-poetry-poetry-releases\n.  collect_stats:darknessomi-musicbox-code_frequency\n.  collect_stats:darknessomi-musicbox-commit_activity\n.  collect_stats:darknessomi-musicbox-participation\n.  collect_stats:darknessomi-musicbox-releases\n.  collect_stats:pyro-ppl-pyro-code_frequency\n.  collect_stats:pyro-ppl-pyro-commit_activity\n.  collect_stats:pyro-ppl-pyro-participation\n.  collect_stats:pyro-ppl-pyro-releases\n.  collect_stats:alexjc-neural-enhance-code_frequency\n.  collect_stats:alexjc-neural-enhance-commit_activity\n.  collect_stats:alexjc-neural-enhance-participation\n.  collect_stats:alexjc-neural-enhance-releases\n.  collect_stats:QuantEcon-QuantEcon.py-code_frequency\n.  collect_stats:QuantEcon-QuantEcon.py-commit_activity\n.  collect_stats:QuantEcon-QuantEcon.py-participation\n.  collect_stats:QuantEcon-QuantEcon.py-releases\n.  collect_stats:Gallopsled-pwntools-code_frequency\n.  collect_stats:Gallopsled-pwntools-commit_activity\n.  collect_stats:Gallopsled-pwntools-participation\n.  collect_stats:Gallopsled-pwntools-releases\n.  collect_stats:amueller-word_cloud-code_frequency\n.  collect_stats:amueller-word_cloud-commit_activity\n.  collect_stats:amueller-word_cloud-participation\n.  collect_stats:amueller-word_cloud-releases\n.  collect_stats:rasbt-mlxtend-code_frequency\n.  collect_stats:rasbt-mlxtend-commit_activity\n.  collect_stats:rasbt-mlxtend-participation\n.  collect_stats:rasbt-mlxtend-releases\n.  collect_stats:google-python-fire-code_frequency\n.  collect_stats:google-python-fire-commit_activity\n.  collect_stats:google-python-fire-participation\n.  collect_stats:google-python-fire-releases\n.  collect_stats:1adrianb-face-alignment-code_frequency\n.  collect_stats:1adrianb-face-alignment-commit_activity\n.  collect_stats:1adrianb-face-alignment-participation\n.  collect_stats:1adrianb-face-alignment-releases\n.  collect_stats:django-django-code_frequency\n.  collect_stats:django-django-commit_activity\n.  collect_stats:django-django-participation\n.  collect_stats:django-django-releases\n.  collect_stats:elebumm-RedditVideoMakerBot-code_frequency\n.  collect_stats:elebumm-RedditVideoMakerBot-commit_activity\n.  collect_stats:elebumm-RedditVideoMakerBot-participation\n.  collect_stats:elebumm-RedditVideoMakerBot-releases\n.  collect_stats:Jack-Cherish-python-spider-code_frequency\n.  collect_stats:Jack-Cherish-python-spider-commit_activity\n.  collect_stats:Jack-Cherish-python-spider-participation\n.  collect_stats:Jack-Cherish-python-spider-releases\n.  collect_stats:OpenBB-finance-OpenBBTerminal-code_frequency\n.  collect_stats:OpenBB-finance-OpenBBTerminal-commit_activity\n.  collect_stats:OpenBB-finance-OpenBBTerminal-participation\n.  collect_stats:OpenBB-finance-OpenBBTerminal-releases\n.  collect_stats:networkx-networkx-code_frequency\n.  collect_stats:networkx-networkx-commit_activity\n.  collect_stats:networkx-networkx-participation\n.  collect_stats:networkx-networkx-releases\n.  collect_stats:openshift-openshift-ansible-code_frequency\n.  collect_stats:openshift-openshift-ansible-commit_activity\n.  collect_stats:openshift-openshift-ansible-participation\n.  collect_stats:openshift-openshift-ansible-releases\n.  collect_stats:heartexlabs-label-studio-code_frequency\n.  collect_stats:heartexlabs-label-studio-commit_activity\n.  collect_stats:heartexlabs-label-studio-participation\n.  collect_stats:heartexlabs-label-studio-releases\n.  collect_stats:CTFd-CTFd-code_frequency\n.  collect_stats:CTFd-CTFd-commit_activity\n.  collect_stats:CTFd-CTFd-participation\n.  collect_stats:CTFd-CTFd-releases\n.  collect_stats:nvbn-thefuck-code_frequency\n.  collect_stats:nvbn-thefuck-commit_activity\n.  collect_stats:nvbn-thefuck-participation\n.  collect_stats:nvbn-thefuck-releases\n.  collect_stats:encode-django-rest-framework-code_frequency\n.  collect_stats:encode-django-rest-framework-commit_activity\n.  collect_stats:encode-django-rest-framework-participation\n.  collect_stats:encode-django-rest-framework-releases\n.  collect_stats:tflearn-tflearn-code_frequency\n.  collect_stats:tflearn-tflearn-commit_activity\n.  collect_stats:tflearn-tflearn-participation\n.  collect_stats:tflearn-tflearn-releases\n.  collect_stats:Theano-Theano-code_frequency\n.  collect_stats:Theano-Theano-commit_activity\n.  collect_stats:Theano-Theano-participation\n.  collect_stats:Theano-Theano-releases\n.  collect_stats:TheSpeedX-TBomb-code_frequency\n.  collect_stats:TheSpeedX-TBomb-commit_activity\n.  collect_stats:TheSpeedX-TBomb-participation\n.  collect_stats:TheSpeedX-TBomb-releases\n.  collect_stats:hyperopt-hyperopt-code_frequency\n.  collect_stats:hyperopt-hyperopt-commit_activity\n.  collect_stats:hyperopt-hyperopt-participation\n.  collect_stats:hyperopt-hyperopt-releases\n.  collect_stats:donnemartin-dev-setup-code_frequency\n.  collect_stats:donnemartin-dev-setup-commit_activity\n.  collect_stats:donnemartin-dev-setup-participation\n.  collect_stats:donnemartin-dev-setup-releases\n.  collect_stats:microsoft-qlib-code_frequency\n.  collect_stats:microsoft-qlib-commit_activity\n.  collect_stats:microsoft-qlib-participation\n.  collect_stats:microsoft-qlib-releases\n.  collect_stats:googleapis-google-api-python-client-code_frequency\n.  collect_stats:googleapis-google-api-python-client-commit_activity\n.  collect_stats:googleapis-google-api-python-client-participation\n.  collect_stats:googleapis-google-api-python-client-releases\n.  collect_stats:horovod-horovod-code_frequency\n.  collect_stats:horovod-horovod-commit_activity\n.  collect_stats:horovod-horovod-participation\n.  collect_stats:horovod-horovod-releases\n.  collect_stats:scikit-image-scikit-image-code_frequency\n.  collect_stats:scikit-image-scikit-image-commit_activity\n.  collect_stats:scikit-image-scikit-image-participation\n.  collect_stats:scikit-image-scikit-image-releases\n.  collect_stats:git-cola-git-cola-code_frequency\n.  collect_stats:git-cola-git-cola-commit_activity\n.  collect_stats:git-cola-git-cola-participation\n.  collect_stats:git-cola-git-cola-releases\n.  collect_stats:nicolargo-glances-code_frequency\n.  collect_stats:nicolargo-glances-commit_activity\n.  collect_stats:nicolargo-glances-participation\n.  collect_stats:nicolargo-glances-releases\n.  collect_stats:deepmind-pysc2-code_frequency\n.  collect_stats:deepmind-pysc2-commit_activity\n.  collect_stats:deepmind-pysc2-participation\n.  collect_stats:deepmind-pysc2-releases\n.  collect_stats:librosa-librosa-code_frequency\n.  collect_stats:librosa-librosa-commit_activity\n.  collect_stats:librosa-librosa-participation\n.  collect_stats:librosa-librosa-releases\n.  collect_stats:PyMySQL-mysqlclient-code_frequency\n.  collect_stats:PyMySQL-mysqlclient-commit_activity\n.  collect_stats:PyMySQL-mysqlclient-participation\n.  collect_stats:PyMySQL-mysqlclient-releases\n.  collect_stats:trustedsec-ptf-code_frequency\n.  collect_stats:trustedsec-ptf-commit_activity\n.  collect_stats:trustedsec-ptf-participation\n.  collect_stats:trustedsec-ptf-releases\n.  collect_stats:facebookresearch-fairseq-code_frequency\n.  collect_stats:facebookresearch-fairseq-commit_activity\n.  collect_stats:facebookresearch-fairseq-participation\n.  collect_stats:facebookresearch-fairseq-releases\n.  collect_stats:mingrammer-diagrams-code_frequency\n.  collect_stats:mingrammer-diagrams-commit_activity\n.  collect_stats:mingrammer-diagrams-participation\n.  collect_stats:mingrammer-diagrams-releases\n.  collect_stats:mkleehammer-pyodbc-code_frequency\n.  collect_stats:mkleehammer-pyodbc-commit_activity\n.  collect_stats:mkleehammer-pyodbc-participation\n.  collect_stats:mkleehammer-pyodbc-releases\n.  collect_stats:aaPanel-BaoTa-code_frequency\n.  collect_stats:aaPanel-BaoTa-commit_activity\n.  collect_stats:aaPanel-BaoTa-participation\n.  collect_stats:aaPanel-BaoTa-releases\n.  collect_stats:mlflow-mlflow-code_frequency\n.  collect_stats:mlflow-mlflow-commit_activity\n.  collect_stats:mlflow-mlflow-participation\n.  collect_stats:mlflow-mlflow-releases\n.  collect_stats:deepchem-deepchem-code_frequency\n.  collect_stats:deepchem-deepchem-commit_activity\n.  collect_stats:deepchem-deepchem-participation\n.  collect_stats:deepchem-deepchem-releases\n.  collect_stats:frappe-bench-code_frequency\n.  collect_stats:frappe-bench-commit_activity\n.  collect_stats:frappe-bench-participation\n.  collect_stats:frappe-bench-releases\n.  collect_stats:matplotlib-matplotlib-code_frequency\n.  collect_stats:matplotlib-matplotlib-commit_activity\n.  collect_stats:matplotlib-matplotlib-participation\n.  collect_stats:matplotlib-matplotlib-releases\n.  collect_stats:pydata-pandas-datareader-code_frequency\n.  collect_stats:pydata-pandas-datareader-commit_activity\n.  collect_stats:pydata-pandas-datareader-participation\n.  collect_stats:pydata-pandas-datareader-releases\n.  collect_stats:TencentARC-GFPGAN-code_frequency\n.  collect_stats:TencentARC-GFPGAN-commit_activity\n.  collect_stats:TencentARC-GFPGAN-participation\n.  collect_stats:TencentARC-GFPGAN-releases\n.  collect_stats:ThoughtfulDev-EagleEye-code_frequency\n.  collect_stats:ThoughtfulDev-EagleEye-commit_activity\n.  collect_stats:ThoughtfulDev-EagleEye-participation\n.  collect_stats:ThoughtfulDev-EagleEye-releases\n.  collect_stats:Uberi-speech_recognition-code_frequency\n.  collect_stats:Uberi-speech_recognition-commit_activity\n.  collect_stats:Uberi-speech_recognition-participation\n.  collect_stats:Uberi-speech_recognition-releases\n.  collect_stats:scikit-learn-contrib-imbalanced-learn-code_frequency\n.  collect_stats:scikit-learn-contrib-imbalanced-learn-commit_activity\n.  collect_stats:scikit-learn-contrib-imbalanced-learn-participation\n.  collect_stats:scikit-learn-contrib-imbalanced-learn-releases\n.  collect_stats:Lightning-AI-lightning-code_frequency\n.  collect_stats:Lightning-AI-lightning-commit_activity\n.  collect_stats:Lightning-AI-lightning-participation\n.  collect_stats:Lightning-AI-lightning-releases\n.  collect_stats:strawlab-python-pcl-code_frequency\n.  collect_stats:strawlab-python-pcl-commit_activity\n.  collect_stats:strawlab-python-pcl-participation\n.  collect_stats:strawlab-python-pcl-releases\n.  collect_stats:jopohl-urh-code_frequency\n.  collect_stats:jopohl-urh-commit_activity\n.  collect_stats:jopohl-urh-participation\n.  collect_stats:jopohl-urh-releases\n.  collect_stats:GreaterWMS-GreaterWMS-code_frequency\n.  collect_stats:GreaterWMS-GreaterWMS-commit_activity\n.  collect_stats:GreaterWMS-GreaterWMS-participation\n.  collect_stats:GreaterWMS-GreaterWMS-releases\n.  collect_stats:LionSec-katoolin-code_frequency\n.  collect_stats:LionSec-katoolin-commit_activity\n.  collect_stats:LionSec-katoolin-participation\n.  collect_stats:LionSec-katoolin-releases\n.  collect_stats:ManimCommunity-manim-code_frequency\n.  collect_stats:ManimCommunity-manim-commit_activity\n.  collect_stats:ManimCommunity-manim-participation\n.  collect_stats:ManimCommunity-manim-releases\n.  collect_stats:dmlc-gluon-cv-code_frequency\n.  collect_stats:dmlc-gluon-cv-commit_activity\n.  collect_stats:dmlc-gluon-cv-participation\n.  collect_stats:dmlc-gluon-cv-releases\n.  collect_stats:gorakhargosh-watchdog-code_frequency\n.  collect_stats:gorakhargosh-watchdog-commit_activity\n.  collect_stats:gorakhargosh-watchdog-participation\n.  collect_stats:gorakhargosh-watchdog-releases\n.  collect_stats:biolab-orange3-code_frequency\n.  collect_stats:biolab-orange3-commit_activity\n.  collect_stats:biolab-orange3-participation\n.  collect_stats:biolab-orange3-releases\n.  collect_stats:NullArray-AutoSploit-code_frequency\n.  collect_stats:NullArray-AutoSploit-commit_activity\n.  collect_stats:NullArray-AutoSploit-participation\n.  collect_stats:NullArray-AutoSploit-releases\n.  collect_stats:webpy-webpy-code_frequency\n.  collect_stats:webpy-webpy-commit_activity\n.  collect_stats:webpy-webpy-participation\n.  collect_stats:webpy-webpy-releases\n.  collect_stats:sherlock-project-sherlock-code_frequency\n.  collect_stats:sherlock-project-sherlock-commit_activity\n.  collect_stats:sherlock-project-sherlock-participation\n.  collect_stats:sherlock-project-sherlock-releases\n.  collect_stats:celery-celery-code_frequency\n.  collect_stats:celery-celery-commit_activity\n.  collect_stats:celery-celery-participation\n.  collect_stats:celery-celery-releases\n.  collect_stats:xinntao-Real-ESRGAN-code_frequency\n.  collect_stats:xinntao-Real-ESRGAN-commit_activity\n.  collect_stats:xinntao-Real-ESRGAN-participation\n.  collect_stats:xinntao-Real-ESRGAN-releases\n.  collect_stats:drivendata-cookiecutter-data-science-code_frequency\n.  collect_stats:drivendata-cookiecutter-data-science-commit_activity\n.  collect_stats:drivendata-cookiecutter-data-science-participation\n.  collect_stats:drivendata-cookiecutter-data-science-releases\n.  collect_stats:pgmpy-pgmpy-code_frequency\n.  collect_stats:pgmpy-pgmpy-commit_activity\n.  collect_stats:pgmpy-pgmpy-participation\n.  collect_stats:pgmpy-pgmpy-releases\n.  collect_stats:Chia-Network-chia-blockchain-code_frequency\n.  collect_stats:Chia-Network-chia-blockchain-commit_activity\n.  collect_stats:Chia-Network-chia-blockchain-participation\n.  collect_stats:Chia-Network-chia-blockchain-releases\n.  collect_stats:thunil-TecoGAN-code_frequency\n.  collect_stats:thunil-TecoGAN-commit_activity\n.  collect_stats:thunil-TecoGAN-participation\n.  collect_stats:thunil-TecoGAN-releases\n.  collect_stats:CouchPotato-CouchPotatoServer-code_frequency\n.  collect_stats:CouchPotato-CouchPotatoServer-commit_activity\n.  collect_stats:CouchPotato-CouchPotatoServer-participation\n.  collect_stats:CouchPotato-CouchPotatoServer-releases\n.  collect_stats:boto-boto3-code_frequency\n.  collect_stats:boto-boto3-commit_activity\n.  collect_stats:boto-boto3-participation\n.  collect_stats:boto-boto3-releases\n.  collect_stats:RaRe-Technologies-gensim-code_frequency\n.  collect_stats:RaRe-Technologies-gensim-commit_activity\n.  collect_stats:RaRe-Technologies-gensim-participation\n.  collect_stats:RaRe-Technologies-gensim-releases\n.  collect_stats:CharlesPikachu-Games-code_frequency\n.  collect_stats:CharlesPikachu-Games-commit_activity\n.  collect_stats:CharlesPikachu-Games-participation\n.  collect_stats:CharlesPikachu-Games-releases\n.  collect_stats:pytorch-tutorials-code_frequency\n.  collect_stats:pytorch-tutorials-commit_activity\n.  collect_stats:pytorch-tutorials-participation\n.  collect_stats:pytorch-tutorials-releases\n.  collect_stats:PyMySQL-PyMySQL-code_frequency\n.  collect_stats:PyMySQL-PyMySQL-commit_activity\n.  collect_stats:PyMySQL-PyMySQL-participation\n.  collect_stats:PyMySQL-PyMySQL-releases\n.  collect_stats:google-jax-code_frequency\n.  collect_stats:google-jax-commit_activity\n.  collect_stats:google-jax-participation\n.  collect_stats:google-jax-releases\n.  collect_stats:asweigart-pyautogui-code_frequency\n.  collect_stats:asweigart-pyautogui-commit_activity\n.  collect_stats:asweigart-pyautogui-participation\n.  collect_stats:asweigart-pyautogui-releases\n.  collect_stats:Hironsan-BossSensor-code_frequency\n.  collect_stats:Hironsan-BossSensor-commit_activity\n.  collect_stats:Hironsan-BossSensor-participation\n.  collect_stats:Hironsan-BossSensor-releases\n.  collect_stats:tensorflow-agents-code_frequency\n.  collect_stats:tensorflow-agents-commit_activity\n.  collect_stats:tensorflow-agents-participation\n.  collect_stats:tensorflow-agents-releases\n.  collect_stats:Zulko-moviepy-code_frequency\n.  collect_stats:Zulko-moviepy-commit_activity\n.  collect_stats:Zulko-moviepy-participation\n.  collect_stats:Zulko-moviepy-releases\n.  collect_stats:wting-autojump-code_frequency\n.  collect_stats:wting-autojump-commit_activity\n.  collect_stats:wting-autojump-participation\n.  collect_stats:wting-autojump-releases\n.  collect_stats:python-mypy-code_frequency\n.  collect_stats:python-mypy-commit_activity\n.  collect_stats:python-mypy-participation\n.  collect_stats:python-mypy-releases\n.  collect_stats:docker-docker-py-code_frequency\n.  collect_stats:docker-docker-py-commit_activity\n.  collect_stats:docker-docker-py-participation\n.  collect_stats:docker-docker-py-releases\n.  collect_stats:conda-conda-code_frequency\n.  collect_stats:conda-conda-commit_activity\n.  collect_stats:conda-conda-participation\n.  collect_stats:conda-conda-releases\n.  collect_stats:aristocratos-bpytop-code_frequency\n.  collect_stats:aristocratos-bpytop-commit_activity\n.  collect_stats:aristocratos-bpytop-participation\n.  collect_stats:aristocratos-bpytop-releases\n.  collect_stats:pypa-pip-code_frequency\n.  collect_stats:pypa-pip-commit_activity\n.  collect_stats:pypa-pip-participation\n.  collect_stats:pypa-pip-releases\n.  collect_stats:InstaPy-InstaPy-code_frequency\n.  collect_stats:InstaPy-InstaPy-commit_activity\n.  collect_stats:InstaPy-InstaPy-participation\n.  collect_stats:InstaPy-InstaPy-releases\n.  collect_stats:jupyterhub-jupyterhub-code_frequency\n.  collect_stats:jupyterhub-jupyterhub-commit_activity\n.  collect_stats:jupyterhub-jupyterhub-participation\n.  collect_stats:jupyterhub-jupyterhub-releases\n.  collect_stats:my8100-scrapydweb-code_frequency\n.  collect_stats:my8100-scrapydweb-commit_activity\n.  collect_stats:my8100-scrapydweb-participation\n.  collect_stats:my8100-scrapydweb-releases\n.  collect_stats:coursera-dl-coursera-dl-code_frequency\n.  collect_stats:coursera-dl-coursera-dl-commit_activity\n.  collect_stats:coursera-dl-coursera-dl-participation\n.  collect_stats:coursera-dl-coursera-dl-releases\n.  collect_stats:zeromq-pyzmq-code_frequency\n.  collect_stats:zeromq-pyzmq-commit_activity\n.  collect_stats:zeromq-pyzmq-participation\n.  collect_stats:zeromq-pyzmq-releases\n.  collect_stats:frappe-erpnext-code_frequency\n.  collect_stats:frappe-erpnext-commit_activity\n.  collect_stats:frappe-erpnext-participation\n.  collect_stats:frappe-erpnext-releases\n.  collect_stats:microsoft-pyright-code_frequency\n.  collect_stats:microsoft-pyright-commit_activity\n.  collect_stats:microsoft-pyright-participation\n.  collect_stats:microsoft-pyright-releases\n.  collect_stats:sightmachine-SimpleCV-code_frequency\n.  collect_stats:sightmachine-SimpleCV-commit_activity\n.  collect_stats:sightmachine-SimpleCV-participation\n.  collect_stats:sightmachine-SimpleCV-releases\n.  collect_stats:deepmind-graph_nets-code_frequency\n.  collect_stats:deepmind-graph_nets-commit_activity\n.  collect_stats:deepmind-graph_nets-participation\n.  collect_stats:deepmind-graph_nets-releases\n.  collect_stats:sshuttle-sshuttle-code_frequency\n.  collect_stats:sshuttle-sshuttle-commit_activity\n.  collect_stats:sshuttle-sshuttle-participation\n.  collect_stats:sshuttle-sshuttle-releases\n.  collect_stats:joestump-python-oauth2-code_frequency\n.  collect_stats:joestump-python-oauth2-commit_activity\n.  collect_stats:joestump-python-oauth2-participation\n.  collect_stats:joestump-python-oauth2-releases\n.  collect_stats:ycm-core-YouCompleteMe-code_frequency\n.  collect_stats:ycm-core-YouCompleteMe-commit_activity\n.  collect_stats:ycm-core-YouCompleteMe-participation\n.  collect_stats:ycm-core-YouCompleteMe-releases\n.  collect_stats:twisted-twisted-code_frequency\n.  collect_stats:twisted-twisted-commit_activity\n.  collect_stats:twisted-twisted-participation\n.  collect_stats:twisted-twisted-releases\n.  collect_stats:SecureAuthCorp-impacket-code_frequency\n.  collect_stats:SecureAuthCorp-impacket-commit_activity\n.  collect_stats:SecureAuthCorp-impacket-participation\n.  collect_stats:SecureAuthCorp-impacket-releases\n.  collect_stats:encode-starlette-code_frequency\n.  collect_stats:encode-starlette-commit_activity\n.  collect_stats:encode-starlette-participation\n.  collect_stats:encode-starlette-releases\n.  collect_stats:nodejs-node-gyp-code_frequency\n.  collect_stats:nodejs-node-gyp-commit_activity\n.  collect_stats:nodejs-node-gyp-participation\n.  collect_stats:nodejs-node-gyp-releases\n.  collect_stats:pyserial-pyserial-code_frequency\n.  collect_stats:pyserial-pyserial-commit_activity\n.  collect_stats:pyserial-pyserial-participation\n.  collect_stats:pyserial-pyserial-releases\n.  collect_stats:keras-rl-keras-rl-code_frequency\n.  collect_stats:keras-rl-keras-rl-commit_activity\n.  collect_stats:keras-rl-keras-rl-participation\n.  collect_stats:keras-rl-keras-rl-releases\n.  collect_stats:onionshare-onionshare-code_frequency\n.  collect_stats:onionshare-onionshare-commit_activity\n.  collect_stats:onionshare-onionshare-participation\n.  collect_stats:onionshare-onionshare-releases\n.  collect_stats:mesonbuild-meson-code_frequency\n.  collect_stats:mesonbuild-meson-commit_activity\n.  collect_stats:mesonbuild-meson-participation\n.  collect_stats:mesonbuild-meson-releases\n.  collect_stats:MTG-sms-tools-code_frequency\n.  collect_stats:MTG-sms-tools-commit_activity\n.  collect_stats:MTG-sms-tools-participation\n.  collect_stats:MTG-sms-tools-releases\n.  collect_stats:mps-youtube-mps-youtube-code_frequency\n.  collect_stats:mps-youtube-mps-youtube-commit_activity\n.  collect_stats:mps-youtube-mps-youtube-participation\n.  collect_stats:mps-youtube-mps-youtube-releases\n.  collect_stats:MongoEngine-mongoengine-code_frequency\n.  collect_stats:MongoEngine-mongoengine-commit_activity\n.  collect_stats:MongoEngine-mongoengine-participation\n.  collect_stats:MongoEngine-mongoengine-releases\n.  collect_stats:deepset-ai-haystack-code_frequency\n.  collect_stats:deepset-ai-haystack-commit_activity\n.  collect_stats:deepset-ai-haystack-participation\n.  collect_stats:deepset-ai-haystack-releases\n.  collect_stats:sourabhv-FlapPyBird-code_frequency\n.  collect_stats:sourabhv-FlapPyBird-commit_activity\n.  collect_stats:sourabhv-FlapPyBird-participation\n.  collect_stats:sourabhv-FlapPyBird-releases\n.  collect_stats:open-mmlab-mmcv-code_frequency\n.  collect_stats:open-mmlab-mmcv-commit_activity\n.  collect_stats:open-mmlab-mmcv-participation\n.  collect_stats:open-mmlab-mmcv-releases\n.  collect_stats:faucetsdn-ryu-code_frequency\n.  collect_stats:faucetsdn-ryu-commit_activity\n.  collect_stats:faucetsdn-ryu-participation\n.  collect_stats:faucetsdn-ryu-releases\n</pre>"},{"location":"xxii/2022-12-13-github-api-stats.html#explore-the-data-in-dataframes","title":"explore the data in dataframes","text":"<pre><code>     import pandas\n</code></pre> <pre><code>    df = pandas.DataFrame(get_iterables(), columns=\"url project repo\".split()).set_index(\"url\")\n    df = df.set_index(df.index.str.rpartition(\"/\").get_level_values(-1).rename(\"stat\"),append=True)\n    df = df.reorder_levels([1, 0], axis=0)\n</code></pre> <pre><code>    releases =df.loc[\"releases\"].index.to_series().map(get_stats).apply(pandas.Series).stack().apply(pandas.Series)\n</code></pre> <pre>/tmp/ipykernel_70909/139248023.py:1: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n  releases =df.loc[\"releases\"].index.to_series().map(get_stats).apply(pandas.Series).stack().apply(pandas.Series)\n</pre> <pre><code>    releases[[\"tag_name\", \"published_at\"]]\n</code></pre> tag_name published_at url https://api.github.com/repos/tensorflow/models/releases 0 v2.11.0 2022-11-23T00:09:34Z 1 v2.10.1 2022-11-17T05:15:35Z 2 v2.10.0 2022-09-19T21:45:22Z 3 v2.7.2 2022-07-08T06:48:39Z 4 v2.9.2 2022-05-20T04:55:27Z ... ... ... ... https://api.github.com/repos/open-mmlab/mmcv/releases 25 v1.3.13 2021-09-10T03:43:36Z 26 v1.3.12 2021-08-24T14:17:49Z 27 v1.3.11 2021-08-12T09:20:52Z 28 v1.3.10 2021-07-24T12:40:10Z 29 v1.3.9 2021-07-10T03:07:15Z <p>2808 rows \u00d7 2 columns</p> <pre><code>    freq = df.loc[\"code_frequency\"].index.to_series().map(\n        get_stats\n    ).apply(\n        pandas.Series\n    ).stack().reset_index(-1, drop=True).apply(pandas.Series)\n    freq.columns = list(\"w+-\")    \n    freq.w = freq.w.pipe(pandas.to_datetime, unit=\"s\")\n    freq = freq.set_index(freq.index.map(operator.itemgetter(slice(len(GH) + 7, -len(\"/stats/code_frequency\")))))\n</code></pre> <pre><code>    import hvplot.pandas\n</code></pre> <pre><code>    b = freq[list(\"+-\")].abs().sum(axis=1).gt(0)\n</code></pre> <pre><code>    freq[b][list(\"+-\")].describe()\n</code></pre> + - count 5.267500e+04 5.267500e+04 mean 5.047921e+03 -4.063599e+03 std 8.565557e+04 9.036993e+04 min 0.000000e+00 -1.494524e+07 25% 4.000000e+01 -6.400000e+02 50% 2.940000e+02 -1.100000e+02 75% 1.367500e+03 -1.300000e+01 max 1.461846e+07 0.000000e+00"},{"location":"xxii/2022-12-15-html-tags-study.html","title":"all the tags i could be using","text":"<p>i'm interested in how we write about code, and i think we should use standards in as many places as possible. the document explores some of the standard html tags that i'm not aware of, or forgot about.</p> <p>let's look through the standard html tags and see what opinions we can reuse.</p>"},{"location":"xxii/2022-12-15-html-tags-study.html#motivation","title":"motivation","text":"<p>this exercise is useful for me because i like to write in markdown which has a limited design affordances. since markdown is a superset of html we can reuse standard tags as design units in our literate programming.</p>"},{"location":"xxii/2022-12-15-html-tags-study.html#a-concrete-example-is-the-var-tag","title":"a concrete example is the <code>&lt;var/&gt;</code> tag","text":"<p>The  HTML element represents the name of a variable in a mathematical expression or a programming context. It's typically presented using an italicized version of the current typeface, although that behavior is browser-dependent. The Var Text element <p>based on definition the <code>&lt;var&gt;</code> tag seems like perfect way to style variables defined within a program. * i do not agree with the style, but i agree with the semantics. * to derive intertextuality between code/narrative. <code>pre</code> tags seems to make more sense between there forms will be most consistent. the monospace indicates that this reads code.     * maybe the code has a different style itself.</p> <pre><code>    %reload_ext pidgy\n    import pandas, requests\n    pandas.options\n    __import__(\"requests_cache\").install_cache()\n</code></pre> <pre><code>### style choices\n\nwhile toying with the document i realize that some folks might be caught up \nby style inconsistencies with the tags.\ni'm changing some styles used in this document.\nthe goal of this is semantic consistency so style matters less today.\n\n    style=\\\n```css\nvar {\n    font-family: monospace;\n    whitespace: pre;\n    font-weight: bold;\n}\n\nmark {\n    background-color: lightblue;\n}\na:link {\n    font-weight: bold;\n}\n```\n&lt;style&gt;\n{{style.splitlines(True)[1:-1] | join}}\n&lt;/style&gt;\n</code></pre>"},{"location":"xxii/2022-12-15-html-tags-study.html#style-choices","title":"style choices","text":"<p>while toying with the document i realize that some folks might be caught up  by style inconsistencies with the tags. i'm changing some styles used in this document. the goal of this is semantic consistency so style matters less today.</p> <pre><code>style=\\\n</code></pre> <p><code>css var {     font-family: monospace;     whitespace: pre;     font-weight: bold; }  mark {     background-color: lightblue; } a:link {     font-weight: bold; }</code></p>"},{"location":"xxii/2022-12-15-html-tags-study.html#our-resources","title":"our resources","text":"<p>````````````````````````````````````````````````python we are going to explore documentation from mdn and w3schools because they are popular resources that populated the query all the html tags.</p> <pre><code>mdn,w3schools=filter(any, (\n</code></pre> <p>https://developer.mozilla.org/en-US/docs/Web/HTML/Element</p> <p>https://www.w3schools.com/TAGS/default.asp</p> <pre><code>).splitlines())\n</code></pre> <p>````````````````````````````````````````````````</p> <p>we are going to explore documentation from mdn and w3schools because they are popular resources that populated the query all the html tags.</p> <pre><code>mdn,w3schools=filter(any, (\n</code></pre> <p>https://developer.mozilla.org/en-US/docs/Web/HTML/Element</p> <p>https://www.w3schools.com/TAGS/default.asp</p> <pre><code>).splitlines())\n</code></pre> <p>````````````````````````````````````````````````python</p>"},{"location":"xxii/2022-12-15-html-tags-study.html#choosing-a-resource","title":"choosing a resource","text":"<p>we are going to refer to the mdn docs: * mdn has more description * the mdn docs have {{len(mdn_extras)}} more tags defined.  after further inspection these may be mostly deprecated tags. * mdn breaks their tables into groups</p> <p>between the two resources there are {{len(AB)}} tags to explore.</p>       A = pandas.concat(dfs := pandas.read_html(io.StringIO(requests.get(mdn).text))).set_index(\"Element\")     B = pandas.concat(pandas.read_html(io.StringIO(requests.get(w3schools).text))).set_index(\"Tag\")     AB = A[\"Description\"].to_frame(\"mdn\").join(         B[\"Description\"].rename(\"w3schools\"), how=\"outer\"     )     mdn_extras = AB[\"mdn\"].index.symmetric_difference(AB[\"w3schools\"].dropna().index).to_frame().index   <p>````````````````````````````````````````````````</p>"},{"location":"xxii/2022-12-15-html-tags-study.html#choosing-a-resource_1","title":"choosing a resource","text":"<p>we are going to refer to the mdn docs: * mdn has more description * the mdn docs have 20 more tags defined.  after further inspection these may be mostly deprecated tags. * mdn breaks their tables into groups</p> <p>between the two resources there are 139 tags to explore.</p>       A = pandas.concat(dfs := pandas.read_html(io.StringIO(requests.get(mdn).text))).set_index(\"Element\")     B = pandas.concat(pandas.read_html(io.StringIO(requests.get(w3schools).text))).set_index(\"Tag\")     AB = A[\"Description\"].to_frame(\"mdn\").join(         B[\"Description\"].rename(\"w3schools\"), how=\"outer\"     )     mdn_extras = AB[\"mdn\"].index.symmetric_difference(AB[\"w3schools\"].dropna().index).to_frame().index   <p>````````````````````````````````````````````````python</p>"},{"location":"xxii/2022-12-15-html-tags-study.html#the-tags","title":"the tags","text":"<p>````````````````````````````````````````````````</p>"},{"location":"xxii/2022-12-15-html-tags-study.html#the-tags_1","title":"the tags","text":"<p>````````````````````````````````````````````````python</p>"},{"location":"xxii/2022-12-15-html-tags-study.html#the-html-tag","title":"the <code>html</code> tag","text":"<p>Using the language attribute on the HTML element requires the <code>lang</code> attribute to be defined. otherwise, most automated testing with fail.</p> <p>{{dfs[0]}}</p> <p>````````````````````````````````````````````````</p>"},{"location":"xxii/2022-12-15-html-tags-study.html#the-html-tag_1","title":"the <code>html</code> tag","text":"<p>Using the language attribute on the HTML element requires the <code>lang</code> attribute to be defined. otherwise, most automated testing with fail.</p> Element Description 0 &lt;html&gt; The &lt;html&gt; HTML element represents the root (t... <p>````````````````````````````````````````````````python</p>"},{"location":"xxii/2022-12-15-html-tags-study.html#document-tags","title":"document tags","text":"<p>there is nothing fun and new here.  i do need to visit the recommendations for the <code>&lt;meta&gt;</code> for others reasons.</p> <p>for accessibility reasons we need to include <code>&lt;title&gt;</code> because it is the document title.</p> <p>{{dfs[1]}}</p> <p>````````````````````````````````````````````````</p>"},{"location":"xxii/2022-12-15-html-tags-study.html#document-tags_1","title":"document tags","text":"<p>there is nothing fun and new here.  i do need to visit the recommendations for the <code>&lt;meta&gt;</code> for others reasons.</p> <p>for accessibility reasons we need to include <code>&lt;title&gt;</code> because it is the document title.</p> Element Description 0 &lt;base&gt; The &lt;base&gt; HTML element specifies the base URL... 1 &lt;head&gt; The &lt;head&gt; HTML element contains machine-reada... 2 &lt;link&gt; The &lt;link&gt; HTML element specifies relationship... 3 &lt;meta&gt; The &lt;meta&gt; HTML element represents Metadata th... 4 &lt;style&gt; The &lt;style&gt; HTML element contains style inform... 5 &lt;title&gt; The &lt;title&gt; HTML element defines the document'... <p>````````````````````````````````````````````````python</p> <pre><code>dfs[2]; # skip the body tag\n</code></pre> <p>````````````````````````````````````````````````</p> <p>````````````````````````````````````````````````python</p>"},{"location":"xxii/2022-12-15-html-tags-study.html#content-sections","title":"content sections","text":"<p>the <code>&lt;header&gt;</code> element might be practial to utilize within markdown. there are probably geo situations where address would be useful too.</p> <p>{{dfs[3]}} ````````````````````````````````````````````````</p>"},{"location":"xxii/2022-12-15-html-tags-study.html#content-sections_1","title":"content sections","text":"<p>the <code>&lt;header&gt;</code> element might be practial to utilize within markdown. there are probably geo situations where address would be useful too.</p> Element Description 0 &lt;address&gt; The &lt;address&gt; HTML element indicates that the ... 1 &lt;article&gt; The &lt;article&gt; HTML element represents a self-c... 2 &lt;aside&gt; The &lt;aside&gt; HTML element represents a portion ... 3 &lt;footer&gt; The &lt;footer&gt; HTML element represents a footer ... 4 &lt;header&gt; The &lt;header&gt; HTML element represents introduct... 5 &lt;h1&gt;, &lt;h2&gt;, &lt;h3&gt;, &lt;h4&gt;, &lt;h5&gt;, &lt;h6&gt; The &lt;h1&gt; to &lt;h6&gt; HTML elements represent six l... 6 &lt;main&gt; The &lt;main&gt; HTML element represents the dominan... 7 &lt;nav&gt; The &lt;nav&gt; HTML element represents a section of... 8 &lt;section&gt; The &lt;section&gt; HTML element represents a generi... <p>````````````````````````````````````````````````python</p> Element Description 0 &lt;blockquote&gt; The &lt;blockquote&gt; HTML element indicates that t... 1 &lt;dd&gt; The &lt;dd&gt; HTML element provides the description... 2 &lt;div&gt; The &lt;div&gt; HTML element is the generic containe... 3 &lt;dl&gt; The &lt;dl&gt; HTML element represents a description... 4 &lt;dt&gt; The &lt;dt&gt; HTML element specifies a term in a de... 5 &lt;figcaption&gt; The &lt;figcaption&gt; HTML element represents a cap... 6 &lt;figure&gt; The &lt;figure&gt; HTML element represents self-cont... 7 &lt;hr&gt; The &lt;hr&gt; HTML element represents a thematic br... 8 &lt;li&gt; The &lt;li&gt; HTML element is used to represent an ... 9 &lt;menu&gt; The &lt;menu&gt; HTML element is described in the HT... 10 &lt;ol&gt; The &lt;ol&gt; HTML element represents an ordered li... 11 &lt;p&gt; The &lt;p&gt; HTML element represents a paragraph. P... 12 &lt;pre&gt; The &lt;pre&gt; HTML element represents preformatted... 13 &lt;ul&gt; The &lt;ul&gt; HTML element represents an unordered ..."},{"location":"xxii/2022-12-15-html-tags-study.html#text-content","title":"text content","text":"<pre><code>dfs[4]\n</code></pre> <p>````````````````````````````````````````````````</p>"},{"location":"xxii/2022-12-15-html-tags-study.html#text-content_1","title":"text content","text":"<pre><code>dfs[4]\n</code></pre> <p>````````````````````````````````````````````````python</p>"},{"location":"xxii/2022-12-15-html-tags-study.html#inline-text-content","title":"inline text content","text":"<ul> <li>a variable could be an: <code>a, abbr, dfn, mark, ruby, var</code></li> <li> <p>there are different references to coded objects like: <code>var, code, samp</code> </p> <ul> <li>these differentiations can help an author give more semantic meaning</li> </ul> <p>dfs[5] ````````````````````````````````````````````````</p> </li> </ul>"},{"location":"xxii/2022-12-15-html-tags-study.html#inline-text-content_1","title":"inline text content","text":"<ul> <li>a variable could be an: <code>a, abbr, dfn, mark, ruby, var</code></li> <li> <p>there are different references to coded objects like: <code>var, code, samp</code> </p> <ul> <li>these differentiations can help an author give more semantic meaning</li> </ul> <p>dfs[5]</p> </li> </ul> <p>````````````````````````````````````````````````python in a literate programming, it seems possible that we layer inline tags together</p> <p>my variable is an example with layers.</p> <p>````````````````````````````````````````````````</p> <p>in a literate programming, it seems possible that we layer inline tags together</p> <p>my variable is an example with layers.</p> <p>````````````````````````````````````````````````python</p> Element Description 0 &lt;area&gt; The &lt;area&gt; HTML element defines an area inside... 1 &lt;audio&gt; The &lt;audio&gt; HTML element is used to embed soun... 2 &lt;img&gt; The &lt;img&gt; HTML element embeds an image into th... 3 &lt;map&gt; The &lt;map&gt; HTML element is used with area eleme... 4 &lt;track&gt; The &lt;track&gt; HTML element is used as a child of... 5 &lt;video&gt; The &lt;video&gt; HTML element embeds a media player... Element Description 0 &lt;embed&gt; The &lt;embed&gt; HTML element embeds external conte... 1 &lt;iframe&gt; The &lt;iframe&gt; HTML element represents a nested ... 2 &lt;object&gt; The &lt;object&gt; HTML element represents an extern... 3 &lt;picture&gt; The &lt;picture&gt; HTML element contains zero or mo... 4 &lt;portal&gt; The &lt;portal&gt; HTML element enables the embeddin... 5 &lt;source&gt; The &lt;source&gt; HTML element specifies multiple m... Element Description 0 &lt;svg&gt; The svg element is a container that defines a ... 1 &lt;math&gt; The top-level element in MathML is &lt;math&gt;. Eve..."},{"location":"xxii/2022-12-15-html-tags-study.html#multimediaembeds","title":"multimedia/embeds","text":"<p>don't forget your alt text.</p> <pre><code>return dfs[6], dfs[7], dfs[8]\n</code></pre> <p>````````````````````````````````````````````````</p>"},{"location":"xxii/2022-12-15-html-tags-study.html#multimediaembeds_1","title":"multimedia/embeds","text":"<p>don't forget your alt text.</p> <pre><code>return dfs[6], dfs[7], dfs[8]\n</code></pre>"},{"location":"xxii/2022-12-16-issue-activity-graphql.html","title":"retreiving my issue activity","text":"<p>retreive my activity with the github graphql api.</p> <pre><code>    %reload_ext pidgy\n    import requests, pandas\n    from info import header\n    __import__(\"requests_cache\").install_cache(allowable_methods=[\"POST\"])\n</code></pre>"},{"location":"xxii/2022-12-16-issue-activity-graphql.html#construct-the-query-from-parameters","title":"construct the query from parameters","text":"<p>we use <code>%</code> string formatting because of the braces in graphql syntaxes.</p> <pre><code>    def get_stamps(user=\"tonyfast\", repo=\"iota-school/notebooks-for-all\"):\n        return \\\nquery { \n  search(type:ISSUE, query: \"user:%s repo:%s\", first: 100) {\n    edges {\n      node {\n      ... on Issue {\n        url\n      }\n       ... on PullRequest {\n        url\n      }\n      ... on Comment {\n        publishedAt\n      }\n      }\n    }\n  }\n}\\\n\n            % (user, repo)\n</code></pre> <pre><code>def get_stamps(user=\"tonyfast\", repo=\"iota-school/notebooks-for-all\"):\n    return \\\n</code></pre> <p>query {    search(type:ISSUE, query: \"user:%s repo:%s\", first: 100) {     edges {       node {       ... on Issue {         url       }        ... on PullRequest {         url       }       ... on Comment {         publishedAt       }       }     }   } }\\</p> <pre><code>        % (user, repo)\n</code></pre> <pre><code>&lt;details open&gt;\n    &lt;summary&gt;\na graphql query the find the dates a user made comments on issues or pull requests.\n    &lt;/summary&gt;\n\n\n```graphql\n{{get_stamps()}}\n```\n\n&lt;/details&gt;\n</code></pre>  a graphql query the find the dates a user made comments on issues or pull requests.      <pre><code>query { \n  search(type:ISSUE, query: \"user:tonyfast repo:iota-school/notebooks-for-all\", first: 100) {\n    edges {\n      node {\n      ... on Issue {\n        url\n      }\n       ... on PullRequest {\n        url\n      }\n      ... on Comment {\n        publishedAt\n      }\n      }\n    }\n  }\n}\n</code></pre> <pre><code>    df = pandas.DataFrame((\n        response := requests.post(\"https://api.github.com/graphql\", json=dict(query=get_stamps()), **header)\n    ).json()[\"data\"][\"search\"][\"edges\"])[\"node\"].apply(pandas.Series)\n    df.publishedAt = df.publishedAt.pipe(pandas.to_datetime)\n</code></pre> <pre><code>df = pandas.DataFrame((\n    response := requests.post(\"https://api.github.com/graphql\", json=dict(query=get_stamps()), **header)\n).json()[\"data\"][\"search\"][\"edges\"])[\"node\"].apply(pandas.Series)\ndf.publishedAt = df.publishedAt.pipe(pandas.to_datetime)\n</code></pre> <pre><code>    freq = df.groupby(pandas.Grouper(freq=\"1D\", key=\"publishedAt\")).count()\n</code></pre> <pre><code>freq = df.groupby(pandas.Grouper(freq=\"1D\", key=\"publishedAt\")).count()\n</code></pre> <p>what days where these comments made at?</p> <pre><code>    days = freq[freq.astype(bool)].dropna()\n    days\n</code></pre> url publishedAt 2015-08-07 00:00:00+00:00 1.0 2016-01-02 00:00:00+00:00 2.0 2016-01-03 00:00:00+00:00 3.0 2016-01-11 00:00:00+00:00 1.0 2016-01-23 00:00:00+00:00 1.0 ... ... 2022-11-08 00:00:00+00:00 2.0 2022-11-16 00:00:00+00:00 1.0 2022-11-21 00:00:00+00:00 1.0 2022-11-22 00:00:00+00:00 1.0 2022-12-14 00:00:00+00:00 1.0 <p>64 rows \u00d7 1 columns</p> <pre><code>days = freq[freq.astype(bool)].dropna()\ndays\n</code></pre> <pre><code>    days\n</code></pre> url publishedAt 2015-08-07 00:00:00+00:00 1.0 2016-01-02 00:00:00+00:00 2.0 2016-01-03 00:00:00+00:00 3.0 2016-01-11 00:00:00+00:00 1.0 2016-01-23 00:00:00+00:00 1.0 ... ... 2022-11-08 00:00:00+00:00 2.0 2022-11-16 00:00:00+00:00 1.0 2022-11-21 00:00:00+00:00 1.0 2022-11-22 00:00:00+00:00 1.0 2022-12-14 00:00:00+00:00 1.0 <p>64 rows \u00d7 1 columns</p> <pre><code>days\n</code></pre> <pre><code>\n</code></pre>"},{"location":"xxii/2022-12-17-find-dependencies-in-content.html","title":"automating blog posts to work with jupyter-lite","text":"<p>there is a rare occasion that i write notebooks completely in lite. most often i write in a conventional environment then need to ammend the content to work when we are in jupyterlite.</p> <pre><code>    %reload_ext pidgy\n</code></pre> <pre><code>%reload_ext pidgy\n</code></pre> <pre><code>## what do we need to do to make a post work in lite?\n\n* explicitly defined dependencies.\n\n    working on a virtual file system is different than your standard file system.\n    normally we don't have to define our environment each time,\n    but independent of a real file system - in the browser - we need to install packages each time.\n\n* patching shit\n\n    if we use requests then we should used https://github.com/koenvo/pyodide-http\n\n* dealing with `pidgy` and extensions.\n\n* some packages won't work in lite so we will throw a warning when we know this fo\n\n\n    we can infer this information or provide it explicitly in the metadata\n</code></pre>"},{"location":"xxii/2022-12-17-find-dependencies-in-content.html#what-do-we-need-to-do-to-make-a-post-work-in-lite","title":"what do we need to do to make a post work in lite?","text":"<ul> <li> <p>explicitly defined dependencies.</p> <p>working on a virtual file system is different than your standard file system. normally we don't have to define our environment each time, but independent of a real file system - in the browser - we need to install packages each time.</p> </li> <li> <p>patching shit</p> <p>if we use requests then we should used https://github.com/koenvo/pyodide-http</p> </li> <li> <p>dealing with <code>pidgy</code> and extensions.</p> </li> <li> <p>some packages won't work in lite so we will throw a warning when we know this fo</p> <p>we can infer this information or provide it explicitly in the metadata</p> </li> </ul> <pre><code>sometimes i forget imports\n</code></pre> <p>sometimes i forget imports</p> <pre><code>## [`depfinder`](https://github.com/ericdill/depfinder) to find packages in a notebook for python\n\nsome of my personal style choices might fail like when i use `__import__`, maybe this is a way to cut dependencies from the list.\n</code></pre>"},{"location":"xxii/2022-12-17-find-dependencies-in-content.html#depfinder-to-find-packages-in-a-notebook-for-python","title":"<code>depfinder</code> to find packages in a notebook for python","text":"<p>some of my personal style choices might fail like when i use <code>__import__</code>, maybe this is a way to cut dependencies from the list.</p> <pre><code>    from pathlib import Path\n    import depfinder, pandas\n    __import__(\"requests_cache\").install_cache()\n</code></pre> <pre><code>from pathlib import Path\nimport depfinder, pandas\n__import__(\"requests_cache\").install_cache()\n</code></pre> <pre><code>    def get_files(dir=\"\", glob=\"*.ipynb\") -&gt; pandas.Index:\n        return pandas.Index(Path(dir).rglob(glob)).rename(\"files\")\n</code></pre> <pre><code>def get_files(dir=\"\", glob=\"*.ipynb\") -&gt; pandas.Index:\n    return pandas.Index(Path(dir).rglob(glob)).rename(\"files\")\n</code></pre> <pre><code>    def get_cells(files: pandas.Index) -&gt; pandas.DataFrame:\n        df = (\n            files.to_series().apply(Path.read_text)\n            .apply(json.loads).apply(pandas.Series)\n            .cells.apply(pandas.Series).stack().apply(pandas.Series)\n        )\n        return df.join(get_has_pidgy(df))\n</code></pre> <pre><code>def get_cells(files: pandas.Index) -&gt; pandas.DataFrame:\n    df = (\n        files.to_series().apply(Path.read_text)\n        .apply(json.loads).apply(pandas.Series)\n        .cells.apply(pandas.Series).stack().apply(pandas.Series)\n    )\n    return df.join(get_has_pidgy(df))\n</code></pre>"},{"location":"xxii/2022-12-17-find-dependencies-in-content.html#can-haz-pidgy","title":"can haz pidgy?","text":"<p>some of these posts are in <code>pidgy</code>, i'll use <code>%reload_ext pidgy</code> when that is the situation. peek in the <code>cells</code> to find <code>pidgy</code> notebooks.</p> <pre><code>    def get_has_pidgy(cells):\n        return cells[cells.cell_type.eq(\"code\")].source.apply(\"\".join).groupby(\n            pandas.Grouper(level=0)\n        ).apply(lambda df: df.str.contains(\"%[re]*load_ext pidgy\").any()).rename(\"pidgy\")\n</code></pre> <pre><code>def get_has_pidgy(cells):\n    return cells[cells.cell_type.eq(\"code\")].source.apply(\"\".join).groupby(\n        pandas.Grouper(level=0)\n    ).apply(lambda df: df.str.contains(\"%[re]*load_ext pidgy\").any()).rename(\"pidgy\")\n</code></pre> <pre><code>    cells = get_cells(get_files())\n</code></pre> <pre><code>cells = get_cells(get_files())\n</code></pre> <pre><code>### get the imports\n    def get_import(row: pandas.Series) -&gt; dict:\n`get_import` normalizes the cell source code for analysis by `depfinder`.\nthis method catches those situations or returns the attributes of `depfinder.inspection.ImportFinder`\n\n        source = \"\".join(row.source)\n        if row.pidgy:\n            source = midgy.python.Python().render(source)\n        try:\n            return vars(depfinder.inspection.get_imported_libs(textwrap.dedent(source), row.name[0]))\n        except BaseException as e:\n            return None\n</code></pre>"},{"location":"xxii/2022-12-17-find-dependencies-in-content.html#get-the-imports","title":"get the imports","text":"<pre><code>def get_import(row: pandas.Series) -&gt; dict:\n</code></pre> <p><code>get_import</code> normalizes the cell source code for analysis by <code>depfinder</code>. this method catches those situations or returns the attributes of <code>depfinder.inspection.ImportFinder</code></p> <pre><code>    source = \"\".join(row.source)\n    if row.pidgy:\n        source = midgy.python.Python().render(source)\n    try:\n        return vars(depfinder.inspection.get_imported_libs(textwrap.dedent(source), row.name[0]))\n    except BaseException as e:\n        return None\n</code></pre>"},{"location":"xxii/2022-12-17-find-dependencies-in-content.html#evaluate-the-sources","title":"evaluate the sources","text":"<pre><code>    import depfinder, pandas, midgy\n    __import__(\"requests_cache\").install_cache()\n    \u00d8 = __name__ == \"__main__\" and \"__file__\" not in locals()\n</code></pre> <pre><code>import depfinder, pandas, midgy\n__import__(\"requests_cache\").install_cache()\n\u00d8 = __name__ == \"__main__\" and \"__file__\" not in locals()\n</code></pre> <pre><code>    def get_modules(cells):\n        return (\n            (\n                results:=\n                cells[cells.cell_type.eq(\"code\")].apply(get_import, axis=1)\n                .dropna().apply(functools.partial(pandas.Series, dtype=\"O\"))\n            )[results.columns[results.columns.str.endswith(\"_modules\")]]\n        )\n</code></pre> <pre><code>def get_modules(cells):\n    return (\n        (\n            results:=\n            cells[cells.cell_type.eq(\"code\")].apply(get_import, axis=1)\n            .dropna().apply(functools.partial(pandas.Series, dtype=\"O\"))\n        )[results.columns[results.columns.str.endswith(\"_modules\")]]\n    )\n</code></pre> <p>a snapshot of the modules import within the content</p> <pre><code>    if \u00d8:\n        (cells := get_cells(get_files()))\n        (cells := cells.join(get_modules(cells)))\n        modules = cells[cells.columns[cells.columns.str.endswith(\"_modules\")]]\n        modules = modules.stack().apply(list).apply(pandas.Series, dtype=\"O\").stack()\n        return HTML(modules.value_counts().to_frame().T.to_html())\n</code></pre> pandas pathlib requests tonyfast IPython json midgy functools toolz re depfinder shlex importnb dataclasses typer pidgy nbconvert ipywidgets info textwrap typing traitlets doit dask pluggy sys requests_cache jsonref playwright nbformat inspect types ast uritemplate __ jinja2 numpy io gc pyld orjson jsonpointer urllib.parse linecache operator poser matplotlib rich mpl_toolkits importlib anyio unittest.mock __static_notebook_tags nbconvert_html5 bs4 mkdocs icalendar yaml hvplot jupyter_core shutil arrow __11_12_async_import doctest unittest __09_pyproject_analysis html tomli pytest __12_09_pyproject_analysis warnings _022_10_21_markdown_future a_little_markdown_program click markdown sympy __better_dask_shape asyncio dis traceback micropip __pycache__ ibis duckdb pyarrow nest_asyncio collections abc tqdm 0 41 30 14 14 14 13 12 12 11 10 10 7 7 7 7 6 6 6 6 6 6 5 5 5 5 5 5 5 5 5 4 4 4 4 4 4 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 <pre><code>if \u00d8:\n    (cells := get_cells(get_files()))\n    (cells := cells.join(get_modules(cells)))\n    modules = cells[cells.columns[cells.columns.str.endswith(\"_modules\")]]\n    modules = modules.stack().apply(list).apply(pandas.Series, dtype=\"O\").stack()\n    return HTML(modules.value_counts().to_frame().T.to_html())\n</code></pre>"},{"location":"xxii/2022-12-17-find-dependencies-in-content.html#todo","title":"todo","text":"<ul> <li>inject the imports back into the notebooks. where though?</li> <li>find magics</li> </ul>"},{"location":"xxii/2022-12-18-mkdocs-task.html","title":"<code>doit</code> integration - a <code>mkdocs</code> example","text":"<p>in the hunt for a computable blog, i've wanted to be able to reuse the code i write about in posts. one integration we are beginning to experiment with in this post is access to <code>doit</code> task specifications  from posts. the <code>tonyfast.dodo</code> module integrates posts with tasks.</p> <p><code>doit</code> is a great tool for orchestrating commands that operate on files. to demonstrate the integration we'll compose a task to build a <code>mkdocs</code> site, and deal with some pain points in the configuration.</p>"},{"location":"xxii/2022-12-18-mkdocs-task.html#the-mkdocs-task","title":"the <code>mkdocs</code> task","text":"<p><code>mkdocs</code> integrations are identified when a project has the <code>mkdocs.yml</code> file. this file contains all the information for your site including the documents to build. for blog style content, adding a new post means updating the configuration file. my adhd brain has a tendency to forget the configuration bit. in this file, we wrote tools to infer the files that should be included in the configuration, we sort them, and place them back in the configuration file.</p> <p>what follow is the incovation for <code>mkdocs</code> for the <code>tonyfast</code> site. in this document we:</p> <ul> <li>define functions to find posts</li> <li>define a <code>doit</code> task to execute <code>mkdocs</code></li> </ul> <p>there is a <code>mkdocs-material</code> blog feature avaiable to insiders. when this is generally available a lot of this content will be moot.</p>"},{"location":"xxii/2022-12-18-mkdocs-task.html#the-mkdocs-doit-task","title":"the <code>mkdocs</code> <code>doit</code> task","text":"<p>primarily <code>doit</code> tasks are functions that begin with the prefix <code>task_</code>; <code>task_mkdocs</code> is the one task we define in this document.</p> <p>find posts and build the mkdocs site</p> <pre><code>    def task_mkdocs():\n        yield dict(name=\"toc\", actions=[\n            (set_nav, (pathlib.Path(\"tonyfast\"), \"*.ipynb\", \"mkdocs.yml\"))\n        ], targets=[\"mkdocs.yml\"], uptodate=[False])\n        yield dict(\n            name=\"build\",\n            actions=[\"mkdocs build\"],\n            file_dep=[\"mkdocs.yml\"],\n            targets=[\"site/index.html\"]\n        )\n</code></pre>"},{"location":"xxii/2022-12-18-mkdocs-task.html#finding-and-sorting-the-posts","title":"finding and sorting the posts","text":"<p>find all the potential notebook posts</p> <pre><code>    def get_posts_from_dir(dir, glob=\"*.ipynb\"):\n        for file in dir.iterdir():\n            if file.is_dir():\n                if \"checkpoints\" not in file.name: yield from get_posts_from_dir(file, glob)\n            elif file.suffix in {\".ipynb\"}:\n                if (m := title.match(str(file.stem))): yield file, m\n\n    def get_posts(dir, glob=\"*.ipynb\"):\n        return sorted((\n            (x.relative_to(WHERE), y) for x, y in get_posts_from_dir(dir, glob)\n        ), reverse=True, key=lambda x: x[1].group(*\"ymd\"))\n</code></pre> <p>format the ordered entries</p> <pre><code>    def get_toc(dir, glob=\"*.ipynb\"):\n        for x, y in list(get_posts(WHERE, glob)):\n            yield \" \"* 4 + F\"- {x}\" \n</code></pre> <p>we don't use <code>yaml</code> cause our <code>mkdocs</code> uses <code>yaml</code>  tags. instead we put the nav at the end of the document then replace the default with the updated version.</p>"},{"location":"xxii/2022-12-18-mkdocs-task.html#replace-the-nav","title":"replace the nav","text":"<pre><code>    def get_nav(dir, glob=\"*.ipynb\"):\n        return \"\".join(re.split(\n            \"(notes\\S*:\\S*)\",\n            (WHERE.parent / \"mkdocs.yml\").read_text(),\n            1\n        )[:2] )+ \"\\n\" + \"\\n\".join(get_toc(dir, glob))\n\n    import tonyfast, pathlib, yaml, re\n    WHERE = pathlib.Path(tonyfast.__file__).parent\n    title = re.compile(\"(?P&lt;y&gt;[0-9]{4})-(?P&lt;m&gt;[0-9]{1,2})-(?P&lt;d&gt;[0-9]{1,2})-(?P&lt;t&gt;.+)\")\n\n    def set_nav(dir, glob=\"*.ipynb\", target=WHERE.parent / \"mkdocs.yml\"):\n        pathlib.Path(target).write_text(get_nav(pathlib.Path(dir), glob))\n</code></pre>"},{"location":"xxii/2022-12-18-mkdocs-task.html#invocation","title":"invocation","text":"<ul> <li> <p>the task is exposed in the <code>tonyfast</code> module</p> <p>python -m tonyfast tasks mkdocs</p> </li> <li> <p>this command is invoked with <code>hatch</code> in a virtual environment using:</p> <p>hatch run docs:build</p> </li> <li> <p>use with <code>importnb -t</code></p> </li> </ul> <pre><code>    if \"__file__\" not in locals():\n        !python -m importnb -t 2022-12-18-mkdocs-task.ipynb info mkdocs\n</code></pre> <pre>\nmkdocs\n\nfind posts and build the mkdocs site\n\nstatus     : run\n * The task has no dependencies.\n\ntask_dep   : \n - mkdocs:toc\n - mkdocs:build\n</pre>"},{"location":"xxii/2022-12-19-integrating-typer.html","title":"integrating <code>typer</code> into the blog","text":"<p>in this blog, posts are programs and they are designed to be reused in python. that means that we want to be able to reuse code and narrative as much as possible. </p> <ul> <li>add command to main</li> </ul> <pre><code>    IMPORTED,MAIN = \"__file__\" in locals(),  __name__ == \"__main__\"; \u00d8 = not IMPORTED and MAIN\n</code></pre>"},{"location":"xxii/2022-12-19-integrating-typer.html#a-small-example","title":"a small example","text":"<p>the first example we'll describe is a simple function with little consequence. this will validate our integration.</p> <pre><code>    def main(greeting: str = \"howdy\", name: str=\"tony\"):\n\"\"\"a nothing function that says hi to the audience\"\"\"\n        print(greeting, name)\n</code></pre> <p>invoking the command line</p> <pre><code>    if \u00d8:\n        !python -m tonyfast\n</code></pre> <pre>                                                                                Usage: python -m tonyfast [OPTIONS] COMMAND [ARGS]...                         \n\u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --help  -h        Show this message and exit.                                \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 hello     a nothing function that says hi to the audience                    \u2502\n\u2502 tasks     run doit tasks                                                     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\n</pre> <pre><code>    if \u00d8:\n        !python -m tonyfast hello --name y\\'all\n</code></pre> <pre>howdy y'all\n</pre> <p>this is a nice example to start with because it allows us to consider what our works look like as literature.</p>"},{"location":"xxii/2022-12-19-integrating-typer.html#a-more-complex-example","title":"a more complex example","text":"<p>in a recent post, we made it possible add <code>doit</code> tasks to the blog.</p> <pre><code>    from typer import Typer, Context\n    app= Typer(rich_markup_mode=\"rich\")\n\n    @app.command(context_settings={\"allow_extra_args\": True, \"ignore_unknown_options\": True})\n    def tasks(ctx: Context):\n\"\"\"run doit tasks\"\"\"\n        from doit.doit_cmd import DoitMain\n        from doit.cmd_base import ModuleTaskLoader\n        from tonyfast import dodo\n\n        return DoitMain(ModuleTaskLoader(dodo)).run(ctx.args)\n</code></pre> <p>verifying the <code>doit</code> commands</p> <pre><code>    if \u00d8:\n        !python -m tonyfast tasks list --status --all\n</code></pre> <pre>R mkdocs         build document with mkdocs\nR mkdocs:build   \nR mkdocs:toc     \n</pre>"},{"location":"xxii/2022-12-19-integrating-typer.html#invoking-this-document-as-a-standalone-script","title":"invoking this document as a standalone script","text":"<pre><code>    if IMPORTED and MAIN:\n        app.command(name=\"hello\")(main)\n        app()\n</code></pre> <pre><code>    if \u00d8:\n        !importnb 2022-12-19-integrating-typer.ipynb --help\n</code></pre> <pre>                                                                                Usage: 2022-12-19-integrating-typer.ipynb [OPTIONS] COMMAND [ARGS]...         \n\u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --install-completion          Install completion for the current shell.      \u2502\n\u2502 --show-completion             Show completion for the current shell, to copy \u2502\n\u2502                               it or customize the installation.              \u2502\n\u2502 --help                        Show this message and exit.                    \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 hello     a nothing function that says hi to the audience                    \u2502\n\u2502 tasks     run doit tasks                                                     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\n</pre>"},{"location":"xxii/2022-12-20-pyscript-nbconvert.html","title":"rendering a notebook with <code>pyscript</code>","text":"<p>let's convert a notebook to a pyscript document.</p> <p>we'll using <code>nbconvert and jinja2</code> to transform a notebook into a standalone interactive document.</p>"},{"location":"xxii/2022-12-20-pyscript-nbconvert.html#jinja2-template-overrides-for-nbconvert","title":"<code>jinja2</code> template overrides for <code>nbconvert</code>","text":"<p>our pyscript extends the base jupyterlab styling.</p> <pre><code>    template = \"\"\"\n    {%- extends 'lab/index.html.j2' -%}\"\"\"\n</code></pre> <p>include pyscript css and javascript assets in the <code>&lt;head&gt;</code></p> <pre><code>    template += \"\"\"\n    {%- block header -%}\n    {{super()}}\n    &lt;link rel=\"stylesheet\" href=\"https://pyscript.net/latest/pyscript.css\" /&gt;\n    &lt;script defer src=\"https://pyscript.net/latest/pyscript.js\"&gt;&lt;/script&gt;\n    {%- endblock header -%}\"\"\"\n</code></pre> <p>requirejs and pyscript do not play well together, and the block below prevents requirejs from loading.</p> <pre><code>    template += \"\"\"\n    {%- block html_head_js -%}\n    {%- endblock html_head_js -%}\"\"\"\n</code></pre> <p>from a notebook's source we can infer the packages it needs to run. the packages are placed in the <code>&lt;py-config&gt;</code> tag. </p> <p>continue reading to see how the <code>get_imports_from_cells</code> filter is defined.</p> <pre><code>    template += \"\"\"\n    {% block body_header %}   \n    {{super()}}\n    &lt;py-config&gt;\n    packages = {{nb | get_imports_from_cells}}\n    &lt;/py-config&gt;\n    {% endblock body_header %}\"\"\"\n</code></pre> <p>we'll replace standard pygments cell inputs with a <code>&lt;py-repl&gt;</code> with autogenerate disabled.</p> <pre><code>    template += \"\"\"\n    {% block input %}\n    &lt;py-repl output=\"out-{{cell.id}}\"&gt;\n    {{cell.source | escape | dedent}}\n    &lt;/py-repl&gt;\n    {% endblock input %}\"\"\"\n</code></pre> <p>we use any existing outputs as the dead pixels. the outputs are replaced the first pyscript executes in a nearby cell.</p> <pre><code>    template += \"\"\"\n    {% block output %}\n    &lt;div id=\"out-{{cell.id}}\"&gt;{{super()}}&lt;/div&gt;\n    {% endblock output %}\n\n    {% block codecell %}\n    {{super()}}\n    {% if not cell.outputs %}\n    &lt;div id=\"out-{{cell.id}}\"&gt;&lt;/div&gt;\n    {% endif %}\n    {% endblock codecell %}\n    \"\"\"\n</code></pre> <p>our <code>template</code> is defined for<code>&lt;py-script&gt;</code> documents. next we introduce <code>template</code> into the <code>nbconvert</code> machinery.</p>"},{"location":"xxii/2022-12-20-pyscript-nbconvert.html#nbconvert-exporting-machinery","title":"<code>nbconvert</code> exporting machinery","text":"<p><code>nbconvert</code> is the primary machinery used to transform notebook documents into other file formats. it is a wrapper around the shape of the notebook and a <code>jinja2</code> environment.</p> <pre><code>    import depfinder; from pathlib import Path; from functools import partial\n    from nbconvert.exporters import HTMLExporter, TemplateExporter\n</code></pre>"},{"location":"xxii/2022-12-20-pyscript-nbconvert.html#inferring-dependencies","title":"inferring dependencies","text":"<p>the <code>py-config</code> defines the environment. we use <code>depfinder</code> to do that.</p> <pre><code>    def get_imports_from_cells(nb):\n        imports = set()\n        for cell in nb.cells:\n            imports.update(get_imports_from_cell(cell))\n        if imports.intersection({\"requests\", \"httpx\", \"urllib\"}): # add more later\n            imports.add(\"pyodide-http\")\n        return list(imports)\n\n    def get_imports_from_cell(cell):\n        import depfinder\n        __import__(\"requests_cache\").install_cache()        \n        if cell[\"cell_type\"] == \"code\":\n            try:\n                yield from depfinder.inspection.get_imported_libs(textwrap.dedent(\"\".join(cell[\"source\"]))).required_modules\n            except BaseException as e:\n                pass\n</code></pre>"},{"location":"xxii/2022-12-20-pyscript-nbconvert.html#the-nbconvert-exporter","title":"the <code>nbconvert</code> exporter","text":"<p><code>get_exporter</code> generates a new notebook file converter.</p> <ul> <li>adds filters used in <code>template</code></li> <li>puts a template on the <code>jinja2.DictLoader</code> with our custom template</li> </ul> <pre><code>    def get_exporter(template=template):\n        import textwrap, html, jinja2\n        exporter = HTMLExporter(\n            template_file=\"pyscript.j2\", filters=dict(\n                dedent=textwrap.dedent, get_imports_from_cells=get_imports_from_cells, escape=html.escape\n            )\n        )\n        for loader in exporter.environment.loader.loaders:\n            if isinstance(loader, jinja2.DictLoader):\n                loader.mapping[\"pyscript.j2\"] = template\n        return exporter\n</code></pre>"},{"location":"xxii/2022-12-20-pyscript-nbconvert.html#pyscript-transformation-functions","title":"<code>pyscript</code> transformation functions","text":"<p><code>get_pyscript</code> turns a file into a string of py-script html.</p> <pre><code>    def get_pyscript(file): return get_exporter(template).from_filename(file)[0]\n</code></pre> <p><code>pyscript</code> transforms a file and writes the py-script document to disk.</p> <pre><code>    def pyscript(file: Path, target: Path = None, write: bool=True):\n\"\"\"generate a pyscript version of a notebook\"\"\"\n        body = get_pyscript(file)\n        if write:\n            if not target:\n                target = file.with_suffix(F\"{file.suffix}.html\")\n            target.write_text(body)\n            print(F\"created {target}\")               \n</code></pre> <pre><code>    if __name__ == \"__main__\" and \"__file__\" not in locals():\n        !python -m tonyfast pyscript 2022-12-19-integrating-typer.ipynb\n\n        from IPython.display import display, IFrame\n        display(IFrame(*\"2022-12-19-integrating-typer.ipynb.html 100% 600\".split()))\n</code></pre> <pre>created 2022-12-19-integrating-typer.ipynb.html\n</pre> <pre><code>\n</code></pre>"},{"location":"xxii/2022-12-21-lite-build.html","title":"<code>jupyterlite</code> blog integration","text":"<p>i've always thought of blog posts as a means, not an ends. my dream has always been content that myself and others can execute themselves. often this goal has been hindered by the need for infrastructure. advances in the <code>jupyterlite</code> have made it possible to realize this vision without infrastructure.</p> <p><code>jupyterlite</code> is jupyterlab running completely in the browser without the need for a local server. this means that folks can redirect from a static post into an interactive version they can try themselves.</p>"},{"location":"xxii/2022-12-21-lite-build.html#jupyterlite-notebooks-are-different","title":"<code>jupyterlite</code> notebooks are different","text":"<p>when working with a standard jupyter implementation we are interacting with a server within an implicit environment. when we write our notebooks we assume that we can import modules because they are in our environment. however, in <code>jupyterlite</code> we need to explicitly define our dependencies for every notebook.</p> <p>we define our dependencies by inserting the <code>pip</code> line magic:</p> <pre><code>%pip install my dependencies\n</code></pre> <p>this statement is superfluous under normal circumstances so it doesn't need to exist in the source. instead we use the <code>depfinder</code> project to infer the projects imported by our notebook. the inferred dependencies are then inserted in to the first line of the first code cell of the notebook.</p>"},{"location":"xxii/2022-12-21-lite-build.html#the-doit-lite-implementation","title":"the <code>doit lite</code> implementation","text":"<p>in the code that follow we define a <code>doit</code> task that: 1. builds a <code>jupyterlite</code> site for this blog 2. make the dependencies compatible with <code>jupyterlite</code></p> <pre><code>    def task_lite():\n\"\"\"build the jupyter lite site and append requirements\"\"\"\n        return dict(\n            actions=[\n                \"jupyter lite build --contents tonyfast --output-dir site/run\",\n                (set_files_imports, (pathlib.Path(\"site/run/files\"),))\n            ],\n            clean=[\"rm -rf site/run\"]\n        )\n\n    import typing, tonyfast, pathlib, textwrap, re, json\n</code></pre>"},{"location":"xxii/2022-12-21-lite-build.html#discovering-imports-with-depfinder","title":"discovering imports with <code>depfinder</code>","text":"<p>following sections we'll build the methods for discovering imports with <code>depfinder</code></p> <p><code>set_files_imports</code> iterates through a directory and amends notebooks to work in <code>jupyterlite</code></p> <pre><code>    def set_files_imports(FILES: typing.Iterable[pathlib.Path]=(\n        FILES := (WHERE := pathlib.Path(tonyfast.__file__).parent.parent) / \"site/run/files\"\n    )) -&gt; None:\n        for file in FILES.rglob(\"*.ipynb\"):  set_file_imports(file)\n</code></pre> <p><code>get_imports</code> finds the imports in each cell</p> <pre><code>    def get_imports(cell: dict, pidgy=False) -&gt; set:\n        import depfinder\n        __import__(\"requests_cache\").install_cache()\n        source = \"\".join(cell[\"source\"])\n        if pidgy:\n            source = tangle.render(source)\n        source = textwrap.dedent(source)\n        try:\n            found = depfinder.inspection.get_imported_libs(source)\n            return found.required_modules.union(found.sketchy_modules)\n        except BaseException as e:\n            return\n</code></pre> <p><code>get_deps</code> transforms inputs to dependencies.</p> <p>some dependencies may require extra features to work in <code>jupyterlite</code> and they are appended here.</p> <pre><code>    mapping = dict(bs4=\"beautifulsoup4\")\n    def get_deps(deps: set) -&gt; set:\n        if \"requests\" in deps: deps.add(\"pyodide-http\")\n        if \"pandas\" in deps: deps.add(\"jinja2\")\n        return {\n            mapping.get(x, x) for x in deps \n            if not x.startswith(\"_\") or x not in {\"tonyfast\"}\n        }\n</code></pre>"},{"location":"xxii/2022-12-21-lite-build.html#handling-pidgy-documents","title":"handling <code>pidgy</code> documents","text":"<p>some documents might use [pidgy] syntax that need to be dealt with.</p> <pre><code>    PIDGY = re.compile(\"^\\s*%(re)?load_ext\\s*pidgy\")\n    from midgy import Python; tangle = Python()\n    def has_pidgy(nb: dict):\n        yes = False\n        for _, cell in iter_code_cells(nb):\n            yes = yes or PIDGY.match(\"\".join(cell[\"source\"])) and True\n        return yes\n</code></pre>"},{"location":"xxii/2022-12-21-lite-build.html#updating-the-jupyterlite-notebooks","title":"updating the <code>jupyterlite</code> notebooks","text":"<p>these methods are meant to operate on the contents of a <code>jupyterlite</code> not the raw notebooks.</p> <p><code>set_file_imports</code> operates in one file discovers dependencies and writes code back to the source.</p> <pre><code>    def set_file_imports(file: pathlib.Path) -&gt; None:\n        data = json.loads(file.read_text())\n        deps, first = set(), None\n        pidgy = has_pidgy(data)\n        for no, cell in iter_code_cells(data):\n            if first is None:\n                first = no\n            if pidgy:\n                data[\"cells\"][no][\"metadata\"].setdefault(\"jupyter\", {})[\"source_hidden\"] = True\n            deps.update(get_imports(cell, pidgy) or [])\n\n        deps = get_deps(deps)\n        if pidgy:\n            deps.add(\"pidgy\")\n        if deps and (first is not None):\n            cell = data[\"cells\"][first]\n            was_str = isinstance(cell[\"source\"], str)\n            if was_str:\n                cell[\"source\"] = cell[\"source\"].splitlines(1)\n            for i, line in enumerate(list(cell[\"source\"])):\n                if (left := line.lstrip()):\n                    if left.startswith((\"%pip install\",)):\n                        break\n                    indent = len(line) - len(left)                    \n                    if \"pyodide-http\" in deps:\n                        data[\"cells\"][first][\"source\"].insert(i, \" \"*indent + \"__import__('pyodide_http').patch_all()\\n\")\n                    data[\"cells\"][first][\"source\"].insert(i, \" \"*indent + \"%pip install \" + \" \".join(deps) +\"\\n\")\n                    print(F\"writing {len(set(deps))} pip requirements to {file}\")\n                    file.write_text(json.dumps(data, indent=2))\n                    break\n        else:\n            print(F'no deps for {file}')\n</code></pre> <p><code>set_files_imports</code> sets the dependencies for a lot of files.</p> <pre><code>    def set_files_imports(FILES: typing.Iterable[pathlib.Path]=FILES):\n        for file in FILES.rglob(\"*.ipynb\"):\n            set_file_imports(file)\n</code></pre> <p><code>iter_code_cells</code> iterates through just the code cells.</p> <pre><code>    def iter_code_cells(nb: dict) -&gt; typing.Iterator[tuple[int, dict]]:\n        for i, cell in enumerate(nb[\"cells\"]):\n            if cell[\"cell_type\"] == \"code\":\n                yield i, cell\n</code></pre>"},{"location":"xxii/2022-12-21-lite-build.html#usage","title":"usage","text":"<ul> <li>from the <code>tonyfast</code> module, requires deps</li> </ul> <pre><code>    if (I := '__file__' not in locals()):\n        !python -m tonyfast tasks info lite\n</code></pre> <pre>\nlite\n\nbuild the jupyter lite site and append requirements\n\nstatus     : run\n * The task has no dependencies.\n</pre> <ul> <li>from post with <code>importnb</code></li> </ul> <pre><code>    if (I := '__file__' not in locals()):\n        !importnb -t 2022-12-21-lite-build.ipynb list\n</code></pre> <pre>lite   build the jupyter lite site and append requirements\n</pre> <ul> <li>run this task from <code>hatch</code> in the root of the project. the <code>hatch</code> environment has all the necessary dependencies defined.<pre><code>hatch run lite:build\n</code></pre> </li> </ul>"},{"location":"xxii/2022-12-22-pyproject-analysis.html","title":"analyzing <code>pyproject.toml</code> configurations of popular projects","text":"<p><code>get_pyproject_config_data</code> loads a dataframe created in a previous post. it contains the results of a graphql query to posted to the github api that returnsthe pyproject files for some of the most popular python projects on github.</p> <pre><code>    def get_pyproject_config_data() -&gt; \"pandas.DataFrame\":\n        with importnb.Notebook(): from __09_pyproject_analysis import tidy_configs, tidy_responses, gather, pyproject_query \n        return tidy_configs(df := tidy_responses(responses := gather(pyproject_query, max=15)))\n</code></pre> <p>the shape of our dataframe - <code>df</code> from <code>get_pyproject_config_data</code> - is:</p> <ul> <li>on the rows: one project per row</li> <li>on the columns: the keys found in the projects <code>pyproject.toml</code></li> </ul> <pre><code>    import importnb, pandas\n    display((df := get_pyproject_config_data()).head(3))\n    F\"there are {len(df)} `pyproject.toml` files in the dataset.\"\n</code></pre> tool build-system project mypy flake8 url https://github.com/open-telemetry/opentelemetry-python {'black': {'line-length': 79, 'exclude': '(   /(  # generated files     .tox|     venv|     .*/build/lib/.*|     exporter/opentelemetry-exporter-jaeger-proto-grpc/src/opentelemetry/exporter/jaeger/proto/grpc/gen|     exporter/opentelemetry-exporter-jaeger-thrift/src/opentelemetry/exporter/jaeger/thrift/gen|     exporter/opentelemetry-exporter-zipkin-proto-http/src/opentelemetry/exporter/zipkin/proto/http/v2/gen|     opentelemetry-proto/src/opentelemetry/proto/.*/.*|     scripts   )/ ) '}, 'pytest': {'ini_options': {'addopts': '-rs -v', 'log_cli': True, 'log_cli_level': 'warning'}}} NaN NaN NaN NaN https://github.com/freemocap/freemocap {'taskipy': {'tasks': {'setup': 'pre-commit install', 'test': 'python -m unittest src/tests/**/test_*', 'installer': './bin/installer.sh', 'format': 'black src/'}}} NaN NaN NaN NaN https://github.com/3b1b/manim NaN {'requires': ['setuptools', 'wheel']} NaN NaN NaN <pre>'there are 234 `pyproject.toml` files in the dataset.'</pre>"},{"location":"xxii/2022-12-22-pyproject-analysis.html#what-tools-are-used-most","title":"what tools are used most?","text":"<p>PEPXXX defines the <code>tool</code> key as a place that third party applications can store configuration information.</p> <p>when we explode the <code>df.tool</code> in <code>tools</code> we find a frame with all the third party tools named.</p> <pre><code>    (tools := df.tool.dropna().apply(pandas.Series)).head(3).fillna(\"\")\n</code></pre> black pytest taskipy pyright hatch isort mutmut check-wheel-contents flit coverage ... jupyter-releaser check-manifest vendoring commitizen scriv autoflake tbump autopub poetry-version-plugin typeshed url https://github.com/open-telemetry/opentelemetry-python {'line-length': 79, 'exclude': '(   /(  # generated files     .tox|     venv|     .*/build/lib/.*|     exporter/opentelemetry-exporter-jaeger-proto-grpc/src/opentelemetry/exporter/jaeger/proto/grpc/gen|     exporter/opentelemetry-exporter-jaeger-thrift/src/opentelemetry/exporter/jaeger/thrift/gen|     exporter/opentelemetry-exporter-zipkin-proto-http/src/opentelemetry/exporter/zipkin/proto/http/v2/gen|     opentelemetry-proto/src/opentelemetry/proto/.*/.*|     scripts   )/ ) '} {'ini_options': {'addopts': '-rs -v', 'log_cli': True, 'log_cli_level': 'warning'}} ... https://github.com/freemocap/freemocap {'tasks': {'setup': 'pre-commit install', 'test': 'python -m unittest src/tests/**/test_*', 'installer': './bin/installer.sh', 'format': 'black src/'}} ... https://github.com/openai/gym {'ini_options': {'filterwarnings': ['ignore:.*step API.*:DeprecationWarning']}} {'include': ['gym/**', 'tests/**'], 'exclude': ['**/node_modules', '**/__pycache__'], 'strict': [], 'typeCheckingMode': 'basic', 'pythonVersion': '3.6', 'pythonPlatform': 'All', 'typeshedPath': 'typeshed', 'enableTypeIgnoreComments': True, 'reportMissingImports': 'none', 'reportMissingTypeStubs': False, 'reportInvalidTypeVarUse': 'none', 'reportGeneralTypeIssues': 'none', 'reportUntypedFunctionDecorator': 'none', 'reportPrivateUsage': 'warning', 'reportUnboundVariable': 'warning'} ... <p>3 rows \u00d7 54 columns</p> <pre><code>    F\"there are {len(tools.columns)} tools used in the {len(df)} pyproject.toml files.\" \n</code></pre> <pre>'there are 54 tools used in the 234 pyproject.toml files.'</pre> <p>the <code>top12</code> most frequently defined tools in the <code>pyproject.toml</code>s are </p> <pre><code>    tool_counts = tools.isna().astype(int).sub(1).abs().sum().sort_values(ascending=False)\n    (top12 := tool_counts.iloc[:12]).to_frame(\"counts\").T\n</code></pre> black isort pytest mypy coverage poetry setuptools_scm hatch setuptools pylint towncrier pyright counts 123 85 67 42 34 32 21 15 14 14 11 10 <p>from the perspective of these popular projects:</p> <ul> <li>there is strong community adoption of <code>black</code> and <code>isort</code>.   from this data it might be a recommended convention to format your code and sort your imports.</li> <li><code>pytest</code>'s third place popularity recommends that we test our projects</li> <li><code>mypy</code> suggests that type hinting is feature of some popular projects</li> <li><code>coverage</code> </li> <li><code>poetry</code></li> <li><code>setuptools_scm</code></li> <li><code>hatch</code></li> </ul> <p>next we find</p>"},{"location":"xxii/2022-12-22-pyproject-analysis.html#build-systems","title":"build systems","text":"<pre><code>    df[\"build-system\"].dropna().apply(pandas.Series)\n</code></pre> requires build-backend dependencies url https://github.com/3b1b/manim [setuptools, wheel] NaN NaN https://github.com/deepmind/hanabi-learning-environment [setuptools, wheel, scikit-build, cmake, ninja] NaN NaN https://github.com/miguelgrinberg/Flask-SocketIO [setuptools&gt;=42, wheel] setuptools.build_meta NaN https://github.com/pypa/pipx [hatchling&gt;=0.15.0] hatchling.build NaN https://github.com/py-pdf/PyPDF2 [flit_core &gt;=3.2,&lt;4] flit_core.buildapi NaN ... ... ... ... https://github.com/deepset-ai/haystack [hatchling&gt;=1.8.0] hatchling.build NaN https://github.com/dedupeio/dedupe [setuptools==63, wheel, cython] setuptools.build_meta NaN https://github.com/sktime/sktime [setuptools&gt;61, wheel, toml, build] setuptools.build_meta NaN https://github.com/enthought/mayavi [oldest-supported-numpy, setuptools, vtk, wheel] NaN NaN https://github.com/holoviz/datashader [param, pyct, setuptools] setuptools.build_meta NaN <p>173 rows \u00d7 3 columns</p>"},{"location":"xxii/2022-12-22-pyproject-analysis.html#into-the-projects","title":"into the projects?","text":"<pre><code>    df.project.dropna().apply(pandas.Series).head(0)\n</code></pre> name description readme license requires-python keywords authors classifiers dependencies dynamic urls scripts maintainers optional-dependencies entry-points gui-scripts version url"},{"location":"xxii/2022-12-23-mkdocs-plugin.html","title":"<code>mkdocs</code> plugin for jupyter notebooks","text":"<p>i think i want more control of how <code>mkdocs</code> renders notebooks. i've been using <code>mkdocs-jupyter</code> for a while and it is great, but i need more knobs.</p> <p>my particular need is to configure <code>nbconvert</code> exporters with more fine grain control than what <code>mkdocs-jupyter</code> offers. the major difference is we are going to target markdown output rather than html.</p>","tags":["mkdocs-plugin"]},{"location":"xxii/2022-12-23-mkdocs-plugin.html#checklist-for-successfully-integrating-the-plugin","title":"checklist for successfully integrating the plugin","text":"<p>steps to adding a <code>mkdocs</code> plugin to this the <code>tonyfast</code> project:</p> <ul> <li> add plugin to <code>mkdocs.yml</code></li> </ul> <pre><code>plugins:\n- markdown_notebook\n</code></pre> <ul> <li> define plugin entry point for <code>tonyfast</code></li> </ul> <pre><code>[project.entry-points.\"mkdocs.plugins\"]\nmarkdown_notebook = \"tonyfast.mkdocs:MarkdownNotebook\"\n</code></pre> <ul> <li> build the <code>MarkdownNotebook</code> plugin </li> <li> integrate the plugin</li> </ul> <pre><code>from tonyfast.mkdocs import MarkdownNotebook\n</code></pre> <ul> <li> add and improve the <code>nbconvert</code> export display renderers</li> </ul>","tags":["mkdocs-plugin"]},{"location":"xxii/2022-12-23-mkdocs-plugin.html#building-the-mkdocs-plugin","title":"building the <code>mkdocs</code> plugin","text":"<pre><code>    import json, nbconvert, nbformat, pathlib, mkdocs.plugins, warnings, re, functools\n    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n</code></pre> <p>the [<code>mkdocs</code> plugin]</p> <p>we now use a custom template and expo defined in 2022-12-31-markdownish-notebook.ipynb</p> <pre><code>        with __import__(\"importnb\").Notebook():\n            from tonyfast.xxii.__markdownish_notebook import template, PidgyExporter\n</code></pre> <pre><code>    class MarkdownNotebook(mkdocs.plugins.BasePlugin):\n        exporter_cls = PidgyExporter\n        config_scheme = (\n            # ('foo', mkdocs.config.config_options.Type(str, default='a default value')),\n        )\n\n        @functools.lru_cache\n        def get_exporter(self, key=\"mkdocs\", **kw):\n            with __import__(\"importnb\").Notebook():\n                from tonyfast.xxii.__markdownish_notebook import template, HEAD, replace_attachments\n            kw.setdefault(\"template_file\", key)\n            exporter = self.exporter_cls(**kw)\n            exporter.environment.filters.setdefault(\"attachment\", replace_attachments)\n            from jinja2 import DictLoader\n            for loader in exporter.environment.loader.loaders:\n                if isinstance(loader, DictLoader):\n                    loader.mapping[key] = template\n                    loader.mapping[\"HEAD\"] = HEAD\n                    break\n            return exporter\n\n        def on_page_read_source(self, page, config):\n            if page.file.is_modified():\n                if page.file.src_uri.endswith((\".ipynb\", )):\n                    body = pathlib.Path(page.file.abs_src_path).read_text()\n                    nb = nbformat.v4.reads(body)\n                    exporter = self.get_exporter()\n                    return \"\\n\".join((\n                        \"---\", json.dumps(nb.metadata),\"---\", # add metadata as front matter\n                        exporter.from_notebook_node(nb)[0]\n                    ))\n\n        def on_post_page(self, output, page, config):\n            if '&lt;script type=\"application/vnd.jupyter.widget-view+json\"&gt;' in output:\n                left, sep, right = output.partition(\"&lt;/head\")\n                exporter = self.get_exporter()\n                return left + self.get_exporter().environment.get_template(\"HEAD\").render(resources=dict(\n                            jupyter_widgets_base_url=exporter.jupyter_widgets_base_url, \n                            html_manager_semver_range=exporter.html_manager_semver_range, \n                            widget_renderer_url=exporter.widget_renderer_url,\n                            require_js_url=exporter.require_js_url\n                        )) + sep + right\n\n        def on_page_markdown(self, markdown, page, config, files):\n            import markdown\n            title = markdown.Markdown(extensions=config['markdown_extensions']).convert(page.title)\n            page.title = title[len(\"&lt;p&gt;\"):-len(\"&lt;/p&gt;\")].strip().replace(\"code&gt;\", \"pre&gt;\")\n</code></pre> <p>we trick <code>mkdocs</code> into thinking notebook files are markdown extensions.</p> <pre><code>    mkdocs.utils.markdown_extensions += \".ipynb\", # this feels naughty.\n</code></pre>","tags":["mkdocs-plugin"]},{"location":"xxii/2022-12-30-typer-magic.html","title":"using <code>typer</code> in ipython magics","text":"<ul> <li> wrap function to consume system arguments using <code>typer</code></li> <li> register the magic with <code>IPython</code></li> <li> examples</li> <li> ipython extensions</li> </ul>","tags":["ipython-extension"]},{"location":"xxii/2022-12-30-typer-magic.html#wrapping-the-function","title":"wrapping the function","text":"<p>we needs to process system arguments as a string when use magics. the line in a line magic or the first line in a cell magic may take arguments.</p> <p><code>wrap_magic</code> transforms our function into a magic style method that has the following signature.</p> <pre><code>def magicish(line: str, cell: str =None): ...\n</code></pre> <p>it uses <code>click</code> by way of <code>typer</code> to deserialize the line of system arguments. these parameters are passed to the original function.  the magic function's help/docstring is replaced with the help from the command line interface.</p> <pre><code>    def wrap_magic(function, cell_key=\"cell\"):\n        import typer, click, shlex, functools\n        app = typer.Typer(add_completion=False, context_settings={\"help_option_names\": [\"-h\", \"--help\"]})\n        app.command()(function)\n        ctx = click.Context(typer.main.get_command(app))\n\n        @functools.wraps(function)\n        def magic(line, cell=None):\n            try:\n                ctx.command.parse_args(ctx, shlex.split(line))\n            except click.exceptions.Exit:\n                return\n            if cell_key in ctx.params:\n                ctx.params[cell_key] = cell\n            return function(**ctx.params)\n\n        magic.__doc__ = \"\\n\".join((function.__doc__ or \"\", get_help(ctx)))\n        return magic\n</code></pre>","tags":["ipython-extension"]},{"location":"xxii/2022-12-30-typer-magic.html#register-the-magic-with-ipython","title":"register the magic with <code>IPython</code>","text":"<p><code>register</code> a line, cell or line/cell magic method.</p> <pre><code>    def register_magic(function, name=None,  cell_key = \"cell\"):\n        import inspect\n        from IPython import get_ipython\n        shell = get_ipython()\n        cache_rich_console()\n        signature = inspect.signature(function)\n        wrapper = wrap_magic(function, cell_key=cell_key)\n        kind = \"line\"\n        if cell_key in signature.parameters:\n            kind = \"line_cell\"\n            if signature.parameters[cell_key].default is inspect._empty:\n                kind = \"cell\"\n        shell.register_magic_function(wrapper, kind, name)\n        shell.log.info(F\"registered {repr(function)} as magic named {name or function.__name__}\")\n        return function\n</code></pre>","tags":["ipython-extension"]},{"location":"xxii/2022-12-30-typer-magic.html#getting-the-help","title":"getting the help","text":"<p>when <code>rich</code> is installed, which it often is, we need to do some tomfoolery</p> <p>in our interactive condition we want access to the <code>rich</code> console that <code>typer</code> uses. we're going to wrap a cache around <code>typer</code>s method so that each we recieve the same <code>rich.console.Console</code> each time the function is invoked.</p> <pre><code>    def cache_rich_console(cache={}):\n        import typer, functools\n        if not cache:\n            cache.setdefault(\"_get_rich_console\", typer.rich_utils._get_rich_console)\n        typer.rich_utils._get_rich_console = functools.lru_cache(cache[\"_get_rich_console\"])\n</code></pre> <p>when the <code>Console</code> is consistent we can capture it's output and reclaim the help information</p> <pre><code>    def get_help(ctx):\n        with typer.rich_utils._get_rich_console().capture() as console: ctx.get_help()\n        return console.get()\n</code></pre>","tags":["ipython-extension"]},{"location":"xxii/2022-12-30-typer-magic.html#examples","title":"examples","text":"<ul> <li>register a line magic</li> </ul> <pre><code>    if (\u00d8 := \"__file__\" not in locals()):\n        import typer\n        @register_magic\n        def hello(count:int = 5, name:str = typer.Option(\"world\", help=\"a name to repeat\"), msg: str = \"&lt;3\"):\n\"\"\"a function that says hello\"\"\"\n            print(name*count, msg)\n        assert \"hello\" not in (shell := get_ipython()).magics_manager.magics[\"cell\"]\n        %hello \n</code></pre> <pre></pre> <pre>worldworldworldworldworld &lt;3\n</pre> <ul> <li>register a cell magic because the cell parameter was found in the signature. this is by convention, and should be configurable.</li> </ul> <pre><code>    if \u00d8:\n        @register_magic\n        def yall(count:int = 5, name:str = typer.Option(\"world\", help=\"a name to repeat\"),  cell: str = \"xoxo\"):\n\"\"\"a function that says hello to yall\"\"\"\n            hello(count, name, msg=cell)\n        assert \"yall\" in shell.magics_manager.magics[\"cell\"], \"the method didn't get registered.\"\n</code></pre> <pre></pre> <p>verify that we can import <code>register_magic</code> for reuse.</p> <pre><code>    if \u00d8:\n        with __import__(\"importnb\").Notebook():\n            from tonyfast.xxii.__typer_magic import register_magic as imported_register_magic\n</code></pre> <pre><code>    def load_ipython_extension(shell): shell.user_ns.setdefault(register_magic.__name__, register_magic)\n    def unload_ipython_extension(shell): pass\n</code></pre>","tags":["ipython-extension"]},{"location":"xxii/2022-12-31-jupyter-config-files.html","title":"configuration files","text":"<p>i'm going to include my configuration files in this package. it seems like a great place to keep them for consistency. we can import them.</p> <pre><code>    from tonyfast import ipython_config, jupyter_lab_config\n</code></pre> <p>the configurations on the <code>c</code> symbol staying consistent with traitlets configurations.</p> <pre><code>    ipython_config.c\n</code></pre> <p>then we can apply the configuration files to the property directories. <code>IPython</code> and <code>jupyter_core</code> ship their path locations</p> <pre><code>    import IPython.paths, jupyter_core.paths\n    from pathlib import Path\n</code></pre> <pre><code>    JUPYTER = Path(jupyter_core.paths.jupyter_config_dir())\n    IPYTHON = Path(IPython.paths.get_ipython_dir())\n</code></pre> <p>set the configuration files for <code>IPython</code> and <code>jupyter</code></p> <pre><code>    def set_configs(use_platform_dir: bool=True):\n        import shutil\n        if use_platform_dir:\n            shutil.copy(jupyter_lab_config.__file__, JUPYTER / Path(jupyter_lab_config.__file__).name)        \n            shutil.copy(ipython_config.__file__, IPYTHON / Path(ipython_config.__file__).name)\n        else:\n            shutil.copy(jupyter_lab_config.__file__, Path(jupyter_lab_config.__file__).name)        \n            shutil.copy(ipython_config.__file__, Path(ipython_config.__file__).name)\n</code></pre> <pre><code>    if __name__ == \"__main__\":\n        if \"__file__\" in locals():\n            __import__(\"typer\").run(set_configs)\n        else:\n            !importnb 2022-12-31-jupyter-config-files.ipynb --help\n</code></pre>"},{"location":"xxii/2022-12-31-markdownish-notebook.html","title":"a template for exporting markdownish notebooks","text":"<p>we need a combination of markdown and html templates to operate optimally with mkdocs. this document frankensteins templates and gives us some nice pixels.</p> <p><code>get_template</code> creates our hybrid template from the initial <code>TEMPLATE</code> and goes on to append blocks from <code>nbconvert</code> templates.</p> <pre><code>    def get_template() -&gt; str:\n        blocks = __import__(\"collections\").ChainMap(*map(get_blocks, \"classic/base.html.j2 classic/index.html.j2\".split()))\n        template = TEMPLATE \n        for k in KEEP:\n            if k in blocks: template += blocks[k].group(\"block\") + \"\\n\" * 3\n        return template\n</code></pre> <p>we <code>KEEP</code> some blocks from the classic templates</p> <pre><code>    KEEP = \"notebook_css execute_result  stream_stdout stream_stderr \\\n    data_svg data_html data_png data_jpg error traceback_line data_widget_state data_widget_view\".split()\n</code></pre> <p><code>get_blocks</code> loads a template and returns a dictionary of its blocks.</p> <pre><code>    def get_blocks(alias) -&gt; dict[str, (T := __import__(\"typing\")).Pattern]:\n        template = get_exporter().environment.get_template(alias)\n        with open(template.filename) as file: body = file.read()\n        return dict(yield_blocks(body))\n</code></pre> <p><code>yield</code> all the blocks recursing into the found matches</p> <pre><code>    def yield_blocks(string) -&gt; T.Iterator[tuple[str, T.Pattern]]:\n        from tonyfast.regexs import jinja_block\n        for m in jinja_block.finditer(string):\n            yield m.group(\"name\"), m\n            yield from yield_blocks(m.group(\"inner\"))\n</code></pre> <p>initialize our exporter and jinja environment</p> <p>i want to hide the input code, but no remove it; a custom exporter felt like a better way.</p> <pre><code>    import nbconvert, re\n    class PidgyExporter(nbconvert.exporters.HTMLExporter):\n        def from_notebook_node(self, nb, resources=None, **kw):\n            resources = self._init_resources(dict(is_pidgy=is_pidgy(nb)))\n            return super().from_notebook_node(nb, resources, **kw)\n</code></pre> <p>we moved <code>is_pidgy</code> and <code>PIDGY</code> from the mkdocs plugin because them make more self here.</p> <pre><code>    def is_pidgy(nb):\n        for cell in nb[\"cells\"]:\n            if cell[\"cell_type\"] == \"code\":\n                if PIDGY.match(\"\".join(cell[\"source\"])):\n                    return True\n        return False\n</code></pre> <pre><code>    PIDGY = re.compile(r\"\\s*%(re)?load_ext pidgy\")\n</code></pre> <pre><code>    def replace_attachments(cell):\n        source = \"\".join(cell[\"source\"])\n        if cell.get(\"attachments\"):\n            for k, v in cell[\"attachments\"].items():\n                for t, v in v.items():\n                    source = source.replace(\"attachment:\" + k, \"data:\" + t + \";base64,\" + v)\n        return source\n</code></pre> <pre><code>    @(cache := __import__(\"functools\").lru_cache)\n    def get_exporter() -&gt; \"nbconvert.TemplateExporter\":\n        exporter = PidgyExporter()\n        exporter.environment.filters.setdefault(\"highlight_code\", lambda x: x)\n        exporter.environment.filters.setdefault(\"attachment\", replace_attachments)\n        return exporter\n</code></pre>"},{"location":"xxii/2022-12-31-markdownish-notebook.html#generating-the-template","title":"generating the template","text":"<p>this template holds so of our own logic.</p> <pre><code>    TEMPLATE = \"\"\"{%- extends 'display_priority.j2' -%}\n    {% block body_footer %}\n    {{super()}}\n    {% set mimetype = 'application/vnd.jupyter.widget-state+json'%}\n    {% if mimetype in nb.metadata.get(\"widgets\",{})%}\n    &lt;script type=\"{{ mimetype }}\"&gt;\n    {{ nb.metadata.widgets[mimetype] | json_dumps  }}\n    &lt;/script&gt;\n    {% endif %}\n    &lt;/script&gt;\n\n    {% endblock %}\n\n    {% block data_markdown scoped %}\n\n    {{output.data['text/markdown']}}\n\n    {% endblock data_markdown %}\n\n    {% block markdowncell scoped %}\n\n    {{cell | attachment}}\n\n    {% endblock markdowncell %} \n\n    {% block input %}\n    {% if not resources.is_pidgy %}\n    ``````````````````````````````````````````````````````````````python\n    {{cell.source}}\n\n    ``````````````````````````````````````````````````````````````\n    {% endif %}\n    {% endblock %}\n    \"\"\"\n</code></pre> <pre><code>    HEAD = \"\"\"{% from 'base/jupyter_widgets.html.j2' import jupyter_widgets %}\n    &lt;script src=\"{{ resources.require_js_url }}\"&gt;&lt;/script&gt;\n    {{ jupyter_widgets(resources.jupyter_widgets_base_url, resources.html_manager_semver_range, resources.widget_renderer_url) }}\n    \"\"\"\n</code></pre> <p>we can then combine our base template with existing <code>nbconvert</code> ones to compute the final template.</p> <pre><code>    template = get_template()\n</code></pre>"},{"location":"xxii/2022-12-31-markdownish-notebook.html#the-generated-template","title":"the generated template","text":"<pre><code>    if \"__file__\" not in locals():\n        display({\"text/markdown\": F\"``````````````````````````html+jinja\\n{template}\\n``````````````````````````\"}, raw=True)\n</code></pre> <pre><code>{%- extends 'display_priority.j2' -%}\n{% block body_footer %}\n{{super()}}\n{% set mimetype = 'application/vnd.jupyter.widget-state+json'%}\n{% if mimetype in nb.metadata.get(\"widgets\",{})%}\n&lt;script type=\"{{ mimetype }}\"&gt;\n{{ nb.metadata.widgets[mimetype] | json_dumps  }}\n&lt;/script&gt;\n{% endif %}\n&lt;/script&gt;\n\n{% endblock %}\n\n{% block input %}\n{% if resources.is_pidgy %}&lt;div class=\"cell source\" hidden&gt;\n{% endif %}\n````````````````````````python\n{{cell.source}}\n````````````````````````\n{% if resources.is_pidgy %}&lt;/div&gt;\n{% endif %}\n{% endblock input %}\n\n{% block data_markdown scoped %}\n\n{{output.data['text/markdown']}}\n\n{% endblock data_markdown %}\n\n{% block markdowncell scoped %}\n\n{{cell | attachment}}\n\n{% endblock markdowncell %} \n\n{% block notebook_css %}\n{{ resources.include_css(\"static/style.css\") }}\n&lt;style type=\"text/css\"&gt;\n/* Overrides of notebook CSS for static HTML export */\nbody {\noverflow: visible;\npadding: 8px;\n}\n\ndiv#notebook {\noverflow: visible;\nborder-top: none;\n}\n\n{%- if resources.global_content_filter.no_prompt-%}\ndiv#notebook-container{\npadding: 6ex 12ex 8ex 12ex;\n}\n{%- endif -%}\n\n@media print {\nbody {\nmargin: 0;\n}\ndiv.cell {\ndisplay: block;\npage-break-inside: avoid;\n}\ndiv.output_wrapper {\ndisplay: block;\npage-break-inside: avoid;\n}\ndiv.output {\ndisplay: block;\npage-break-inside: avoid;\n}\n}\n&lt;/style&gt;\n{% endblock notebook_css %}\n\n\n{% block execute_result -%}\n{%- set extra_class=\"output_execute_result\" -%}\n{% block data_priority scoped %}\n{{ super() }}\n{% endblock data_priority %}\n{%- set extra_class=\"\" -%}\n{%- endblock execute_result %}\n\n\n{% block stream_stdout -%}\n&lt;div class=\"output_subarea output_stream output_stdout output_text\"&gt;\n&lt;pre&gt;\n{{- output.text | ansi2html -}}\n&lt;/pre&gt;\n&lt;/div&gt;\n{%- endblock stream_stdout %}\n\n\n{% block stream_stderr -%}\n&lt;div class=\"output_subarea output_stream output_stderr output_text\"&gt;\n&lt;pre&gt;\n{{- output.text | ansi2html -}}\n&lt;/pre&gt;\n&lt;/div&gt;\n{%- endblock stream_stderr %}\n\n\n{% block data_svg scoped -%}\n&lt;div class=\"output_svg output_subarea {{ extra_class }}\"&gt;\n{%- if output.svg_filename %}\n&lt;img src=\"{{ output.svg_filename | posix_path }}\"&gt;\n{%- else %}\n{{ output.data['image/svg+xml'] }}\n{%- endif %}\n&lt;/div&gt;\n{%- endblock data_svg %}\n\n\n{% block data_html scoped -%}\n&lt;div class=\"output_html rendered_html output_subarea {{ extra_class }}\"&gt;\n{%- if output.get('metadata', {}).get('text/html', {}).get('isolated') -%}\n&lt;iframe\n    class=\"isolated-iframe\"\n    style=\"height:520px; width:100%; margin:0; padding: 0\"\n    frameborder=\"0\"\n    scrolling=\"auto\"\n    src=\"data:text/html;base64,{{output.data['text/html'] | text_base64}}\"&gt;\n&lt;/iframe&gt;\n{%- else -%}\n{{ output.data['text/html'] }}\n{%- endif -%}\n&lt;/div&gt;\n{%- endblock data_html %}\n\n\n{% block data_png scoped %}\n&lt;div class=\"output_png output_subarea {{ extra_class }}\"&gt;\n{%- if 'image/png' in output.metadata.get('filenames', {}) %}\n&lt;img src=\"{{ output.metadata.filenames['image/png'] | posix_path }}\"\n{%- else %}\n&lt;img src=\"data:image/png;base64,{{ output.data['image/png'] }}\"\n{%- endif %}\n{%- set width=output | get_metadata('width', 'image/png') -%}\n{%- if width is not none %}\nwidth={{ width }}\n{%- endif %}\n{%- set height=output | get_metadata('height', 'image/png') -%}\n{%- if height is not none %}\nheight={{ height }}\n{%- endif %}\n{%- if output | get_metadata('unconfined', 'image/png') %}\nclass=\"unconfined\"\n{%- endif %}\n{%- set alttext=(output | get_metadata('alt', 'image/png')) or (cell | get_metadata('alt')) -%}\n{%- if alttext is not none %}\nalt=\"{{ alttext }}\"\n{%- endif %}\n&gt;\n&lt;/div&gt;\n{%- endblock data_png %}\n\n\n{% block data_jpg scoped %}\n&lt;div class=\"output_jpeg output_subarea {{ extra_class }}\"&gt;\n{%- if 'image/jpeg' in output.metadata.get('filenames', {}) %}\n&lt;img src=\"{{ output.metadata.filenames['image/jpeg'] | posix_path }}\"\n{%- else %}\n&lt;img src=\"data:image/jpeg;base64,{{ output.data['image/jpeg'] }}\"\n{%- endif %}\n{%- set width=output | get_metadata('width', 'image/jpeg') -%}\n{%- if width is not none %}\nwidth={{ width }}\n{%- endif %}\n{%- set height=output | get_metadata('height', 'image/jpeg') -%}\n{%- if height is not none %}\nheight={{ height }}\n{%- endif %}\n{%- if output | get_metadata('unconfined', 'image/jpeg') %}\nclass=\"unconfined\"\n{%- endif %}\n{%- set alttext=(output | get_metadata('alt', 'image/jpeg')) or (cell | get_metadata('alt')) -%}\n{%- if alttext is not none %}\nalt=\"{{ alttext }}\"\n{%- endif %}\n&gt;\n&lt;/div&gt;\n{%- endblock data_jpg %}\n\n\n{% block error -%}\n&lt;div class=\"output_subarea output_text output_error\"&gt;\n&lt;pre&gt;\n{{- super() -}}\n&lt;/pre&gt;\n&lt;/div&gt;\n{%- endblock error %}\n\n\n{%- block traceback_line %}\n{{ line | ansi2html }}\n{%- endblock traceback_line %}\n\n\n{%- block data_widget_state scoped %}\n{% set div_id = uuid4() %}\n{% set datatype_list = output.data | filter_data_type %}\n{% set datatype = datatype_list[0]%}\n&lt;div id=\"{{ div_id }}\" class=\"output_subarea output_widget_state {{ extra_class }}\"&gt;\n&lt;script type=\"text/javascript\"&gt;\nvar element = $('#{{ div_id }}');\n&lt;/script&gt;\n&lt;script type=\"{{ datatype }}\"&gt;\n{{ output.data[datatype] | json_dumps }}\n&lt;/script&gt;\n&lt;/div&gt;\n{%- endblock data_widget_state -%}\n\n\n{%- block data_widget_view scoped %}\n{% set div_id = uuid4() %}\n{% set datatype_list = output.data | filter_data_type %}\n{% set datatype = datatype_list[0]%}\n&lt;div id=\"{{ div_id }}\" class=\"output_subarea output_widget_view {{ extra_class }}\"&gt;\n&lt;script type=\"text/javascript\"&gt;\nvar element = $('#{{ div_id }}');\n&lt;/script&gt;\n&lt;script type=\"{{ datatype }}\"&gt;\n{{ output.data[datatype] | json_dumps }}\n&lt;/script&gt;\n&lt;/div&gt;\n{%- endblock data_widget_view -%}\n</code></pre> <pre><code>\n</code></pre>"},{"location":"xxii/oct/2022-10-05-dask-search.html","title":"searching notebooks","text":"<p>sorry haters. notebooks are here to stay. their growth and adoption means that they'll present newer problems. one forthcoming challenge with notebooks and their adoption is the ability to search notebooks across space and time.  in this notebook, we build tooling to search notebooks and think about the question we might ask to our notebooks.</p> <p>Searching notebooks as structured data.</p> <p>What questions would you ask? today? a year from today? a lifetime from today?</p>"},{"location":"xxii/oct/2022-10-05-dask-search.html#notebook-schema","title":"notebook schema","text":"<p>one of the reasons we can search notebooks is their consistent structure defined by the <code>nbformat</code> <code>SCHEMA</code>. the schema provides both a description of the document format along with type information about the notebook data.</p> <pre><code>    import nbformat.v4, jsonref, IPython.display as SOME\n    COMPACT = nbformat.validator._get_schema_json(nbformat.v4)    \n</code></pre> <p>the <code>COMPACT</code> should be expanded to allow for easier access the components of the schema. if we don't that we need to really on the implicit structure of the schema document.</p> <pre><code>    SCHEMA = jsonref.JsonRef.replace_refs(COMPACT)\n    SOME.JSON(SCHEMA, root=SCHEMA[\"description\"]);\n</code></pre> <p>for this demonstration we are going to avoid anything dealing with the top level metadata.  our goal is to explore the contents of cells and think about the questions we may ask on the cell sources and outputs.</p>"},{"location":"xxii/oct/2022-10-05-dask-search.html#cell-schema","title":"cell schema","text":"<p>below we extra the expected <code>CELL</code> keys from the <code>SCHEMA</code></p> <pre><code>    CELL, CELLS = SCHEMA[\"properties\"][\"cells\"], {\"nid\"}\n    for s in CELL[\"items\"][\"oneOf\"]:\n        CELLS.update(s.get(\"properties\", \"\"))\n    CELLS = sorted(CELLS)\n    CELLS_META_EXPLICIT = dict(execution_count=\"float64\", nid=int, cell_type=\"category\")\n    CELLS_META = tuple((k, CELLS_META_EXPLICIT.get(k, \"object\")) for k in CELLS)\n    F\"the expected cell keys are {CELLS}\"\n</code></pre> <pre>\"the expected cell keys are ['attachments', 'cell_type', 'execution_count', 'id', 'metadata', 'nid', 'outputs', 'source']\"</pre>"},{"location":"xxii/oct/2022-10-05-dask-search.html#loading-our-notebook-data","title":"loading our notebook data.","text":"<p>we're going to use <code>dask</code> to accelerate our efforts. <code>dask</code> will help us looking across files in a fast way, and we can speak dataframes natively.</p> <pre><code>    import dask.dataframe, pandas, jsonref, json; from dask import delayed; from pathlib import Path\n</code></pre> <p>our dataframe is going to be constructed from a bunch of parallel files reads. each file is passed through <code>get_cell</code> to return a <code>pandas.DataFrame</code>.</p> <pre><code>    def get_cell(path):\n        with open(path) as file:\n            if str(path).endswith((\".ipynb\",)):\n                cells = json.load(file)[\"cells\"]\n            elif str(path).endswith((\".md\",)):\n                cells = dict(metadata={}, cells=[dict(\n                    cell_type=\"markdown\", source=\"\".join(file)\n                )])\n        df = pandas.DataFrame(cells)\n        df.index.name = \"nid\"\n        df = df.reset_index(\"nid\")\n\n        if \"source\" not in df:\n            df = pandas.DataFrame(columns=CELLS)\n        else:\n            df.execution_count = df.execution_count.fillna(-1) # -1 is outside the valid schema, but we don't validate here!\n            df.source = df.source.apply(\"\".join)\n        df.index = [path]*len(df)\n        df.index.name = \"path\"\n\n        for k, _ in CELLS_META:\n            if k not in df.columns:\n                df[k] = None\n            df[k] = df[k].astype(\"O\")\n        return df[CELLS]\n</code></pre> <p><code>get_cells</code> loads, tidies, and separates cells, outputs and metadata</p> <pre><code>    def get_delayeds(dir, recursive=False):\n        dir = Path(dir)\n        files = (recursive and dir.rglob or dir.glob)(\"*.ipynb\")\n        return dask.dataframe.from_delayed(\n            list(map(delayed(get_cell), files))\n        )\n</code></pre> <pre><code>    def get_cells(dir=None, recursive=False):\n        return get_delayeds(dir or Path.cwd(), recursive).pipe(\n            lambda df: (df, df.pop(\"outputs\"), df.pop(\"metadata\"))\n        )\n    L = \"__file__\" not in locals()\n    print(L)\n    if L: cells, outputs, metadata = get_cells(\"../..\"); display(cells)\n</code></pre> <pre>True\n</pre> Dask DataFrame Structure: attachments cell_type execution_count id nid source npartitions=8 object object object object object object ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... Dask Name: drop_by_shallow_copy, 32 tasks <p>find cells with imports in them</p> <pre><code>    if L: cells[cells.source.str.match(\"\\s*import\\s+.*\")].compute().T.pipe(display)\n</code></pre> path ../../2022-06-28-.ipynb ../../2022-06-24-.ipynb ../../2022-03-06-schemata-scratch.ipynb ../../2022-03-06-schemata-scratch.ipynb attachments None None None None cell_type code code code code execution_count 9.0 2.0 7.0 6.0 id c744325a-8f73-4428-b381-c1f4ee5fdb06 ba46c5ef-78e6-48b2-bee3-cd6be3606fe5 ab6ff11f-a7d1-4e59-9fdd-cac7313a7cf4 5d3d2316-b2b0-4f47-ad0d-9b677b1f7e6a nid 6 1 52 126 source \\n    import graphviz\\n    hommage = graph... import functools, abc import sys import urllib <p>find some urls?</p> <pre><code>    if L: cells.source.str.extract(\"(http[s]://\\S+)\").dropna().compute().T.pipe(display)\n</code></pre> path ../../2022-06-28-.ipynb ../../2022-06-28-.ipynb ../../2022-06-28-.ipynb ../../2022-06-28-.ipynb ../../2022-06-28-.ipynb ../../2022-04-12-.ipynb ../../2022-04-12-.ipynb ../../2022-03-06-schemata-scratch.ipynb ../../2022-03-06-schemata-scratch.ipynb ../../2022-03-06-schemata-scratch.ipynb ../../2022-03-06-schemata-scratch.ipynb ../../2022-03-06-schemata-scratch.ipynb 0 https://raw.githubusercontent.com/SchemaStore/... https://joss.theoj.org/papers/in/Jupyter%20Not... https://raw.githubusercontent.com/SchemaStore/... https://raw.githubusercontent.com/jupyter/nbfo... https://c.tenor.com/JHjG5vxW9zIAAAAd/missy-ell... https://github.com/jupyterlab/lumino\", https://github.com/jupyterlab/jupyterlab@master\", https://json-schema.org/draft/next/meta/valida... https://json-schema.org/draft/2020-12/schema'] https://json-schema.org/draft/2020-12/schema\"] https://test.json-schema.org/dynamic-resolutio... https://avatars.githubusercontent.com/u/423627..."},{"location":"xxii/oct/2022-10-05-dask-search.html#break","title":"<code>break</code>","text":"<p>what storage integrate with contents manager what queries</p> <p>working on this notebook revealed an issue with importnb's json parser than needs some care.</p> <p>this document is code and can be used with the statement <code>from tonyfast import search</code></p>"},{"location":"xxii/oct/2022-10-19-mobius-text.html","title":"turn some text into a mobius surface","text":"<p>a good reference was: https://algebra-fun.gitee.io/blog/2020/06/16/Joy-%E7%BB%98%E5%88%B6Mobius/</p> <pre><code>    if __import__(\"sys\").platform == \"emscripten\":\n        await __import__(\"micropip\").install(\"pandas matplotlib ipympl\".split())\n    import pandas, matplotlib, io, numpy\n    from mpl_toolkits.mplot3d import Axes3D\n    %matplotlib agg\n</code></pre> <p><code>get_text</code> transforms some text into a dataframe that will allow us to plot a mobius strip.</p> <pre><code>    def get_text(text=\"deathbeds\", repeat=2):\n        return get_text_array(\n            get_text_figure(text, repeat)\n        ).pipe(get_parameterized_text).pipe(get_xyz)\n</code></pre> <p><code>get_text_figure</code> transforms text to pixels.</p> <pre><code>    def get_text_figure(text=\"deathbeds\", repeat=1):\n        matplotlib.pyplot.gca().text(0, 0, text*repeat, size=1000)\n        matplotlib.pyplot.gca().axis(\"off\")\n        fig = matplotlib.pyplot.gcf()\n        return fig\n</code></pre> <p><code>get_text_array</code> structure those pixels as dataframe</p> <pre><code>    def get_text_array(fig):\n        data= io.BytesIO()\n        fig.savefig(data, bbox_inches=\"tight\")\n        data.seek(0)\n        where = numpy.where(matplotlib.pyplot.imread(data).sum(2)[::-4, ::20] &lt; 2)\n        return pandas.concat(\n            [pandas.Series(where[0], name=\"x\"), pandas.Series(where[1], name=\"y\")], axis=1\n        ).set_index(\"x\")\n</code></pre> <p><code>get_parameterized_text</code> parameterizes x onto 0..1 and s one 0..2\u03c0</p> <pre><code>    def get_parameterized_text(df):\n        extent = df.index.max() - df.index.min()\n        df[\"t\"] = df.index.to_series()\n        df.t = df.t.sub(df.t.min()).div(extent).sub(.5)\n        extent = df.y.max() - df.y.min()\n        df[\"s\"] = df.y.add(df.y.min()).div(extent).mul(2*numpy.pi)\n        return df\n</code></pre> <p><code>get_xyz</code> moves the parameterization in xyz space.</p> <pre><code>    def get_xyz(df, R=100, W=50):\n        return df.assign(\n            x=(R+W*df.t*df.s.div(2).apply(numpy.cos))*df.s.apply(numpy.cos), \n            y=(R+W*df.t*df.s.div(2).apply(numpy.cos))*df.s.apply(numpy.sin), \n            z=W*df.t.mul(df.s.div(2).apply(numpy.sin)), \n        )\n</code></pre> <p><code>get_plot</code> takes our structured data and plots in 3d.</p> <pre><code>    def get_plot(df):\n        fig = matplotlib.pyplot.gcf()\n        ax = Axes3D(fig, auto_add_to_figure=False)\n        fig.add_axes(ax)\n        ax.scatter3D(df.x, df.y, df.z, c=[(.1, .1, .1, .015)], marker=\"v\", s=200, edgecolor=None)\n        return fig\n</code></pre> <p>use the interactive 3-d dispklay</p> <pre><code>    %matplotlib ipympl\n</code></pre> <p>plot it all</p> <pre><code>    matplotlib.pyplot.gcf().set_size_inches((6, 6))        \n    get_text(\"deathbeds\").pipe(get_plot)\n</code></pre>                      Figure"},{"location":"xxii/oct/2022-10-20-meeting-link-widgets.html","title":"making meeting links","text":"<p>i need to be able to make meetings with folks. those meetings will often contain:</p> <ul> <li>some content</li> <li>real time collaboration</li> <li>video chat</li> </ul> <p>the notebooks builds a link for a video chat and real collaboration.</p> <p>this system feels pretty de-platformated using <code>jupyterlab</code>s native rtc and <code>jitsi</code> video chat. ping me on twitter if you want a tour sometime.</p> <p>in the future we can build: binder links, icalendar events.</p> <pre><code>    try:\n        import ipywidgets, icalendar, dataclasses, uritemplate, traitlets, arrow\n    except: \n        await __import__(\"micropip\").install(\"ipywidgets icalendar dataclasses uritemplate traitlets arrow\".split())\n        import ipywidgets, icalendar, dataclasses, uritemplate, traitlets, arrow\n    from functools import partial; from ipywidgets import *\n</code></pre> <pre><code>    video = Text(\"in-this-house-we-wear-sweatpants\", description=\"\ud83d\udcf9 video chat\")\n    rtc = Text(\"exquisite-potluck\", description=\"\ud83e\udd1d real time collaboration\")\n    document = Text(\"\", description=\"\ud83d\udcc4 file path\")\n    input = list(zip(\"JVC-PUBLIC room path\".split(), [video, rtc, document]))\n    lite_url = HTML(\"\", description=\"\ud83d\udca1 lite\")\n</code></pre> <p><code>update_lite_url</code> formats the <code>input</code> widgets using a uri template.    </p> <pre><code>    def update_lite_url(*\u0394, lite_template = \"https://tonyfast.github.io/tonyfast/run/lab{?room,JVC-PUBLIC,path}\"):\n        url = uritemplate.URITemplate(lite_template).expand(dict(\n            (k, v.value) for k, v in input if v.value))\n        lite_url.value = F\"\"\"&lt;a href=\"{url}\"&gt;{url}&lt;/a&gt;\"\"\"\n</code></pre> <p>initialize the widget interactions</p> <pre><code>    for k, widget in input: widget.observe(update_lite_url, \"value\")\n    update_lite_url()\n</code></pre> <p>make the <code>app</code> and start tinkering with it.</p> <pre><code>    app = VBox([x[1] for x in input] + [lite_url]); app\n</code></pre> <pre>VBox(children=(Text(value='in-this-house-we-wear-sweatpants', description='\ud83d\udcf9 video chat'), Text(value='exquisi\u2026</pre> <p>i suspect i'll reuse this document to meet with folks, and build some more tooling for it.</p>"},{"location":"xxii/oct/2022-10-21-markdown-future.html","title":"when markdown and python collide","text":"<p>a story about literacy written in the literate programming style of <code>pidgy</code></p> <p></p> <p>notebooks commonly communicate with two languages: markdown &amp; python. what happen when we dissolve the boundaries between markdown &amp; python or language &amp; code entirely.</p> <pre><code>    class STATE:\n        NB = \"__file__\" not in globals() and __name__ == \"__main__\"\n        SCRIPT = \"__file__\" in globals() and __name__ != \"__main__\"\n        MAIN = \"__file__\" in globals() and __name__ == \"__main__\"\n        LITE = __import__(\"sys\").platform == \"emscripten\"\n</code></pre> <pre><code># execute this code in lite.\nif STATE.LITE:\n    try:\n        %reload_ext pidgy\n    except ModuleNotFoundError:\n        import micropip\n        await micropip.install(\"pidgy importnb qrcode midgy ipywidgets\".split(), pre=True)\n</code></pre> <pre><code>    import pidgy, pathlib, IPython\n    shell = IPython.get_ipython()\n    if STATE.NB:\n        %reload_ext pidgy\n        shell.displays_manager.template_cls = pidgy.weave.IPythonHtml\n</code></pre> <pre><code>import pidgy, pathlib, IPython\nshell = IPython.get_ipython()\nif STATE.NB:\n    %reload_ext pidgy\n    shell.displays_manager.template_cls = pidgy.weave.IPythonHtml</code></pre> <pre><code>&lt;style&gt;\nimg {\n    height: 500px !important;\n}\n.jupyter-wrapper .jp-Cell-inputWrapper {\n    display: none;\n}\n&lt;/style&gt;\n&lt;script src=\"https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js\"&gt;&lt;/script&gt;\n&lt;script&gt;mermaid.initialize({startOnLoad:true, securityLevel: \"loose\"}, \".mermaid\");&lt;/script&gt;\n</code></pre> <pre><code>## literate computing with literary machines using literate programming for mass computational literacy\n\nliteracy rings through the history of computer science.\nin Annette Vee's [Understanding Computer Programming as a Literacy] we get\na high level view of literacy through history and in the our little microcosm of computer programming.\n\n&gt; We compare mass ability to read and write software with mass literacy, and predict equally pervasive changes to society.\n\n    history =\\\n```mermaid\ngantt \ntitle Literacy in computer programming\ndateFormat YYYY\naxisFormat %Y\n\nsection moderninity\nunderstanding media :mcluhan, 1964, 2022\nmother of all demos :englebert, 1968, 2022\nsection post moderninity\nliterate programming :knuth, 1984, 2022\nliterary machines :nelson, 1987, 2022\nwww :tbl, 1989, 2022\n\nsection post web\ncomputer programming for everybody :cp4e, 1999, 2022\nipython :fperez, 2001, 2022\nmarkdown :gruber, 2004, 2022\nipython notebooks :ipynb, 2011, 2022\nanaconda :ana, 2012, 2022\nliterate computing :lc, 2013, 2022\nunderstanding computer programming as a literacy :vee, 2013, 2022\nthe birth &amp; death of javascript: js, 2014, 2022\nbig split :split, 2015, 2022\njupyterlab :lab, 2018, 2022\njupyterlite :lab, 2021, 2022\n\nclick vee href \"https://licsjournal.org/index.php/LiCS/article/view/794/608\"\nclick knuth href \"http://www.literateprogramming.com/knuthweb.pdf\"\nclick nelson href \"https://monoskop.org/images/b/be/Nelson_Ted_Literary_Machines_c1987_chs_0-1.pdf\"\nclick lc href \"https://web.archive.org/web/20220510083647/http://blog.fperez.org/2013/04/literate-computing-and-computational.html\"\nclick cp4e href \"https://www.python.org/doc/essays/cp4e/\"\n\n\n```\n\n    shell.displays_manager.template_cls = pidgy.weave.IPythonMarkdown\n</code></pre>"},{"location":"xxii/oct/2022-10-21-markdown-future.html#literate-computing-with-literary-machines-using-literate-programming-for-mass-computational-literacy","title":"literate computing with literary machines using literate programming for mass computational literacy","text":"<p>literacy rings through the history of computer science. in Annette Vee's [Understanding Computer Programming as a Literacy] we get a high level view of literacy through history and in the our little microcosm of computer programming.</p> <p>We compare mass ability to read and write software with mass literacy, and predict equally pervasive changes to society.</p> <pre><code>history =\\\n</code></pre> <p><code>mermaid gantt  title Literacy in computer programming dateFormat YYYY axisFormat %Y  section moderninity understanding media :mcluhan, 1964, 2022 mother of all demos :englebert, 1968, 2022 section post moderninity literate programming :knuth, 1984, 2022 literary machines :nelson, 1987, 2022 www :tbl, 1989, 2022  section post web computer programming for everybody :cp4e, 1999, 2022 ipython :fperez, 2001, 2022 markdown :gruber, 2004, 2022 ipython notebooks :ipynb, 2011, 2022 anaconda :ana, 2012, 2022 literate computing :lc, 2013, 2022 understanding computer programming as a literacy :vee, 2013, 2022 the birth &amp; death of javascript: js, 2014, 2022 big split :split, 2015, 2022 jupyterlab :lab, 2018, 2022 jupyterlite :lab, 2021, 2022  click vee href \"https://licsjournal.org/index.php/LiCS/article/view/794/608\" click knuth href \"http://www.literateprogramming.com/knuthweb.pdf\" click nelson href \"https://monoskop.org/images/b/be/Nelson_Ted_Literary_Machines_c1987_chs_0-1.pdf\" click lc href \"https://web.archive.org/web/20220510083647/http://blog.fperez.org/2013/04/literate-computing-and-computational.html\" click cp4e href \"https://www.python.org/doc/essays/cp4e/\"</code></p> <pre><code>shell.displays_manager.template_cls = pidgy.weave.IPythonMarkdown\n</code></pre>"},{"location":"xxii/oct/2022-10-21-markdown-future.html#donald-knuths-diagram-for-literate-programming","title":"donald knuth's diagram for literate programming","text":"<pre><code># tangle (code) and weave (display)\n\n    knit =\\\n```mermaid\nflowchart LR\nweb-- tangle ---pas\npas-- pascal ---rel\nweb-- weave ---tex\ntex-- TEX ---dvi\n```\n</code></pre>"},{"location":"xxii/oct/2022-10-21-markdown-future.html#tangle-code-and-weave-display","title":"tangle (code) and weave (display)","text":"<pre><code>knit =\\\n</code></pre> <p><code>mermaid flowchart LR web-- tangle ---pas pas-- pascal ---rel web-- weave ---tex tex-- TEX ---dvi</code></p> <pre><code>## `midgy/pidgy` family of input kernels in `IPython`\n\nliterate inputs with markdown and python as the document and programming languages\n\n&lt;div style=\"font-size: 2rem;\"&gt;\n\n    import midgy as tangle, pidgy as weave\n\n&lt;/div&gt;\n\nwe'll explore a little program in markdown inside a bigger notebook program. hold tight.\n</code></pre>"},{"location":"xxii/oct/2022-10-21-markdown-future.html#midgypidgy-family-of-input-kernels-in-ipython","title":"<code>midgy/pidgy</code> family of input kernels in <code>IPython</code>","text":"<p>literate inputs with markdown and python as the document and programming languages</p>       import midgy as tangle, pidgy as weave   <p>we'll explore a little program in markdown inside a bigger notebook program. hold tight.</p> <pre><code>### how does `IPython` python?\n\n\n* `shell.kernel.do_execute`\n    * `shell.run_cell`\n        * tangle\n            * `shell.transform_cell`\n            * `shell.compile.ast_parse`\n            * `shell.transform_ast`\n            * `shell.run_ast_nodes`        \n        * weave\n            * if `shell.ast_node_interactivity` \n            * `shell.display_formatter.format`\n\n`IPython` is very hackable! that is what makes it fun along with all the development happening in python.\n</code></pre>"},{"location":"xxii/oct/2022-10-21-markdown-future.html#how-does-ipython-python","title":"how does <code>IPython</code> python?","text":"<ul> <li><code>shell.kernel.do_execute</code><ul> <li><code>shell.run_cell</code><ul> <li>tangle<ul> <li><code>shell.transform_cell</code></li> <li><code>shell.compile.ast_parse</code></li> <li><code>shell.transform_ast</code></li> <li><code>shell.run_ast_nodes</code> </li> </ul> </li> <li>weave<ul> <li>if <code>shell.ast_node_interactivity</code> </li> <li><code>shell.display_formatter.format</code></li> </ul> </li> </ul> </li> </ul> </li> </ul> <p><code>IPython</code> is very hackable! that is what makes it fun along with all the development happening in python.</p> <pre><code>    %%file a-little-markdown-program.md\n    this markdown file is a program!\n\n            \u03b4\u03f5\u03b1\u03c4\u03ba=\\\n    death to pseudo code, long live pseudo code\n\n            if __name__ == \"__main__\":\n                print(\u03b4\u03f5\u03b1\u03c4\u03ba.upper())\n</code></pre> <pre>Overwriting a-little-markdown-program.md\n</pre> <p>we can run this like a script. WTF!</p> <pre><code>!midgy a-little-markdown-program.md\n</code></pre> <pre><code>    import midgy.loader\n    with midgy.loader.Markdown() as loader:\n        import a_little_markdown_program\n    a_little_markdown_program, a_little_markdown_program.\u03b4\u03f5\u03b1\u03c4\u03ba\n</code></pre> <pre>(&lt;module 'a-little-markdown-program' from '/home/tbone/Documents/tonyfast/tonyfast/xxii/oct/a-little-markdown-program.md'&gt;,\n 'death to pseudo code, long live pseudo code')</pre> <pre><code>import midgy.loader\nwith midgy.loader.Markdown() as loader:\n    import a_little_markdown_program\na_little_markdown_program, a_little_markdown_program.\u03b4\u03f5\u03b1\u03c4\u03ba\n</code></pre> <pre><code>`a_little_markdown_program` is a module like any other\n\n`{{a_little_markdown_program}}`\n\n\ud83d\udc07and we even generated a compiled version of the markdown source\ud83c\udfa9\n\n    if not STATE.LITE:\n        assert next(\n            (pathlib.Path(a_little_markdown_program.__file__).parent / \"__pycache__\").glob(\"a-little-markdown-program.*.pyc\")\n        ),\\\nverifies there is a compiled file.\n</code></pre> <p><code>a_little_markdown_program</code> is a module like any other</p> <p><code>&lt;module 'a-little-markdown-program' from '/home/tbone/Documents/tonyfast/tonyfast/xxii/oct/a-little-markdown-program.md'&gt;</code></p> <p>\ud83d\udc07and we even generated a compiled version of the markdown source\ud83c\udfa9</p> <pre><code>if not STATE.LITE:\n    assert next(\n        (pathlib.Path(a_little_markdown_program.__file__).parent / \"__pycache__\").glob(\"a-little-markdown-program.*.pyc\")\n    ),\\\n</code></pre> <p>verifies there is a compiled file.</p> <pre><code>## [literate computing widgets and `IPython` interactive displays](2022-10-21-pidgy-displays.ipynb)\n</code></pre>"},{"location":"xxii/oct/2022-10-21-markdown-future.html#literate-computing-widgets-and-ipython-interactive-displays","title":"literate computing widgets and <code>IPython</code> interactive displays","text":"<pre><code>## reusing and importing notebooks\n\nwe can import this presentation.\n\n        import midgy.loader\n        with midgy.loader.Markdown(extensions=[\".ipynb\", \".md\"]):\n            import _022_10_21_markdown_future\n        \"__file__\" not in locals() and display(\n            _022_10_21_markdown_future,\n            _022_10_21_markdown_future.a_little_markdown_program,\n            _022_10_21_markdown_future.a_little_markdown_program.\u03b4\u03f5\u03b1\u03c4\u03ba\n        )\n</code></pre> <pre>Overwriting a-little-markdown-program.md\n</pre> <pre><code>gantt \ntitle Literacy in computer programming\ndateFormat YYYY\naxisFormat %Y\n\nsection moderninity\nunderstanding media :mcluhan, 1964, 2022\nmother of all demos :englebert, 1968, 2022\nsection post moderninity\nliterate programming :knuth, 1984, 2022\nliterary machines :nelson, 1987, 2022\nwww :tbl, 1989, 2022\n\nsection post web\ncomputer programming for everybody :cp4e, 1999, 2022\nipython :fperez, 2001, 2022\nmarkdown :gruber, 2004, 2022\nipython notebooks :ipynb, 2011, 2022\nanaconda :ana, 2012, 2022\nliterate computing :lc, 2013, 2022\nunderstanding computer programming as a literacy :vee, 2013, 2022\nthe birth &amp; death of javascript: js, 2014, 2022\nbig split :split, 2015, 2022\njupyterlab :lab, 2018, 2022\njupyterlite :lab, 2021, 2022\n\nclick vee href \"https://licsjournal.org/index.php/LiCS/article/view/794/608\"\nclick knuth href \"http://www.literateprogramming.com/knuthweb.pdf\"\nclick nelson href \"https://monoskop.org/images/b/be/Nelson_Ted_Literary_Machines_c1987_chs_0-1.pdf\"\nclick lc href \"https://web.archive.org/web/20220510083647/http://blog.fperez.org/2013/04/literate-computing-and-computational.html\"\nclick cp4e href \"https://www.python.org/doc/essays/cp4e/\"\n\n</code></pre> <pre><code>flowchart LR\nweb-- tangle ---pas\npas-- pascal ---rel\nweb-- weave ---tex\ntex-- TEX ---dvi</code></pre> <pre>&lt;module '2022-10-21-markdown-future' from '/home/tbone/Documents/tonyfast/tonyfast/xxii/oct/2022-10-21-markdown-future.ipynb'&gt;</pre> <pre>&lt;module 'a-little-markdown-program' from '/home/tbone/Documents/tonyfast/tonyfast/xxii/oct/a-little-markdown-program.md'&gt;</pre> <pre>'death to pseudo code, long live pseudo code'</pre>"},{"location":"xxii/oct/2022-10-21-markdown-future.html#reusing-and-importing-notebooks","title":"reusing and importing notebooks","text":"<p>we can import this presentation.</p> <pre><code>    import midgy.loader\n    with midgy.loader.Markdown(extensions=[\".ipynb\", \".md\"]):\n        import _022_10_21_markdown_future\n    \"__file__\" not in locals() and display(\n        _022_10_21_markdown_future,\n        _022_10_21_markdown_future.a_little_markdown_program,\n        _022_10_21_markdown_future.a_little_markdown_program.\u03b4\u03f5\u03b1\u03c4\u03ba\n    )\n</code></pre> <pre><code>### what about reusing that diagram\n\n\n    display(\n        IPython.display.Markdown(_022_10_21_markdown_future.history),\n        IPython.display.Markdown(_022_10_21_markdown_future.knit)\n    )\n</code></pre> <pre><code>gantt \ntitle Literacy in computer programming\ndateFormat YYYY\naxisFormat %Y\n\nsection moderninity\nunderstanding media :mcluhan, 1964, 2022\nmother of all demos :englebert, 1968, 2022\nsection post moderninity\nliterate programming :knuth, 1984, 2022\nliterary machines :nelson, 1987, 2022\nwww :tbl, 1989, 2022\n\nsection post web\ncomputer programming for everybody :cp4e, 1999, 2022\nipython :fperez, 2001, 2022\nmarkdown :gruber, 2004, 2022\nipython notebooks :ipynb, 2011, 2022\nanaconda :ana, 2012, 2022\nliterate computing :lc, 2013, 2022\nunderstanding computer programming as a literacy :vee, 2013, 2022\nthe birth &amp; death of javascript: js, 2014, 2022\nbig split :split, 2015, 2022\njupyterlab :lab, 2018, 2022\njupyterlite :lab, 2021, 2022\n\nclick vee href \"https://licsjournal.org/index.php/LiCS/article/view/794/608\"\nclick knuth href \"http://www.literateprogramming.com/knuthweb.pdf\"\nclick nelson href \"https://monoskop.org/images/b/be/Nelson_Ted_Literary_Machines_c1987_chs_0-1.pdf\"\nclick lc href \"https://web.archive.org/web/20220510083647/http://blog.fperez.org/2013/04/literate-computing-and-computational.html\"\nclick cp4e href \"https://www.python.org/doc/essays/cp4e/\"\n\n</code></pre> <pre><code>flowchart LR\nweb-- tangle ---pas\npas-- pascal ---rel\nweb-- weave ---tex\ntex-- TEX ---dvi</code></pre>"},{"location":"xxii/oct/2022-10-21-markdown-future.html#what-about-reusing-that-diagram","title":"what about reusing that diagram","text":"<pre><code>display(\n    IPython.display.Markdown(_022_10_21_markdown_future.history),\n    IPython.display.Markdown(_022_10_21_markdown_future.knit)\n)\n</code></pre> <pre><code>i'm not saying importing markdown or notebooks is a good idea. \ncoffeescript died didn't it?\nsometimes it is too soon.\nit can be done and some folks might thrive working that way.\n</code></pre> <p>i'm not saying importing markdown or notebooks is a good idea.  coffeescript died didn't it? sometimes it is too soon. it can be done and some folks might thrive working that way.</p> <pre><code>### an inclusive future for code\n\n![](https://pbs.twimg.com/media/FfmxiqlaAAIzTvT?format=jpg&amp;name=large)\n\nin this demo, we used markdown and notebooks for source.\n\nliterate programs explicitly define a document and program language.\nnotebooks are literate programs.\nthere are times when when code and narrative are inseparable.\n\n```future\ndocker up my-paper.pdf # can a paper contain containers?\nimportpdf my-paper --input-file my-data.csv # could you run a pdf with your data?\n\nwith importdocx():\n    import my_word_document # https://nbviewer.org/github/deathbeds/deathbeds.github.io/blob/master/deathbeds/2019-03-08-say-word.ipynb\n```\n</code></pre>"},{"location":"xxii/oct/2022-10-21-markdown-future.html#an-inclusive-future-for-code","title":"an inclusive future for code","text":"<p>in this demo, we used markdown and notebooks for source.</p> <p>literate programs explicitly define a document and program language. notebooks are literate programs. there are times when when code and narrative are inseparable.</p> <pre><code>docker up my-paper.pdf # can a paper contain containers?\nimportpdf my-paper --input-file my-data.csv # could you run a pdf with your data?\n\nwith importdocx():\n    import my_word_document # https://nbviewer.org/github/deathbeds/deathbeds.github.io/blob/master/deathbeds/2019-03-08-say-word.ipynb\n</code></pre> <pre><code>## the power of markdown\n\noften notebooks or markdown are means not an ends.\n\n* how many agendas have we made in `hackmd`?\n* how many `README`s guided our way?\n* how much good code is lost in notebooks?\n</code></pre>"},{"location":"xxii/oct/2022-10-21-markdown-future.html#the-power-of-markdown","title":"the power of markdown","text":"<p>often notebooks or markdown are means not an ends.</p> <ul> <li>how many agendas have we made in <code>hackmd</code>?</li> <li>how many <code>README</code>s guided our way?</li> <li>how much good code is lost in notebooks?</li> </ul> <p></p> <pre><code>    def qr(url, size=8):\n        q = __import__(\"qrcode\").QRCode(version=1, error_correction=1,\n                          box_size=size, border=1, mask_pattern=None,)\n        q.add_data(url), q.make()\n        return q.make_image()\n</code></pre> <pre><code>## what if the code was just the start something?\n\ny'all, like all y'all can modify this document in jupyterlite on github pages.\n\n&lt;style&gt;\n[data-mime-type=\"image/png\"] img {\n    max-width: 200px; max-height: 200px;\n}\n&lt;/style&gt;\n\n    qr(        \nhttps://tonyfast.github.io/tonyfast/run/lab/index.html?path=xxii/oct/2022-10-21-markdown-future.ipynb&amp;room=deathbeds-more-like-deft-breads\n\n    )\n</code></pre>"},{"location":"xxii/oct/2022-10-21-markdown-future.html#what-if-the-code-was-just-the-start-something","title":"what if the code was just the start something?","text":"<p>y'all, like all y'all can modify this document in jupyterlite on github pages.</p> <pre><code>qr(\n</code></pre> <p>https://tonyfast.github.io/tonyfast/run/lab/index.html?path=xxii/oct/2022-10-21-markdown-future.ipynb&amp;room=deathbeds-more-like-deft-breads</p> <pre><code>)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"xxii/oct/2022-10-21-pidgy-displays.html","title":"literate computing - interactive literate programming","text":"<p>literate computing relies on a rapid feedback from the computer. <code>pidgy</code> features multiple reactive/interactive displays for presenting your content. we'll explore the displays and meaning with two demos: 1. the cookies demo 2. the dataframe demo</p>"},{"location":"xxii/oct/2022-10-21-pidgy-displays.html#cookies-demo","title":"cookies demo","text":"<p>the cookies demo is mainstay in the deathbeds repertoire. inspired by bret viktors tanglejs we explore the cookie demo in <code>pidgy</code>.</p> <pre><code>    %reload_ext pidgy\n    import pidgy\n    shell.displays_manager.template_cls = pidgy.weave.IPyWidgetsHtml\n</code></pre> <pre>HTML(value='&lt;pre&gt;&lt;code&gt;%reload_ext pidgy\\nimport pidgy\\nshell.displays_manager.template_cls = pidgy.weave.IPyW\u2026</pre> <pre><code>    cookies = IntSlider(3)\n</code></pre> <pre>HTML(value='&lt;pre&gt;&lt;code&gt;cookies = IntSlider(3)&lt;/code&gt;&lt;/pre&gt;\\n')</pre> <pre><code>&lt;style&gt;\n#hunger {\n    opacity: {{cookies.value/20}};\n    font-size: {{cookies.value/20}}rem;\n    background-image: url(\"https://media4.giphy.com/media/BsUORZkF3gBqg/giphy.gif\");\n    background-size: cover;\n}\n&lt;/style&gt;\n</code></pre> <pre>HTML(value='&lt;style&gt;\\n#hunger {\\n    opacity: 0.15;\\n    font-size: 0.15rem;\\n    background-image: url(\"https:\u2026</pre> <pre><code>&lt;div id=\"hunger\"&gt;cookies!\ncookies!\ncookies!\n&lt;/div&gt;\n</code></pre> <pre>HTML(value='&lt;div id=\"hunger\"&gt;cookies!\\ncookies!\\ncookies!\\n&lt;/div&gt;')</pre> <pre><code>if i eat {{cookies.value}} then i consume {{cookies.value*50}} calories.\n\n    shell.displays_manager.template_cls = pidgy.weave.IPyWidgetsHtml\n</code></pre> <pre>HTML(value='&lt;p&gt;if i eat 3 then i consume 150 calories.&lt;/p&gt;\\n&lt;pre&gt;&lt;code&gt;shell.displays_manager.template_cls = p\u2026</pre> <pre><code>if i eat {{cookies.value}} then i consume {{cookies.value*50}} calories.\n\n    shell.displays_manager.template_cls = pidgy.weave.IPythonHtml\n</code></pre> <p>if i eat 3 then i consume 150 calories.</p> <pre><code>shell.displays_manager.template_cls = pidgy.weave.IPythonHtml</code></pre> <pre><code>if i eat {{cookies.value}} then i consume {{cookies.value*50}} calories.\n\n    shell.displays_manager.template_cls = pidgy.weave.IPythonMarkdown\n</code></pre> <p>if i eat 3 then i consume 150 calories.</p> <pre><code>shell.displays_manager.template_cls = pidgy.weave.IPythonMarkdown\n</code></pre> <pre><code>    cookies\n</code></pre> <pre>IntSlider(value=3)</pre> <pre><code>cookies\n</code></pre>"},{"location":"xxii/oct/2022-10-21-pidgy-displays.html#dataframes","title":"Dataframes","text":"<pre><code>    from ipywidgets import interact_manual\n</code></pre> <pre><code>from ipywidgets import interact_manual\n</code></pre> <pre><code>    import pandas\n    who = Text(\"tonyfast\")   \n</code></pre> <pre><code>import pandas\nwho = Text(\"tonyfast\")\n</code></pre> <pre><code>    shell.displays_manager.template_cls = pidgy.weave.IPyWidgetsHtml\n{{g.T}}\n</code></pre> <pre>HTML(value='&lt;pre&gt;&lt;code&gt;shell.displays_manager.template_cls = pidgy.weave.IPyWidgetsHtml\\n&lt;/code&gt;&lt;/pre&gt;\\n&lt;p&gt;&lt;co\u2026</pre> <pre><code>    shell.displays_manager.template_cls = pidgy.weave.IPythonHtml\n{{g.T}}\n</code></pre> <pre><code>shell.displays_manager.template_cls = pidgy.weave.IPythonHtml\n</code></pre> <p><code>g is undefined</code></p> <pre><code>    shell.displays_manager.template_cls = pidgy.weave.IPythonMarkdown\n{{g.T}}\n</code></pre> <pre><code>shell.displays_manager.template_cls = pidgy.weave.IPythonMarkdown\n</code></pre> <p><code>g is undefined</code></p> <pre><code>g = df.iloc[:5, :5]\n</code></pre> <pre><code>    def update(who):\n        global df, g\n        g = df = pandas.read_json(F\"https://api.github.com/users/{who}/gists\")\n    interact_manual(update, who=who)\n</code></pre> <pre>interactive(children=(Text(value='tonyfast', description='who'), Button(description='Run Interact', style=Butt\u2026</pre> <pre>&lt;function __main__.update(who)&gt;</pre> <pre><code>def update(who):\n    global df, g\n    g = df = pandas.read_json(F\"https://api.github.com/users/{who}/gists\")\ninteract_manual(update, who=who)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"xxii/oct/2022-10-25-static-notebook-tags.html","title":"post processing html accessibility","text":"<p>this demo illustrates how an <code>nbconvert</code> template's html can be editted directly using <code>BeautifulSoup</code></p> <p>these concepts intersect multiple outstanding issues: * https://github.com/Iota-School/notebooks-for-all/issues/19#issuecomment-1251245078 * https://github.com/Iota-School/notebooks-for-all/issues/15 * https://github.com/Iota-School/notebooks-for-all/issues/20</p> <pre><code>    import nbconvert_html5\n    from bs4 import BeautifulSoup\n    from pathlib import Path\n</code></pre>"},{"location":"xxii/oct/2022-10-25-static-notebook-tags.html#jupyter-selectors","title":"jupyter selectors","text":"<p>we need to collect these across representations <code>nbconvert (lab/class), nbviewer, sphinx, mkdocs</code></p> <pre><code>    MAIN = \"#notebook, .jp-Notebook\"\n    CELL = \".cell, .jp-Cell\"\n    CODE = \".code_cell, .jp-CodeCell\"\n    MD = \".text_cell, .jp-MarkdownCell\"\n    OUT = \".output, .jp-OutputArea.jp-Cell-outputArea\"\n    IN = \".code_cell .input .input_area, .jp-Editor\"\n    PROMPT = \".input_prompt\"\n</code></pre>"},{"location":"xxii/oct/2022-10-25-static-notebook-tags.html#the-html5-exporter","title":"the <code>Html5</code> exporter","text":"<p>currently the class does not change anything but exposes an api from directly modify exported html.</p> <pre><code>    old = nbconvert_html5.Html5().from_filename(\"2022-10-25-static-notebook-tags.ipynb\")[0]\n    source = Path(\"indexed-source.html\"); source.write_text(old)\n</code></pre> <pre>603500</pre>"},{"location":"xxii/oct/2022-10-25-static-notebook-tags.html#jupyter-remediations-for-landmarks","title":"<code>jupyter</code> remediations for landmarks","text":"<p>we are exploring the efficacy of html5 conventions to provide accessibility landmarks in the jupyter notebook. we'll modify: * the primary container * cell inputs and outputs * executin counts</p> <pre><code>    def set_notebook(soup):\n        set_main(soup); set_cells(soup); set_inputs(soup); set_prompts(soup)\n\n    def get_html(x, **k):\n        soup = BeautifulSoup(x, features=\"lxml\"); set_notebook(soup)\n        return str(soup)\n</code></pre>"},{"location":"xxii/oct/2022-10-25-static-notebook-tags.html#the-setters","title":"the <code>setters</code>","text":"<pre><code>    def set_main(soup):\n        e = soup.select_one(MAIN)\n        e.attrs.pop(\"tabindex\", None)\n        e.name = \"main\"\n\n    def set_main_aside(soup):\n\"\"\"[Move Metadata to the top](https://github.com/Iota-School/notebooks-for-all/issues/21)\"\"\"\n\n    def set_cells(soup):\n        for element in soup.select(CODE):\n            set_code_cell(element)\n        for element in soup.select(MD):\n            set_md_cell(element)\n\n    def set_code_cell(e):        \n        e.name = \"article\"\n        # in multi kernel scenarios are cell magics the input might vary\n        e.attrs.setdefault(\"aria-label\", \"code cell\")\n\n    def set_md_cell(e):\n        e.name = \"article\"\n        e.attrs.setdefault(\"aria-label\", \"markdown cell\")\n\n    def set_displays(e):\n\"\"\"introduces a section tag to the outputs\"\"\"\n\n        out = e.select_one(OUT)\n        out.name = \"section\"\n        e.attrs.setdefault(\"aria-label\", \"code outputs\")\n\n    def set_inputs(soup):\n        for inp in soup.select(IN):\n            inp.replace_with(BeautifulSoup(F\"&lt;code&gt;&lt;pre&gt;{inp.text}&lt;/pre&gt;&lt;/code&gt;\", features=\"lxml\").select_one(\"code\"))\n\n    def set_prompts(soup):\n\"\"\"https://github.com/Iota-School/notebooks-for-all/issues/20#issuecomment-1247172797\"\"\"\n\n        for prompt in soup.select(PROMPT):\n            prompt.name = \"aside\"\n</code></pre>"},{"location":"xxii/oct/2022-10-25-static-notebook-tags.html#running-the-post-processor","title":"Running the post processor","text":"<pre><code>    new = nbconvert_html5.Html5(post_processor=get_html).from_filename(\"2022-10-25-static-notebook-tags.ipynb\")[0]\n    target = Path(\"indexed-target.html\"); target.write_text(new);\n</code></pre>"},{"location":"xxii/oct/2022-10-25-static-notebook-tags.html#analysis-in-a-headless-browser","title":"analysis in a headless browser","text":"<pre><code>    async def get_headless(file):\n        import playwright.async_api\n        from shlex import split\n        async with playwright.async_api.async_playwright() as play:\n            browser = await play.chromium.launch(\n                args=split('--enable-blink-features=\"AccessibilityObjectModel\"'),\n                headless=True, \n                channel=\"chrome-beta\"\n            )\n            page = await browser.new_page()\n            state = await page.goto(file.absolute().as_uri())\n            data = await page.accessibility.snapshot()\n            await browser.close()\n        return data\n</code></pre>"},{"location":"xxii/oct/2022-10-25-static-notebook-tags.html#comparing-results","title":"comparing results","text":"<pre><code>import pandas\ndf = pandas.DataFrame(await get_headless(source)); df\n\n\n\nA = df.children.apply(pandas.Series).set_index(\"role\")\nB = pandas.DataFrame(await get_headless(target)).children.apply(pandas.Series).set_index(\"role\")\ndisplay(\"old\", A.T, \"new\", B.T)\n</code></pre>"},{"location":"xxii/oct/2022-10-25-static-notebook-tags.html#usage-in-manual-testing","title":"usage in manual testing","text":"<p><code>nbconvert_html5</code> has the hooks to work with <code>jupyter</code>s normal command line tool.</p> <pre><code>    %%file jupyter_nbconvert_config.py\n    from unittest.mock import Mock    \n    c = locals().get(\"c\", Mock()) \n    with __import__(\"importnb\").Notebook():\n        from __static_notebook_tags import get_html\n    c.TemplateExporter.post_processor = get_html\n\n    # or put your methods in here. \n    # what are the A/B tests today?\n</code></pre> <pre>Writing jupyter_nbconvert_config.py\n</pre> <pre><code>    if __name__ == \"__main__\" and \"__file__\" not in locals():\n        !jupyter nbconvert --to html5 --stdout 2022-10-25-static-notebook-tags.ipynb\n</code></pre> <pre>[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.\n</pre> <pre><code>\n</code></pre>"},{"location":"xxii/oct/2022-10-27-axe-core-playwright-python.html","title":"invoking axe-core from python playwright","text":"<p>javascript is not my jam. id rather write python. this post is a result of these inconsistencies.</p> <p>in my accessibility, i often need to test the accessibility of a web page. the javascript way to this is to run using playwright and playwright-axe together.</p> <p>i couldn't find an evident way to do that. instead i peaked into the playwright-axe integration and realizes we could invoke axe through python by copying a little bit.</p>"},{"location":"xxii/oct/2022-10-27-axe-core-playwright-python.html#auditting-an-html-file","title":"auditting an html file","text":"<ol> <li>create a headless playwright browser</li> <li>load the page</li> <li>inject axe-core</li> <li>audit the page</li> <li>close the browser</li> </ol> <pre><code>    from pathlib import Path\n</code></pre> <pre><code>async def audit(file, **config):\n    import playwright.async_api\n    async with playwright.async_api.async_playwright() as play:\n        browser, page = await get_browser_page(play)\n        await page.goto(Path(file).absolute().as_uri())\n        await __import__(\"asyncio\").sleep(3)\n        await injectReadability(page)\n        # await injectAxe(page)\n        # data = await get_audit_data(page, **config)\n        await __import__(\"asyncio\").sleep(30)\n        await browser.close()\n    return data\n</code></pre> <pre><code>async def injectReadability(page): \n    await page.evaluate(requests.get(\"https://raw.githubusercontent.com/mozilla/readability/master/Readability.js\").text)\n    status = await page.evaluate(\"\"\"async () =&gt; {\n      const readability = await import('https://cdn.skypack.dev/@mozilla/readability');\n      return (new readability.Readability(document)).parse();\n    }\"\"\")\n</code></pre> <pre><code>        await audit(\"better.html\")\n</code></pre> <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In [15], line 1\n----&gt; 1 await audit(\"better.html\")\n\nCell In [11], line 7, in audit(file, **config)\n      5 await page.goto(Path(file).absolute().as_uri())\n      6 await __import__(\"asyncio\").sleep(3)\n----&gt; 7 await injectReadability(page)\n      8 # await injectAxe(page)\n      9 # data = await get_audit_data(page, **config)\n     10 await __import__(\"asyncio\").sleep(30)\n\nCell In [12], line 2, in injectReadability(page)\n      1 async def injectReadability(page): \n----&gt; 2     await page.evaluate(requests.get(\"https://raw.githubusercontent.com/mozilla/readability/master/Readability.js\").text)\n      3     status = await page.evaluate(\"\"\"async () =&gt; {\n      4       const readability = await import('https://cdn.skypack.dev/@mozilla/readability');\n      5       return (new readability.Readability(document)).parse();\n      6     }\"\"\")\n\nNameError: name 'requests' is not defined</pre> <pre><code>async def get_browser_page(play, **options):\n    from shlex import split\n    browser = await play.chromium.launch(\n        args=split('--enable-blink-features=\"AccessibilityObjectModel\"'),\n        headless=False,  channel=\"chrome-beta\")\n    return browser, await browser.new_page()\n</code></pre> <p><code>injectAxe</code> mimics how <code>playwright-axe</code> loads the package. we used a cached requests object vendored from unpkg</p> <pre><code>async def injectAxe(page): \n    await page.evaluate(requests.get(\"https://unpkg.com/axe-core\").text)\n</code></pre> <pre><code>async def injectReadability(page): \n    await page.evaluate(requests.get(\"https://raw.githubusercontent.com/mozilla/readability/master/Readability.js\").text)\n    status = await page.evaluate(\"\"\"var article = new Readability(document).parse();\"\"\")\n</code></pre> <p><code>get_audit_data</code> extracts the axe test results and the accesssbility tree from the page.</p> <pre><code>async def get_audit_data(page, **config):\n    from json import dumps\n    return await __import__(\"asyncio\").gather(\n        page.evaluate(F\"window.axe.run(window.document, {dumps(config)})\"),\n        page.accessibility.snapshot())\n</code></pre>"},{"location":"xxii/oct/2022-10-27-axe-core-playwright-python.html#testing-a-page","title":"testing a page","text":"<p>we use this notebook as the test artifact by generating an html version of it with <code>nbconvert</code></p> <pre><code>    import requests_cache, requests, pandas;  requests_cache.install_cache(\"a11y\")\n    from pathlib import Path\n    THIS = Path(\"2022-10-27-axe-core-playwright-python.ipynb\")\n    if __name__ == \"__main__\":\n        !jupyter nbconvert --to html $THIS\n</code></pre> <pre>[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.\n[NbConvertApp] Converting notebook 2022-10-27-axe-core-playwright-python.ipynb to html\n[NbConvertApp] Writing 605344 bytes to 2022-10-27-axe-core-playwright-python.html\n</pre>"},{"location":"xxii/oct/2022-10-27-axe-core-playwright-python.html#getting-the-accessibility-audit-objects","title":"getting the accessibility audit objects","text":"<p><code>axe</code> contains the axe test data and <code>tree</code> contains the accessibility tree.</p> <pre><code>    axe, tree = map(pandas.Series, await audit(THIS.with_suffix(\".html\"), runOnly=\"best-practice\".split()))\n</code></pre>"},{"location":"xxii/oct/2022-10-27-axe-core-playwright-python.html#axe-violations","title":"axe violations","text":"<pre><code>    pandas.DataFrame(axe.violations)\n</code></pre> id impact tags description help helpUrl nodes 0 landmark-one-main moderate [cat.semantics, best-practice] Ensures the document has a main landmark Document should have one main landmark https://dequeuniversity.com/rules/axe/4.5/land... [{'any': [], 'all': [{'id': 'page-has-main', '... 1 region moderate [cat.keyboard, best-practice] Ensures all page content is contained by landm... All page content should be contained by landmarks https://dequeuniversity.com/rules/axe/4.5/regi... [{'any': [{'id': 'region', 'data': {'isIframe'..."},{"location":"xxii/oct/2022-10-27-axe-core-playwright-python.html#accessibility-tree","title":"accessibility tree","text":"<pre><code>    pandas.DataFrame(tree.children)\n</code></pre> role name level 0 text Loading [MathJax]/jax/output/CommonHTML/fonts/... NaN 1 heading invoking axe-core from python playwright 1.0 2 text javascript is not my jam. id rather write pyth... NaN 3 text in my accessibility, i often need to test the ... NaN 4 text i couldn't find an evident way to do that. ins... NaN ... ... ... ... 275 text . NaN 276 text children NaN 277 text ) NaN 278 heading conclusion 2.0 279 text we can run axe in python playwright and analyz... NaN <p>280 rows \u00d7 3 columns</p>"},{"location":"xxii/oct/2022-10-27-axe-core-playwright-python.html#conclusion","title":"conclusion","text":"<p>we can run axe in python playwright and analyze results in pandas.</p>"},{"location":"xxii/oct/2022-10-29-metadata-formatter.html","title":"inferring linked data from <code>IPython</code> run times.","text":"<p>automatically exporting rdf data during interactive computing.</p> <p>we'll modify <code>IPython</code>s display formatter to include a system that describes python objects as <code>json</code> linked data.</p> <pre><code>    from functools import singledispatch, singledispatchmethod\n    import types, gc, re, sys\n    from IPython.core.formatters import DisplayFormatter, BaseFormatter, catch_format_error, JSONFormatter\n    from traitlets import ObjectName, Unicode, Instance, List, Any\n    from IPython import get_ipython\n    from pathlib import Path\n\n    TYPE, ID, GRAPH, CONTAINER, NEST, CONTEXT = \"@type @id @graph @container @nest @context\".split()\n    MAIN = __name__ == \"__main__\"\n    ACTIVE = \"__file__\" not in locals() and MAIN\n    shell = get_ipython()\n</code></pre> <p>a <code>MetadataFormatter</code> for including linked data in <code>IPython</code> reprs. this class carries machinery to generate:</p> <ul> <li>ids for python types and objects as urns <code>MetadataFormatter.get_id</code></li> <li>linked data representations of python objects with <code>MetadataFormatter.get_graph</code></li> </ul> <p><code>MetadataFormatter.for_type, MetadataFormatter.get_id.register, MetadataFormatter.get_graph.register</code> extra the expression of the linked data graphs.</p>"},{"location":"xxii/oct/2022-10-29-metadata-formatter.html#custom-metadata-formatter","title":"custom metadata formatter","text":"<pre><code>    class MetadataFormatter(BaseFormatter):\n        graph, format_type,  = List(), Unicode('application/ld+json') \n        _return_type, print_method = (list, dict), ObjectName('_repr_metadata_')\n\n        @singledispatchmethod\n        def get_id(self, object): return next(self.get_object(object), None)\n\n        @singledispatchmethod\n        def get_graph(self, object):\n            data = {TYPE: self.get_id(type(object))}\n            id = self.get_id(object)\n            if id: \n                data.setdefault(ID, id)\n                if isinstance(id, list): return [{ID: x, **data} for x in id]\n            return data\n\n        def get_object(self, object, filter=None):\n            if isinstance(filter, str): filter = re.compile(filter)\n            for referrer in (x for x in gc.get_referrers(object) if isinstance(x, dict)):\n                yield from self.get_object_from_ns(referrer, object, filter=filter)\n\n        def get_object_from_ns(self, ns, object, filter=None):\n            weakref = ns.get(\"__weakref__\")\n            parent = None\n            if weakref: parent = self.get_id(weakref.__objclass__)\n            else:\n                parent = ns.get(\"__module__\", ns.get(\"__name__\"))\n                if parent: parent += \":\"\n\n            if not parent and ns is sys.modules:\n                return object.__name__\n\n            for k in (k for k, v in ns.items() if v is object and not k.startswith(\"_\")): \n                name = F\"{parent or 'noparent'}#{k}\"\n                if filter is not None and not filter.match(name): continue\n                yield name\n\n        def get_session_cell_id(self):\n            data = get_ipython().kernel.get_parent()\n            return data[\"metadata\"][\"cellId\"], data[\"header\"][\"session\"]\n\n        def set_metadata(self, object=None, **kwargs):\n            ids = dict(zip((\"cell:id\", \"session:id\"), self.get_session_cell_id()))\n            node = {} if object is None else self.get_graph(object)\n            if isinstance(node, dict): node = [node]\n            for node in node:\n                self.graph.append({**ids, **node, **kwargs})\n\n\n        def __call__(self, object):\n            explicit = super().__call__(object)\n            if explicit:\n                if isinstance(explicit, dict): self.set_metadata(**explicit)\n                else: \n                    for e in explicit: self.set_metadata(**w)\n            else: self.set_metadata(object)\n            try: return self.graph[:]\n            finally: self.graph.clear()\n</code></pre>"},{"location":"xxii/oct/2022-10-29-metadata-formatter.html#custom-display-formatter","title":"custom display formatter","text":"<p>the <code>LinkedDataFormatter</code> customizes how <code>IPython</code>s normal <code>DisplayFormatter</code> expresses metadata.</p> <pre><code>    class LinkedDataFormatter(DisplayFormatter):\n        metadata_formatter = Instance(MetadataFormatter, args=())\n        def format(self, object, include=None, exclude=None):\n            data, meta = super().format(object, include, exclude)\n            g = self.metadata_formatter(object)\n            if g: meta[GRAPH] = g\n            return data, meta\n\n    def load_ipython_extension(shell=get_ipython()):\n        shell.display_formatter = LinkedDataFormatter(**shell.display_formatter._trait_values)\n        shell.user_ns[\"set_metadata\"] = shell.display_formatter.metadata_formatter.set_metadata\n\n    def unload_ipython_extension(shell=get_ipython()):\n        shell.display_formatter = DisplayFormatter(**shell.display_formatter._trait_values)\n</code></pre> <p>extend how the graph is generated for tuples and strings as examples.</p> <pre><code>    @MetadataFormatter.get_graph.register(tuple)\n    def get_graph_tuple(self, object): return list(map(self.get_graph, object))\n</code></pre> <p>register a different id for modules. we use their namespaces for expansion later.</p> <pre><code>    @MetadataFormatter.get_id.register(types.ModuleType)\n    def get_name(self, object): return object.__name__\n</code></pre> <p>activate the display formatter</p> <pre><code>    ACTIVE and load_ipython_extension()\n</code></pre>"},{"location":"xxii/oct/2022-10-29-metadata-formatter.html#some-data-for-the-graph","title":"some data for the graph","text":""},{"location":"xxii/oct/2022-10-29-metadata-formatter.html#dataframes","title":"dataframes","text":"<p>create a custom graph expression for <code>pandas.DataFrame</code>s</p> <pre><code>    import pandas\n\n    if ACTIVE:\n        shell.display_formatter.metadata_formatter.get_graph.register(pandas.DataFrame\n        )(lambda s, x: {ID: s.get_id(x), TYPE: s.get_id(type(x)), \"pandas.DataFrame:shape\": list(x.shape)})\n</code></pre> <pre><code>    if ACTIVE:\n        import pandas\n        df = pandas.DataFrame()\n        display((df, pandas, pandas.DataFrame))\n</code></pre> <pre>(Empty DataFrame\n Columns: []\n Index: [],\n &lt;module 'pandas' from '/home/tbone/mambaforge/lib/python3.9/site-packages/pandas/__init__.py'&gt;,\n pandas.core.frame.DataFrame)</pre>"},{"location":"xxii/oct/2022-10-29-metadata-formatter.html#string-or-url","title":"string or url","text":"<p>if there is a url hidden in a string we can elevate that as metadata thereby linked it to a cell.</p> <p>for example, this work revists https://nbviewer.org/gist/tonyfast/16d3bc82d69890949212b46040bd86e1 so we'll include that in the graph.</p> <pre><code>    @MetadataFormatter.get_id.register(str)\n    def get_graph_str(self, object): \n        from urllib.parse import urlparse\n        parsed = urlparse(object)\n        if parsed.scheme:\n            return object\n    \"https://nbviewer.org/gist/tonyfast/16d3bc82d69890949212b46040bd86e1\"\n</code></pre> <pre>'https://nbviewer.org/gist/tonyfast/16d3bc82d69890949212b46040bd86e1'</pre>"},{"location":"xxii/oct/2022-10-29-metadata-formatter.html#looking-at-the-metadata-graph","title":"looking at the metadata graph","text":"<p>our choice of \"@id\" and \"@type\" are jsonld conventions. through these conventions we can surface the metadata by creating a <code>jsonld</code> context. we can ensure a consistent structure of the notebook and thereby context.</p> <pre><code>    ctx = {\n        \"cells\": {\n            ID: \"nb:cell\", CONTAINER: \"@list\", \n            CONTEXT: {\n                \"outputs\": {CONTEXT: {\"metadata\": NEST}, ID: \"cell:metadata\"},\n                \"id\": {ID: \"cell:id\", TYPE: ID},\n                \"cell_type\": \"cell:type\",\n                \"metadata\": {\n                    ID: \"cell:metadata\",\n                    CONTAINER: GRAPH,\n                    CONTEXT: {\n                        \"tags\": \"rdf:name\"\n                    }\n                },\n\n            }\n        },\n        \"@version\": 1.1}\n</code></pre> <pre><code>    if ACTIVE:\n        file = Path(\"2022-10-29-metadata-formatter.ipynb\")\n        data = __import__(\"json\").loads(file.read_text())\n</code></pre> <pre><code>    if ACTIVE:\n        from pyld import jsonld\n        from IPython.display import JSON\n        from_local = jsonld.compact(data, {}, options=dict(expandContext=ctx))\n        set_metadata(from_local, **{\"rdf:description\": \"all of the things we can expand from the notebook metadata.\"})\n        display(from_local)\n</code></pre> <pre>{'nb:cell': {'@list': [{'cell:id': {'@id': 'b89d004a-233f-452e-9da7-84604f291174'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': '1734421e-0762-47e6-8f5f-6f3468bf7b2f'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': '2f97b27e-f363-4dce-a2d5-45927c92feba'},\n    'cell:metadata': {'@graph': {'rdf:name': ['imports', 'constants']}},\n    'cell:type': 'code'},\n   {'cell:id': {'@id': 'd2ed9bc9-c426-4bb4-98fb-bf4f3d26c299'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': '1ea5f698-7263-4dc2-b24f-232e9f1dcfcd'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': 'cec19c6c-affe-4378-99d9-c927f8d2e726'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'code'},\n   {'cell:id': {'@id': '55478faa-bcc6-4447-9e28-607b2b6bafa6'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': '58291cbb-ce73-4bfa-b7ea-4c989090666a'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': '2069ae29-068c-4f0b-ab52-68ea31169358'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'code'},\n   {'cell:id': {'@id': '12548308-caf8-4760-8650-acc8fb13fa6d'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': '0aa91bd4-ef7e-4447-8572-f8e5db6af7fd'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'code'},\n   {'cell:id': {'@id': '22717127-56b3-4e8d-833e-21ba302cab49'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': '131bd548-e951-4a6e-b759-c7630bc6e20e'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'code'},\n   {'cell:id': {'@id': '4dc89ef5-0fd5-4510-9399-2a45ab27bef3'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': 'f121d061-df1c-4a41-8dac-de2ffabc54db'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'code'},\n   {'cell:id': {'@id': '01efe602-d5c1-4945-a3f7-fdae95ac4349'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': '50d9dcf9-18f4-4eb7-9a9a-cc3e14b3b2e2'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': 'f1227a1b-dbd7-4923-9f04-6b7db2e9828f'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': '37e64bd4-d119-470b-b480-44778d33c549'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'code'},\n   {'cell:id': {'@id': 'e3a8b43e-aaeb-4b7a-9ccb-4485ae0689a0'},\n    'cell:metadata': [{'@graph': {}},\n     {'@graph': [{'@id': '__main__:#df',\n        '@type': 'pandas.io.xml:#DataFrame',\n        'cell:id': 'e3a8b43e-aaeb-4b7a-9ccb-4485ae0689a0',\n        'pandas.DataFrame:shape': [0, 0],\n        'session:id': 'f96335f1-429c-4c08-a07e-9aa81224d66d'},\n       {'@id': 'pandas',\n        '@type': 'types:#ModuleType',\n        'cell:id': 'e3a8b43e-aaeb-4b7a-9ccb-4485ae0689a0',\n        'session:id': 'f96335f1-429c-4c08-a07e-9aa81224d66d'},\n       {'@id': 'pandas.io.xml:#DataFrame',\n        '@type': 'builtins:#type',\n        'cell:id': 'e3a8b43e-aaeb-4b7a-9ccb-4485ae0689a0',\n        'session:id': 'f96335f1-429c-4c08-a07e-9aa81224d66d'}]}],\n    'cell:type': 'code'},\n   {'cell:id': {'@id': 'e3dc5bdb-b499-4309-aa79-c0c333f97d56'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': 'db25096c-b1bb-40a1-9330-e58c96f77a6c'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': 'bc71a7c4-c872-454d-8616-64a741dee4f0'},\n    'cell:metadata': [{'@graph': {}},\n     {'@graph': {'@id': 'https://nbviewer.org/gist/tonyfast/16d3bc82d69890949212b46040bd86e1',\n       '@type': 'builtins:#str',\n       'cell:id': 'bc71a7c4-c872-454d-8616-64a741dee4f0',\n       'session:id': 'f96335f1-429c-4c08-a07e-9aa81224d66d'}}],\n    'cell:type': 'code'},\n   {'cell:id': {'@id': '67ce52b5-20b8-4adf-8518-6368d3c24303'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': 'c4377aed-7bb8-4fa1-8dd9-518ef22511a9'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'code'},\n   {'cell:id': {'@id': '24ee56a0-829c-4be6-8194-88e648e6ac11'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'code'},\n   {'cell:id': {'@id': 'fc202593-9a00-4f3b-9748-c5f48b7c475e'},\n    'cell:metadata': [{'@graph': {}},\n     {'@graph': [{'@id': '__main__:#from_local',\n        '@type': 'builtins:#dict',\n        'cell:id': 'fc202593-9a00-4f3b-9748-c5f48b7c475e',\n        'rdf:description': 'all of the things we can expand from the notebook metadata.',\n        'session:id': 'f96335f1-429c-4c08-a07e-9aa81224d66d'},\n       {'@id': '__main__:#from_local',\n        '@type': 'builtins:#dict',\n        'cell:id': 'fc202593-9a00-4f3b-9748-c5f48b7c475e',\n        'session:id': 'f96335f1-429c-4c08-a07e-9aa81224d66d'}]}],\n    'cell:type': 'code'},\n   {'cell:id': {'@id': '31d8a531-2334-4243-9c78-25137ce58637'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': '55ba1060-beca-4342-a780-db7fd9c8b5ac'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'code'},\n   {'cell:id': {'@id': '3e3d2b0b-81b5-4193-82d6-ec27bf37eaa2'},\n    'cell:metadata': [{'@graph': {}},\n     {'@graph': {'@id': '__main__:#from_remote',\n       '@type': 'builtins:#dict',\n       'cell:id': '3e3d2b0b-81b5-4193-82d6-ec27bf37eaa2',\n       'session:id': 'f96335f1-429c-4c08-a07e-9aa81224d66d'}}],\n    'cell:type': 'code'},\n   {'cell:id': {'@id': 'aa2688dd-5237-41ec-981a-7e9b8e2a67b0'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': 'b461d781-4ec6-4d4d-a49e-251e908421f5'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': '30103d50-0741-4a56-95e1-d49c880ef6c3'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'}]}}</pre> <p>when the post is published we can condense the notation.</p> <pre><code>    remote = \"https://raw.githubusercontent.com/tonyfast/tonyfast/main/tonyfast/xxii/oct/2022-10-29-metadata-formatter.ipynb\"; remote\n</code></pre> <pre>'https://raw.githubusercontent.com/tonyfast/tonyfast/main/tonyfast/xxii/oct/2022-10-29-metadata-formatter.ipynb'</pre> <pre><code>    if ACTIVE:\n        from_remote = jsonld.compact(\n            remote, {},\n            options=dict(expandContext=ctx)\n        )\n        display(from_remote)\n</code></pre> <pre>{'nb:cell': {'@list': [{'cell:id': {'@id': 'b89d004a-233f-452e-9da7-84604f291174'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': '1734421e-0762-47e6-8f5f-6f3468bf7b2f'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': '2f97b27e-f363-4dce-a2d5-45927c92feba'},\n    'cell:metadata': {'@graph': {'rdf:name': ['imports', 'constants']}},\n    'cell:type': 'code'},\n   {'cell:id': {'@id': 'd2ed9bc9-c426-4bb4-98fb-bf4f3d26c299'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': '1ea5f698-7263-4dc2-b24f-232e9f1dcfcd'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': 'cec19c6c-affe-4378-99d9-c927f8d2e726'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'code'},\n   {'cell:id': {'@id': '55478faa-bcc6-4447-9e28-607b2b6bafa6'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': '58291cbb-ce73-4bfa-b7ea-4c989090666a'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': '2069ae29-068c-4f0b-ab52-68ea31169358'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'code'},\n   {'cell:id': {'@id': '12548308-caf8-4760-8650-acc8fb13fa6d'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': '0aa91bd4-ef7e-4447-8572-f8e5db6af7fd'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'code'},\n   {'cell:id': {'@id': '22717127-56b3-4e8d-833e-21ba302cab49'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': '131bd548-e951-4a6e-b759-c7630bc6e20e'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'code'},\n   {'cell:id': {'@id': '4dc89ef5-0fd5-4510-9399-2a45ab27bef3'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': 'f121d061-df1c-4a41-8dac-de2ffabc54db'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'code'},\n   {'cell:id': {'@id': '01efe602-d5c1-4945-a3f7-fdae95ac4349'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': '50d9dcf9-18f4-4eb7-9a9a-cc3e14b3b2e2'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': 'f1227a1b-dbd7-4923-9f04-6b7db2e9828f'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': '37e64bd4-d119-470b-b480-44778d33c549'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'code'},\n   {'cell:id': {'@id': 'e3a8b43e-aaeb-4b7a-9ccb-4485ae0689a0'},\n    'cell:metadata': [{'@graph': {}},\n     {'@graph': [{'@id': '#df',\n        '@type': 'pandas.io.xml:#DataFrame',\n        'cell:id': 'e3a8b43e-aaeb-4b7a-9ccb-4485ae0689a0',\n        'pandas.DataFrame:shape': [0, 0],\n        'session:id': 'f96335f1-429c-4c08-a07e-9aa81224d66d'},\n       {'@id': 'pandas',\n        '@type': 'types:#ModuleType',\n        'cell:id': 'e3a8b43e-aaeb-4b7a-9ccb-4485ae0689a0',\n        'session:id': 'f96335f1-429c-4c08-a07e-9aa81224d66d'},\n       {'@id': 'pandas.io.xml:#DataFrame',\n        '@type': 'builtins:#type',\n        'cell:id': 'e3a8b43e-aaeb-4b7a-9ccb-4485ae0689a0',\n        'session:id': 'f96335f1-429c-4c08-a07e-9aa81224d66d'}]}],\n    'cell:type': 'code'},\n   {'cell:id': {'@id': 'e3dc5bdb-b499-4309-aa79-c0c333f97d56'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': 'db25096c-b1bb-40a1-9330-e58c96f77a6c'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': 'bc71a7c4-c872-454d-8616-64a741dee4f0'},\n    'cell:metadata': [{'@graph': {}},\n     {'@graph': {'@id': 'https://nbviewer.org/gist/tonyfast/16d3bc82d69890949212b46040bd86e1',\n       '@type': 'builtins:#str',\n       'cell:id': 'bc71a7c4-c872-454d-8616-64a741dee4f0',\n       'session:id': 'f96335f1-429c-4c08-a07e-9aa81224d66d'}}],\n    'cell:type': 'code'},\n   {'cell:id': {'@id': '67ce52b5-20b8-4adf-8518-6368d3c24303'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': 'c4377aed-7bb8-4fa1-8dd9-518ef22511a9'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'code'},\n   {'cell:id': {'@id': '24ee56a0-829c-4be6-8194-88e648e6ac11'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'code'},\n   {'cell:id': {'@id': 'fc202593-9a00-4f3b-9748-c5f48b7c475e'},\n    'cell:metadata': [{'@graph': {}},\n     {'@graph': [{'@id': '#from_local',\n        '@type': 'builtins:#dict',\n        'cell:id': 'fc202593-9a00-4f3b-9748-c5f48b7c475e',\n        'rdf:description': 'all of the things we can expand from the notebook metadata.',\n        'session:id': 'f96335f1-429c-4c08-a07e-9aa81224d66d'},\n       {'@id': '#from_local',\n        '@type': 'builtins:#dict',\n        'cell:id': 'fc202593-9a00-4f3b-9748-c5f48b7c475e',\n        'session:id': 'f96335f1-429c-4c08-a07e-9aa81224d66d'}]}],\n    'cell:type': 'code'},\n   {'cell:id': {'@id': '31d8a531-2334-4243-9c78-25137ce58637'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': '55ba1060-beca-4342-a780-db7fd9c8b5ac'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'code'},\n   {'cell:id': {'@id': '3e3d2b0b-81b5-4193-82d6-ec27bf37eaa2'},\n    'cell:metadata': [{'@graph': {}},\n     {'@graph': {'@id': '#from_remote',\n       '@type': 'builtins:#dict',\n       'cell:id': '3e3d2b0b-81b5-4193-82d6-ec27bf37eaa2',\n       'session:id': 'f96335f1-429c-4c08-a07e-9aa81224d66d'}}],\n    'cell:type': 'code'},\n   {'cell:id': {'@id': 'aa2688dd-5237-41ec-981a-7e9b8e2a67b0'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': 'b461d781-4ec6-4d4d-a49e-251e908421f5'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'},\n   {'cell:id': {'@id': '30103d50-0741-4a56-95e1-d49c880ef6c3'},\n    'cell:metadata': {'@graph': {}},\n    'cell:type': 'markdown'}]}}</pre> <p>this notebook is certified to have metadata</p>"},{"location":"xxii/oct/2022-10-29-metadata-formatter.html#things-we-capture","title":"things we capture","text":"<p>in this proof of concept we don't capture much, but we do expose machinery to test this concept further and extend.</p> <p>we capture:</p> <ul> <li>kernel session id which can verify the outputs are generated in the same session</li> <li>each cell id that makes it possible link back to the source cells.</li> <li>some python variable information.</li> </ul>"},{"location":"xxii/oct/2022-10-29-metadata-formatter.html#things-we-can-capture-in-the-graph","title":"things we can capture in the graph.","text":"<ul> <li>annotations are type to id mappings.</li> <li>we could trace function calls</li> <li>with could encode imports</li> <li>we could capture variable assignment</li> </ul>"},{"location":"xxii/oct/2022-11-17-assignment-expression-display.html","title":"using assignment expressions to display and assign in <code>IPython</code>","text":"<p>not all notebok users are aware that there are different implicit display conditions that can be configured with <code>IPython</code> with the <code>ast_node_interactivity</code> option</p> <pre><code>    shell = get_ipython()\n</code></pre> <p>by default, <code>shell.ast_node_interactivity</code> displays the last expressions</p> <pre><code>    shell.ast_node_interactivity\n</code></pre> <pre>'last_expr'</pre> <p>the other 5 options follow the code below</p> <pre><code>    shell.traits()[\"ast_node_interactivity\"].values\n</code></pre> <pre>['all', 'last', 'last_expr', 'none', 'last_expr_or_assign']</pre> <p>sometimes when i am debugging i want to store a variable and display it at the same. the <code>IPython</code> approach set <code>shell.ast_node_interactivity = \"last_expr_or_assign\"</code>. admittedly, i never choose this because i don't want it all the time, just while debugging.</p> <p>what i do instead is set the variable and append an implicit display at the end.</p> <pre><code>    my_variable = 42; my_variable\n</code></pre> <pre>42</pre> <p>i've shifted from this approach to using assignment expressions with make more sense.</p> <pre><code>    (my_variable := 42)\n</code></pre> <pre>42</pre> <p>it feels lispy and i like it.</p> <p>it feels good with some widgets too.</p> <pre><code>    (button := __import__(\"ipywidgets\").Button(description=\"a butt\"))\n</code></pre> <pre>Button(description='a butt', style=ButtonStyle())</pre>"},{"location":"xxii/oct/colormap-dataframes/2021-10-11-colorizing.html","title":"what do we learn when we make colormaps from dataframes","text":"<pre><code>    import pandas, numpy, toolz.curried as toolz\n</code></pre> <p>we'll begin with a small linear <code>domain</code> of values between 0..1.</p> <pre><code>    domain = numpy.linspace(0, 1, 11)\n</code></pre> <p>we'll focus on primary color components to start. from the primary components we can make a lot of colors. we combine the <code>domain</code> with empty values, to create triplets that will become our color.</p> <pre><code>    triples = list(map(numpy.array, zip(domain, domain*0, domain*0)))\n</code></pre> <p>we'll start with making <code>red</code>, with a focus on <code>rgb</code> values, as a series of triples between 0..255.</p> <pre><code>    red = pandas.Series(triples).apply(numpy.array).mul(255)\n    red\n</code></pre> <pre>0                    [0.0, 0.0, 0.0]\n1                   [25.5, 0.0, 0.0]\n2                   [51.0, 0.0, 0.0]\n3      [76.50000000000001, 0.0, 0.0]\n4                  [102.0, 0.0, 0.0]\n5                  [127.5, 0.0, 0.0]\n6     [153.00000000000003, 0.0, 0.0]\n7     [178.50000000000003, 0.0, 0.0]\n8                  [204.0, 0.0, 0.0]\n9                  [229.5, 0.0, 0.0]\n10                 [255.0, 0.0, 0.0]\ndtype: object</pre> <pre><code>    def rgb(x): \"format a pandas cells\"; return \"font-size: 0px; background-color: rgb(\" + \", \".join(\n            map(str, x)\n        ) + \");\"\n</code></pre> <p>why are we calling this value <code>red</code>?</p> <p>because we can explicitly the format for each cell and (255, 0, 0) is completely red.</p> <pre><code>    red.to_frame(\"red\").T.applymap(rgb)\n</code></pre> 0 1 2 3 4 5 6 7 8 9 10 red font-size: 0px; background-color: rgb(0.0, 0.0... font-size: 0px; background-color: rgb(25.5, 0.... font-size: 0px; background-color: rgb(51.0, 0.... font-size: 0px; background-color: rgb(76.50000... font-size: 0px; background-color: rgb(102.0, 0... font-size: 0px; background-color: rgb(127.5, 0... font-size: 0px; background-color: rgb(153.0000... font-size: 0px; background-color: rgb(178.5000... font-size: 0px; background-color: rgb(204.0, 0... font-size: 0px; background-color: rgb(229.5, 0... font-size: 0px; background-color: rgb(255.0, 0... <p>with a small change to code in the cell above, we can indeed colorize our table.</p> <pre><code>    red.to_frame(\"red\").T.style.applymap(rgb)\n</code></pre> 0 1 2 3 4 5 6 7 8 9 10 red [0. 0. 0.] [25.5  0.   0. ] [51.  0.  0.] [76.5  0.   0. ] [102.   0.   0.] [127.5   0.    0. ] [153.   0.   0.] [178.5   0.    0. ] [204.   0.   0.] [229.5   0.    0. ] [255.   0.   0.] <p>green and blue are a <code>shift</code> of the indices in the triple.</p> <pre><code>    @toolz.curry\n    def shift(n, x):\n        return numpy.concatenate([x[n:], x[:n]])\n</code></pre> <p>with <code>shift(1)</code> for blue, and <code>shift(2)</code> for green we can construct a composite dataframe with all of our <code>rgb</code> colorvalues <code>...</code></p> <pre><code>    colors = \"red blue green\".split()\n</code></pre> <pre><code>    df = pandas.concat({\n        c: red.apply(shift(i)).rename(c) for i, c in enumerate(colors)\n    }, axis=1).T; df\n</code></pre> 0 1 2 3 4 5 6 7 8 9 10 red [0.0, 0.0, 0.0] [25.5, 0.0, 0.0] [51.0, 0.0, 0.0] [76.50000000000001, 0.0, 0.0] [102.0, 0.0, 0.0] [127.5, 0.0, 0.0] [153.00000000000003, 0.0, 0.0] [178.50000000000003, 0.0, 0.0] [204.0, 0.0, 0.0] [229.5, 0.0, 0.0] [255.0, 0.0, 0.0] blue [0.0, 0.0, 0.0] [0.0, 0.0, 25.5] [0.0, 0.0, 51.0] [0.0, 0.0, 76.50000000000001] [0.0, 0.0, 102.0] [0.0, 0.0, 127.5] [0.0, 0.0, 153.00000000000003] [0.0, 0.0, 178.50000000000003] [0.0, 0.0, 204.0] [0.0, 0.0, 229.5] [0.0, 0.0, 255.0] green [0.0, 0.0, 0.0] [0.0, 25.5, 0.0] [0.0, 51.0, 0.0] [0.0, 76.50000000000001, 0.0] [0.0, 102.0, 0.0] [0.0, 127.5, 0.0] [0.0, 153.00000000000003, 0.0] [0.0, 178.50000000000003, 0.0] [0.0, 204.0, 0.0] [0.0, 229.5, 0.0] [0.0, 255.0, 0.0] <p>that may be stylized using the <code>df.style</code> feature</p> <pre><code>    df.style.applymap(rgb)\n</code></pre> 0 1 2 3 4 5 6 7 8 9 10 red [0. 0. 0.] [25.5  0.   0. ] [51.  0.  0.] [76.5  0.   0. ] [102.   0.   0.] [127.5   0.    0. ] [153.   0.   0.] [178.5   0.    0. ] [204.   0.   0.] [229.5   0.    0. ] [255.   0.   0.] blue [0. 0. 0.] [ 0.   0.  25.5] [ 0.  0. 51.] [ 0.   0.  76.5] [  0.   0. 102.] [  0.    0.  127.5] [  0.   0. 153.] [  0.    0.  178.5] [  0.   0. 204.] [  0.    0.  229.5] [  0.   0. 255.] green [0. 0. 0.] [ 0.  25.5  0. ] [ 0. 51.  0.] [ 0.  76.5  0. ] [  0. 102.   0.] [  0.  127.5   0. ] [  0. 153.   0.] [  0.  178.5   0. ] [  0. 204.   0.] [  0.  229.5   0. ] [  0. 255.   0.] <p>from our <code>df</code> containing a primary palette we can build a <code>secondary</code> palette.</p> <pre><code>    secondary =     pandas.concat([    \n        df.loc[\"red\"].add(df.loc[\"blue\"]).rename(\"violet\"),\n        df.loc[\"red\"].add(df.loc[\"green\"]).rename(\"yellow\"),\n        df.loc[\"blue\"].add(df.loc[\"green\"]).rename(\"cyan\")\n    ], axis=1).T; secondary.style.applymap(rgb)\n</code></pre> 0 1 2 3 4 5 6 7 8 9 10 violet [0. 0. 0.] [25.5  0.  25.5] [51.  0. 51.] [76.5  0.  76.5] [102.   0. 102.] [127.5   0.  127.5] [153.   0. 153.] [178.5   0.  178.5] [204.   0. 204.] [229.5   0.  229.5] [255.   0. 255.] yellow [0. 0. 0.] [25.5 25.5  0. ] [51. 51.  0.] [76.5 76.5  0. ] [102. 102.   0.] [127.5 127.5   0. ] [153. 153.   0.] [178.5 178.5   0. ] [204. 204.   0.] [229.5 229.5   0. ] [255. 255.   0.] cyan [0. 0. 0.] [ 0.  25.5 25.5] [ 0. 51. 51.] [ 0.  76.5 76.5] [  0. 102. 102.] [  0.  127.5 127.5] [  0. 153. 153.] [  0.  178.5 178.5] [  0. 204. 204.] [  0.  229.5 229.5] [  0. 255. 255.] <p>they can all be recombined together on their respective order.</p> <pre><code>    all = pandas.concat([df, secondary]).loc[\n        \"red violet blue cyan green yellow\".split()]\n\n    all.style.applymap(rgb)\n</code></pre> 0 1 2 3 4 5 6 7 8 9 10 red [0. 0. 0.] [25.5  0.   0. ] [51.  0.  0.] [76.5  0.   0. ] [102.   0.   0.] [127.5   0.    0. ] [153.   0.   0.] [178.5   0.    0. ] [204.   0.   0.] [229.5   0.    0. ] [255.   0.   0.] violet [0. 0. 0.] [25.5  0.  25.5] [51.  0. 51.] [76.5  0.  76.5] [102.   0. 102.] [127.5   0.  127.5] [153.   0. 153.] [178.5   0.  178.5] [204.   0. 204.] [229.5   0.  229.5] [255.   0. 255.] blue [0. 0. 0.] [ 0.   0.  25.5] [ 0.  0. 51.] [ 0.   0.  76.5] [  0.   0. 102.] [  0.    0.  127.5] [  0.   0. 153.] [  0.    0.  178.5] [  0.   0. 204.] [  0.    0.  229.5] [  0.   0. 255.] cyan [0. 0. 0.] [ 0.  25.5 25.5] [ 0. 51. 51.] [ 0.  76.5 76.5] [  0. 102. 102.] [  0.  127.5 127.5] [  0. 153. 153.] [  0.  178.5 178.5] [  0. 204. 204.] [  0.  229.5 229.5] [  0. 255. 255.] green [0. 0. 0.] [ 0.  25.5  0. ] [ 0. 51.  0.] [ 0.  76.5  0. ] [  0. 102.   0.] [  0.  127.5   0. ] [  0. 153.   0.] [  0.  178.5   0. ] [  0. 204.   0.] [  0.  229.5   0. ] [  0. 255.   0.] yellow [0. 0. 0.] [25.5 25.5  0. ] [51. 51.  0.] [76.5 76.5  0. ] [102. 102.   0.] [127.5 127.5   0. ] [153. 153.   0.] [178.5 178.5   0. ] [204. 204.   0.] [229.5 229.5   0. ] [255. 255.   0.] <pre><code>\n</code></pre>"},{"location":"xxiii/2023-01-01-strawberry-server.html","title":"WIP: strawberry jupyter server","text":"<p>a work in progress of a <code>graphql</code> schema for jupyter server.</p> <p>https://strawberry.rocks/docs/general/schema-basics</p> <pre><code># %pip install 'strawberry-graphql[debug-server]'\n</code></pre> <pre><code>    from jupyter_server.services.contents.largefilemanager import LargeFileManager\n    from pathlib import Path\n    contents = LargeFileManager(root_dir=str(Path(\"~\").expanduser()))\n</code></pre> <pre><code>    import strawberry as S, typing as T, strawberry.cli, enum\n    from pathlib import Path\n    from datetime import datetime\n</code></pre> <pre><code>    DICT =  S.scalar(\n        T.NewType(\"DICT\", object),\n        description=\"a dictionary\",\n        serialize=lambda v: v,\n        parse_value=lambda v: v,\n    )\n</code></pre> <pre><code>    @strawberry.enum\n    class ContentType(enum.Enum):\n        FILE = \"file\"\n        NOTEBOOK = \"notebook\"\n        DIRECTORY = \"directory\"\n\n    @S.type\n    class Base:\n        name: str\n        path: str\n        last_modified: datetime\n        created: datetime\n        format: str\n        mimetype: T.Optional[str]\n        size: T.Optional[int]\n        writable: bool\n        type: ContentType\n\n\n    Cells = T.Union[DICT]\n\n    @S.type\n    class NbFormat:\n        cells: list[Cells]\n        metadata: DICT\n\n    @S.type\n    class Notebook(Base):\n        content: DICT\n\n    @S.type\n    class File(Base):\n        content: str\n\n    @S.type\n    class Directory(Base):\n        content: T.Annotated[\"Kinds\", \"__main__\"]\n\n    Kinds = T.Union[Notebook, File, Directory]\n\n    @S.type\n    class Query:        \n        @S.field\n        def search(self, dir: str = \"\", kind: T.Optional[ContentType] = None) -&gt; Kinds:\n            return Directory(**contents.get(dir, ))\n\n    schema = strawberry.Schema(Query)\n</code></pre> <pre><code>    from fastapi import FastAPI\n    from strawberry.fastapi import GraphQLRouter\n\n    graphql_app = GraphQLRouter(schema)\n\n    app = FastAPI()\n    app.include_router(graphql_app, prefix=\"/graphql\")\n</code></pre> <pre><code>    if (I := \"__file__\" not in locals()):\n        from IPython.display import IFrame\n        import uvicorn, asyncio\n        __import__(\"nest_asyncio\").apply()\n\n        config = uvicorn.Config(app)\n        if \"server\" in locals():\n            asyncio.ensure_future(server.shutdown())\n        server = uvicorn.Server(config=config)\n\n        asyncio.ensure_future(server.serve())\n</code></pre> <pre>INFO:     Shutting down\nINFO:     Started server process [288580]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\nINFO:     Waiting for application shutdown.\nINFO:     Application shutdown complete.\n</pre> <pre><code>    I and display(IFrame(\"http://127.0.0.1:8000/graphql\", *\"100% 600\".split()))\n</code></pre> <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In [8], line 1\n----&gt; 1 I and display(IFrame(\"http://127.0.0.1:8000/graphql\", *\"100% 600\".split()))\n\nNameError: name 'I' is not defined</pre> <pre><code>asyncio.ensure_future(server.shutdown())\n</code></pre> <pre><code>\n</code></pre>"},{"location":"xxiii/2023-01-02-accessible-dataframes-basic-indexes.html","title":"rendering dataframes for screen readers with <code>pandas</code>","text":"<p>in the document we'll explore what it takes to make <code>pandas.DataFrame</code>s accessible. we'll follow Paul J Adam's instructions for making Simple Data Tables.</p> <pre><code>    %reload_ext pidgy\n    import pandas.io.formats.style, bs4, pytest\n    shell.weave.reactive = False\n    shell.weave.use_async = False\n    soup = lambda x: bs4.BeautifulSoup(x, features=\"html.parser\")\n</code></pre>        %reload_ext pidgy     import pandas.io.formats.style, bs4, pytest     shell.weave.reactive = False     shell.weave.use_async = False     soup = lambda x: bs4.BeautifulSoup(x, features=\"html.parser\")   <pre><code>    (df := pandas.DataFrame(\n        columns=pandas.Index(list(\"ABC\")), \n        index=pandas.Index(range(2), name=\"index\"))\n    ).style.set_caption(\"the basic dataframe &lt;var&gt;df&lt;/var&gt; we use for explanation in this document. \")\n</code></pre> the basic dataframe df we use for explanation in this document.  A B C index 0 nan nan nan 1 nan nan nan <pre><code>(df := pandas.DataFrame(\n    columns=pandas.Index(list(\"ABC\")), \n    index=pandas.Index(range(2), name=\"index\"))\n).style.set_caption(\"the basic dataframe &lt;var&gt;df&lt;/var&gt; we use for explanation in this document. \")\n</code></pre> <pre><code>`df` is a basic `pandas.DataFrame` because:    \n\n* it has ONE row level \n* it has ONE column level \n\nwe do not need to consider the contents of the cells for the recommendations we are implementing.\n</code></pre> <p><code>df</code> is a basic <code>pandas.DataFrame</code> because:    </p> <ul> <li>it has ONE row level </li> <li>it has ONE column level </li> </ul> <p>we do not need to consider the contents of the cells for the recommendations we are implementing.</p> <pre><code>## applying best practices  to pandas\n</code></pre>"},{"location":"xxiii/2023-01-02-accessible-dataframes-basic-indexes.html#applying-best-practices-to-pandas","title":"applying best practices  to pandas","text":"<pre><code>### 1. Title of data table is inside the `&lt;caption&gt;` element.\n\nthe caption is dependent on the data and effects the visual appearance of the table. \nit is context dependent up to the author to supply.\n</code></pre>"},{"location":"xxiii/2023-01-02-accessible-dataframes-basic-indexes.html#1-title-of-data-table-is-inside-the-caption-element","title":"1. Title of data table is inside the <code>&lt;caption&gt;</code> element.","text":"<p>the caption is dependent on the data and effects the visual appearance of the table.  it is context dependent up to the author to supply.</p> <pre><code>    def assert_has_caption(object):\n        caption = soup(object).select_one(\"table caption\")\n        assert caption and caption.string.strip(), \"table is missing a &lt;caption&gt;\"\n    # with pytest.raises(AssertionError): assert_has_caption(df._repr_html_())\n</code></pre> <pre><code>def assert_has_caption(object):\n    caption = soup(object).select_one(\"table caption\")\n    assert caption and caption.string.strip(), \"table is missing a &lt;caption&gt;\"\n# with pytest.raises(AssertionError): assert_has_caption(df._repr_html_())\n</code></pre> <p>the caption can be set using the <code>pandas.DataFrame.style.set_caption</code> method. the result is a <code>pandas.io.formats.style.Styler</code> object that let's us modify how the instance is displayed.</p> <pre><code>`set_caption` user the `pandas.DataFrame.style` attribute to set a caption\n</code></pre> <p><code>set_caption</code> user the <code>pandas.DataFrame.style</code> attribute to set a caption</p> <pre><code>    def set_caption(df, caption) -&gt; pandas.io.formats.style.Styler:\n        return df.style.set_caption(caption)\n\nafter we have a styler we are working with a subset of pandas operations.\nthe styler should be the last stop for the data.\n</code></pre> <pre><code>def set_caption(df, caption) -&gt; pandas.io.formats.style.Styler:\n    return df.style.set_caption(caption)\n</code></pre> <p>after we have a styler we are working with a subset of pandas operations. the styler should be the last stop for the data.</p> <pre><code>the `&lt;table&gt;` below demonstrates how the `&lt;caption&gt;` appears on a `captioned` `pandas.DataFrame`.\n\n{{captioned}}\n\n    assert_has_caption(\n        captioned := set_caption(df, \"a value-less dataframe with columns and row indexes\")._repr_html_()\n    );\n</code></pre> <p>the <code>&lt;table&gt;</code> below demonstrates how the <code>&lt;caption&gt;</code> appears on a <code>captioned</code> <code>pandas.DataFrame</code>.</p> a value-less dataframe with columns and row indexes A B C index 0 nan nan nan 1 nan nan nan <pre><code>assert_has_caption(\n    captioned := set_caption(df, \"a value-less dataframe with columns and row indexes\")._repr_html_()\n);\n</code></pre> <pre><code>#### `pandas.io.formats.style.Styler`\n\n`pandas.io.formats.style.Styler` gives a different html representation that `_repr_html_`\n\n    assert df.style.to_html() != df.to_html()\n</code></pre>"},{"location":"xxiii/2023-01-02-accessible-dataframes-basic-indexes.html#pandasioformatsstylestyler","title":"<code>pandas.io.formats.style.Styler</code>","text":"<p><code>pandas.io.formats.style.Styler</code> gives a different html representation that <code>_repr_html_</code></p> <pre><code>assert df.style.to_html() != df.to_html()\n</code></pre> <pre><code>### 2. Column headers are inside `&lt;th scope=\"col\"&gt;` elements.\n\nthe `scope` property improves navigation for screen readers when used properly.\n</code></pre>"},{"location":"xxiii/2023-01-02-accessible-dataframes-basic-indexes.html#2-column-headers-are-inside-th-scopecol-elements","title":"2. Column headers are inside <code>&lt;th scope=\"col\"&gt;</code> elements.","text":"<p>the <code>scope</code> property improves navigation for screen readers when used properly.</p> <pre><code>    def assert_has_col_scope(object, selector=\"thead tr th\"):\nfor basic frames, all the `&lt;th&gt;` tags in `&lt;thead&gt;` should have `scope=\"col\"`\n\n        assert all(th.attrs.get(\"scope\") in {\"col\", \"colgroup\"} for th in soup(object).select(selector)), \"&lt;th&gt; is missing `scope='col'`\"\n    # with pytest.raises(AssertionError): assert_has_col_scope(captioned)\n</code></pre> <pre><code>def assert_has_col_scope(object, selector=\"thead tr th\"):\n</code></pre> <p>for basic frames, all the <code>&lt;th&gt;</code> tags in <code>&lt;thead&gt;</code> should have <code>scope=\"col\"</code></p> <pre><code>    assert all(th.attrs.get(\"scope\") in {\"col\", \"colgroup\"} for th in soup(object).select(selector)), \"&lt;th&gt; is missing `scope='col'`\"\n# with pytest.raises(AssertionError): assert_has_col_scope(captioned)\n</code></pre> <pre><code>    def set_col_scope(object, selector=\"thead tr th\"):\n`set_col_scope` automatically remediates missing columns `scope`s\n\n        for th in (object := soup(object)).select(selector):\n            th.attrs.setdefault(\"scope\", \"col\")\n        return str(object)\n</code></pre> <pre><code>def set_col_scope(object, selector=\"thead tr th\"):\n</code></pre> <p><code>set_col_scope</code> automatically remediates missing columns <code>scope</code>s</p> <pre><code>    for th in (object := soup(object)).select(selector):\n        th.attrs.setdefault(\"scope\", \"col\")\n    return str(object)\n</code></pre> <pre><code>these `scope` has no visual effect, however we can use `assert_has_col_scope` to verify the scope is correct.\n\n    assert_has_col_scope(col_scoped := set_col_scope(captioned));\n</code></pre> <p>these <code>scope</code> has no visual effect, however we can use <code>assert_has_col_scope</code> to verify the scope is correct.</p> <pre><code>assert_has_col_scope(col_scoped := set_col_scope(captioned));\n</code></pre> <pre><code>### 3. Row headers are inside `&lt;th scope=\"row\"&gt;` elements.\n\nsimilar to `scope=\"col\"`, the `&lt;th&gt;` elements in the body require `scope=\"row\"`;\nbasically every `&lt;th&gt;` needs the scope property.\n</code></pre>"},{"location":"xxiii/2023-01-02-accessible-dataframes-basic-indexes.html#3-row-headers-are-inside-th-scoperow-elements","title":"3. Row headers are inside <code>&lt;th scope=\"row\"&gt;</code> elements.","text":"<p>similar to <code>scope=\"col\"</code>, the <code>&lt;th&gt;</code> elements in the body require <code>scope=\"row\"</code>; basically every <code>&lt;th&gt;</code> needs the scope property.</p> <pre><code>    def assert_has_row_scope(object, selector=\"tbody tr th\"):\n        assert all(th.attrs.get(\"scope\") in {\"row\", \"rowgroup\"} for th in soup(object).select(selector)),\\\n        \"&lt;th&gt; is missing `scope='col'`\"\n    # with pytest.raises(AssertionError): assert_has_row_scope(col_scoped)\n</code></pre> <pre><code>def assert_has_row_scope(object, selector=\"tbody tr th\"):\n    assert all(th.attrs.get(\"scope\") in {\"row\", \"rowgroup\"} for th in soup(object).select(selector)),\\\n    \"&lt;th&gt; is missing `scope='col'`\"\n# with pytest.raises(AssertionError): assert_has_row_scope(col_scoped)\n</code></pre> <pre><code>    def set_row_scope(object, selector=\"tbody tr th, tfoot tr th\"):\nlike the columns, we can deterministically add `scope=\"row\"`\n\n        for th in (object := soup(object)).select(selector):\n            th.attrs.setdefault(\"scope\", \"row\")\n        return str(object)\n</code></pre> <pre><code>def set_row_scope(object, selector=\"tbody tr th, tfoot tr th\"):\n</code></pre> <p>like the columns, we can deterministically add <code>scope=\"row\"</code></p> <pre><code>    for th in (object := soup(object)).select(selector):\n        th.attrs.setdefault(\"scope\", \"row\")\n    return str(object)\n</code></pre> <pre><code>we use `set_row_scope` to verify the `scope` because, again, there aren't any visual effects to these changes.\n\n    assert_has_row_scope(row_scoped := set_row_scope(col_scoped))\n</code></pre> <p>we use <code>set_row_scope</code> to verify the <code>scope</code> because, again, there aren't any visual effects to these changes.</p> <pre><code>assert_has_row_scope(row_scoped := set_row_scope(col_scoped))\n</code></pre> <pre><code>### 4. Avoid using blank header cells.\n\nthis instruction to yield a best practice to __name the dataframe index__.\nwithout a name, the index `&lt;th&gt;` will always be empty.\n</code></pre>"},{"location":"xxiii/2023-01-02-accessible-dataframes-basic-indexes.html#4-avoid-using-blank-header-cells","title":"4. Avoid using blank header cells.","text":"<p>this instruction to yield a best practice to name the dataframe index. without a name, the index <code>&lt;th&gt;</code> will always be empty.</p> <pre><code>    def assert_no_blank_header(body):\n        assert all(th.string.strip() for th in soup(body).select(\"th\")), \"there is a blank &lt;th&gt;\"\n</code></pre> <pre><code>def assert_no_blank_header(body):\n    assert all(th.string.strip() for th in soup(body).select(\"th\")), \"there is a blank &lt;th&gt;\"\n</code></pre> <pre><code>    # with pytest.raises(AssertionError): assert_no_blank_header(row_scoped)\n</code></pre> <pre><code># with pytest.raises(AssertionError): assert_no_blank_header(row_scoped)\n</code></pre> <pre><code>`pandas` requires some upstream work to satisfy this instruction.\n</code></pre> <p><code>pandas</code> requires some upstream work to satisfy this instruction.</p> <pre><code>    def set_squashed_th(body):\n`set_squashed_th` squashes the table column names. this method on works for the most basic dataframes.\n\n        table = soup(body)\n        tr = bs4.Tag(name=\"tr\")\n        col, row = table.select(\"thead tr\")\n        for top, bottom in zip(col.select(\"th\"), row.select(\"th\")):\n            tr.append(top if top.string.strip() else bottom)\n        thead = bs4.Tag(name=\"thead\"); thead.append(tr)\n        table.select_one(\"thead\").replace_with(thead)\n        return str(table)\n</code></pre> <pre><code>def set_squashed_th(body):\n</code></pre> <p><code>set_squashed_th</code> squashes the table column names. this method on works for the most basic dataframes.</p> <pre><code>    table = soup(body)\n    tr = bs4.Tag(name=\"tr\")\n    col, row = table.select(\"thead tr\")\n    for top, bottom in zip(col.select(\"th\"), row.select(\"th\")):\n        tr.append(top if top.string.strip() else bottom)\n    thead = bs4.Tag(name=\"thead\"); thead.append(tr)\n    table.select_one(\"thead\").replace_with(thead)\n    return str(table)\n</code></pre> <pre><code>the frame below doesn't have empty `&lt;th&gt;` elements and is denser.\n\n{{squashed_th}}\n\n    assert_no_blank_header(squashed_th := set_squashed_th(row_scoped))\n</code></pre> <p>the frame below doesn't have empty <code>&lt;th&gt;</code> elements and is denser.</p> a value-less dataframe with columns and row indexes indexABC 0 nan nan nan 1 nan nan nan <pre><code>assert_no_blank_header(squashed_th := set_squashed_th(row_scoped))\n</code></pre> <pre><code>### 5. Header cells with text abbreviations that need expansion use the title attribute with the expanded text set as the value.\n\nthe naming of columns is a context specific screen reader feature.\nauthors would have to add this information themselves.\n</code></pre>"},{"location":"xxiii/2023-01-02-accessible-dataframes-basic-indexes.html#5-header-cells-with-text-abbreviations-that-need-expansion-use-the-title-attribute-with-the-expanded-text-set-as-the-value","title":"5. Header cells with text abbreviations that need expansion use the title attribute with the expanded text set as the value.","text":"<p>the naming of columns is a context specific screen reader feature. authors would have to add this information themselves.</p> <pre><code>    titles = dict(A=\"apple\", B=\"banana\", C=\"carrot\")\n    def set_header_titles(body, titles=titles):\n`set_header_titles` is a method that includes the name of the abbreviation in the `title`.\n\n        for th in (body := soup(body)).select(\"thead tr th\"):\n            name = th.string.strip()\n            if name in titles:\n                th.attrs[\"title\"] = titles[name]\n        return str(body)\n\n&gt; a real dataset would make more sense in this example.\n</code></pre> <pre><code>titles = dict(A=\"apple\", B=\"banana\", C=\"carrot\")\ndef set_header_titles(body, titles=titles):\n</code></pre> <p><code>set_header_titles</code> is a method that includes the name of the abbreviation in the <code>title</code>.</p> <pre><code>    for th in (body := soup(body)).select(\"thead tr th\"):\n        name = th.string.strip()\n        if name in titles:\n            th.attrs[\"title\"] = titles[name]\n    return str(body)\n</code></pre> <p>a real dataset would make more sense in this example.</p> <pre><code>    titled = set_header_titles(squashed_th, titles)\n</code></pre> <pre><code>titled = set_header_titles(squashed_th, titles)\n</code></pre> <pre><code>    def strip_class_ids(body):\n`pandas` adds classes and ids to elements that for the sake of this discussion are superfluous.\n\n        for e in (body := soup(body)).select(\"td, th\"): \n            e.attrs.pop(\"id\", None)\n            e.attrs.pop(\"class\", None)\n\n        return str(body)\n    final = strip_class_ids(titled)\n</code></pre> <pre><code>def strip_class_ids(body):\n</code></pre> <p><code>pandas</code> adds classes and ids to elements that for the sake of this discussion are superfluous.</p> <pre><code>    for e in (body := soup(body)).select(\"td, th\"): \n        e.attrs.pop(\"id\", None)\n        e.attrs.pop(\"class\", None)\n\n    return str(body)\nfinal = strip_class_ids(titled)\n</code></pre> <pre><code>## inconsistencies in labelled indexes\n\neverything goes to hell with `named_column` which as a column name.\n\n    named_column = df.copy()\n    named_column.columns.name = \"letters\"\n</code></pre>"},{"location":"xxiii/2023-01-02-accessible-dataframes-basic-indexes.html#inconsistencies-in-labelled-indexes","title":"inconsistencies in labelled indexes","text":"<p>everything goes to hell with <code>named_column</code> which as a column name.</p> <pre><code>named_column = df.copy()\nnamed_column.columns.name = \"letters\"\n</code></pre> <pre><code>### column and index names\n\nconsider the case of `df2` where the `df2.columns` is named and `df2.index` is not. \n\n{% set df = named_column.style.set_caption(pidgy.filters.md(\"the `named_column` dataframe with a column name\")) %}\n{{df}}\n\nscreenreader visitors may struggle to interpret the meaning of \"letters\" relative to the index.\nensurely a proper experience for screen readers will require extra markup to group the `&lt;th&gt; with the columns. \n</code></pre>"},{"location":"xxiii/2023-01-02-accessible-dataframes-basic-indexes.html#column-and-index-names","title":"column and index names","text":"<p>consider the case of <code>df2</code> where the <code>df2.columns</code> is named and <code>df2.index</code> is not. </p> <p>the <code>named_column</code> dataframe with a column name</p> letters A B C index 0 nan nan nan 1 nan nan nan <p>screenreader visitors may struggle to interpret the meaning of \"letters\" relative to the index. ensurely a proper experience for screen readers will require extra markup to group the ` with the columns.  <pre><code>### column name and no index name\n\n    named_column_no_index = named_column.copy()\n    named_column_no_index.index.name = None\n\n{% set df = named_column_no_index.style.set_caption(pidgy.filters.md(\"the `named_column_no_index` dataframe with a column name and without an index name\")) %}\n{{df}}\n\nin this conformation, it is possible for a screen reader to misinterpet `letters` as the name of the index column.\nwhen the column index is named, like `letters`, the entry should be `&lt;th scope=\"row\"&gt;`. \nit this example we can see how instructions in 2 and 3 differ.\n</code></pre>"},{"location":"xxiii/2023-01-02-accessible-dataframes-basic-indexes.html#column-name-and-no-index-name","title":"column name and no index name","text":"<pre><code>named_column_no_index = named_column.copy()\nnamed_column_no_index.index.name = None\n</code></pre> <p>the <code>named_column_no_index</code> dataframe with a column name and without an index name</p> letters A B C 0 nan nan nan 1 nan nan nan <p>in this conformation, it is possible for a screen reader to misinterpet <code>letters</code> as the name of the index column. when the column index is named, like <code>letters</code>, the entry should be <code>&lt;th scope=\"row\"&gt;</code>.  it this example we can see how instructions in 2 and 3 differ.</p>"},{"location":"xxiii/2023-01-02-accessible-dataframes-basic-indexes.html#conclusions","title":"conclusions","text":"<pre><code>for basic dataframes, two practices can be enforced without knowledge of the data:\n\n- [x] Column headers are inside &lt;th scope=\"col\"&gt; elements.\n- [x] Row headers are inside &lt;th scope=\"row\"&gt; elements.\n\n\nthe abbreviations and caption are context specific and require knowledge of the data:\n\n- [ ] Title of data table is inside the &lt;caption&gt; element.\n- [ ] Header cells with text abbreviations that need expansion use the title attribute with the expanded text set as the value.\n\nwith `pandas&lt;={{pandas.__version__}}`, it is hard to avoid black header cells without some significant effort.\n\n\n- [ ] Avoid using blank header cells.\n\n\nsome conventions we can extract from this study is:\n\n* treat the `df.index` as a column that needs to be named\n* if an index is superfluous then remove it. this can be down with the styler `df.style.hide(axis=0)`\n</code></pre> <p>for basic dataframes, two practices can be enforced without knowledge of the data:</p> <ul> <li> Column headers are inside  elements. <li> Row headers are inside  elements. <p>the abbreviations and caption are context specific and require knowledge of the data:</p> <ul> <li> Title of data table is inside the  element. <li> Header cells with text abbreviations that need expansion use the title attribute with the expanded text set as the value.</li> <p>with <code>pandas&lt;=1.4.2</code>, it is hard to avoid black header cells without some significant effort.</p> <ul> <li> Avoid using blank header cells.</li> </ul> <p>some conventions we can extract from this study is:</p> <ul> <li>treat the <code>df.index</code> as a column that needs to be named</li> <li>if an index is superfluous then remove it. this can be down with the styler <code>df.style.hide(axis=0)</code></li> </ul> <pre><code>### final frame\n\nour final dataframe has:\n\n- [x] `&lt;caption&gt;`\n- [x] `&lt;th scope=\"col\"&gt;`\n- [x] `&lt;th scope=\"row\"&gt;`\n- [x] no empty `&lt;th&gt;`\n- [x] `&lt;th title&gt;` for abbreviations\n\n{{final}}\n\n\n### final html source\n\n```html\n{{final}}\n```\n</code></pre>"},{"location":"xxiii/2023-01-02-accessible-dataframes-basic-indexes.html#final-frame","title":"final frame","text":"<p>our final dataframe has:</p> <ul> <li> <code>&lt;caption&gt;</code></li> <li> <code>&lt;th scope=\"col\"&gt;</code></li> <li> <code>&lt;th scope=\"row\"&gt;</code></li> <li> no empty <code>&lt;th&gt;</code></li> <li> <code>&lt;th title&gt;</code> for abbreviations</li> </ul> a value-less dataframe with columns and row indexes indexABC 0 nan nan nan 1 nan nan nan"},{"location":"xxiii/2023-01-02-accessible-dataframes-basic-indexes.html#final-html-source","title":"final html source","text":"<pre><code>&lt;style type=\"text/css\"&gt;\n&lt;/style&gt;\n&lt;table id=\"T_595b7\"&gt;\n&lt;caption&gt;a value-less dataframe with columns and row indexes&lt;/caption&gt;\n&lt;thead&gt;&lt;tr&gt;&lt;th scope=\"col\"&gt;index&lt;/th&gt;&lt;th scope=\"col\" title=\"apple\"&gt;A&lt;/th&gt;&lt;th scope=\"col\" title=\"banana\"&gt;B&lt;/th&gt;&lt;th scope=\"col\" title=\"carrot\"&gt;C&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;th scope=\"row\"&gt;0&lt;/th&gt;\n&lt;td&gt;nan&lt;/td&gt;\n&lt;td&gt;nan&lt;/td&gt;\n&lt;td&gt;nan&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;th scope=\"row\"&gt;1&lt;/th&gt;\n&lt;td&gt;nan&lt;/td&gt;\n&lt;td&gt;nan&lt;/td&gt;\n&lt;td&gt;nan&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n</code></pre> <pre><code>### about the `scope` attribute\n\n&lt;q cite=\"https://www.w3schools.com/tags/att_scope.asp\"&gt;The scope attribute specifies whether a header cell is a header for a column, row, or group of columns or rows.&lt;/q&gt;\n\n&lt;q cite=\"https://dequeuniversity.com/rules/axe/4.0/scope-attr-valid\"&gt;The scope attribute makes table navigation much easier for screen reader users, provided that it is used correctly. Incorrectly used, scope can make table navigation much harder and less efficient. &lt;q&gt;\n</code></pre>"},{"location":"xxiii/2023-01-02-accessible-dataframes-basic-indexes.html#about-the-scope-attribute","title":"about the <code>scope</code> attribute","text":"<p>The scope attribute specifies whether a header cell is a header for a column, row, or group of columns or rows.</p> <p>The scope attribute makes table navigation much easier for screen reader users, provided that it is used correctly. Incorrectly used, scope can make table navigation much harder and less efficient."},{"location":"xxiii/2023-01-02-accessible-dataframes-basic-indexes.html#links","title":"links","text":"<ul> <li>https://pandas.pydata.org/docs/user_guide/style.html</li> <li>https://pauljadam.com/demos/data-tables.html</li> <li>https://www.w3.org/WAI/tutorials/tables/</li> <li>https://developer.mozilla.org/en-US/docs/Learn/HTML/Tables/Advanced</li> </ul>"},{"location":"xxiii/2023-01-04-tfoot-dataframe.html","title":"using <code>tfoot</code> in dataframes for more information","text":"<p>while exploring techniques that make dataframes better for screen readers. i found resources on the <code>tfoot</code> element. i rarely see it used it with dataframes. this work explores what a footer description might look like.</p> <pre><code>    %reload_ext pidgy\n    INTERACTIVE = \"__file__\" not in locals()\n</code></pre> <pre><code>&lt;details markdown=\"1\"&gt;\n&lt;summary&gt;import functions that make dataframes more useful on screen readers&lt;/summary&gt;\n{% filter md %} \n\n    with __import__('midgy.loader').loader.Markdown(extensions=[\".ipynb\"]):\n        from tonyfast.xxiii.__accessible_dataframes_basic_indexes import (\n            df, soup, set_caption, \n            set_col_scope, set_row_scope, set_squashed_th,\n            set_header_titles, strip_class_ids\n        )\n\n{% endfilter %}    \n&lt;/details&gt;\n</code></pre> import functions that make dataframes more useful on screen readers <pre><code>with __import__('midgy.loader').loader.Markdown(extensions=[\".ipynb\"]):\n    from tonyfast.xxiii.__accessible_dataframes_basic_indexes import (\n        df, soup, set_caption, \n        set_col_scope, set_row_scope, set_squashed_th,\n        set_header_titles, strip_class_ids\n    )\n</code></pre> <pre><code>## set `tfoot`\n\n`&lt;tfoot&gt;` is meant to contain supplementary `&lt;table&gt;` information.\n\n    def set_tfoot(df, caption=None):\n`set_tfoot` sets the footer as `df.describe`\n\n        tfoot = soup(strip_class_ids(df.describe().style.to_html())).select_one(\"tbody\")        \n        tfoot.name = \"tfoot\"\n        with_footer = soup(df.style.set_caption(caption).to_html())\n        with_footer.select_one(\"table\").append(tfoot)\n        return str(with_footer)\n</code></pre>"},{"location":"xxiii/2023-01-04-tfoot-dataframe.html#set-tfoot","title":"set <code>tfoot</code>","text":"<p><code>&lt;tfoot&gt;</code> is meant to contain supplementary <code>&lt;table&gt;</code> information.</p> <pre><code>def set_tfoot(df, caption=None):\n</code></pre> <p><code>set_tfoot</code> sets the footer as <code>df.describe</code></p> <pre><code>    tfoot = soup(strip_class_ids(df.describe().style.to_html())).select_one(\"tbody\")        \n    tfoot.name = \"tfoot\"\n    with_footer = soup(df.style.set_caption(caption).to_html())\n    with_footer.select_one(\"table\").append(tfoot)\n    return str(with_footer)\n</code></pre>"},{"location":"xxiii/2023-01-04-tfoot-dataframe.html#formatting-the-final-dataframe","title":"formatting the final dataframe","text":"<pre><code>    def format_df(df, caption=None):\n        return strip_class_ids(set_header_titles(set_squashed_th(\n            set_row_scope(set_col_scope(set_tfoot(df, caption=caption))))))\n    final_table = format_df(df, \"a value-less dataframe with thead, tbody and tfoot defined. tfoot are statistical descriptions of the data.\")\n</code></pre> <pre><code>def format_df(df, caption=None):\n    return strip_class_ids(set_header_titles(set_squashed_th(\n        set_row_scope(set_col_scope(set_tfoot(df, caption=caption))))))\nfinal_table = format_df(df, \"a value-less dataframe with thead, tbody and tfoot defined. tfoot are statistical descriptions of the data.\")\n</code></pre> <pre><code>&lt;details &gt;\n&lt;summary&gt;import tests from another work.&lt;/summary&gt;\n{% filter md %} \n\n    with __import__('midgy.loader').loader.Markdown(extensions=[\".ipynb\"]):\n        from tonyfast.xxiii.__accessible_dataframes_basic_indexes import (\n         assert_has_col_scope, assert_has_row_scope, assert_no_blank_header, assert_has_caption\n        )\n\n{% endfilter %} \n&lt;/details&gt;\n</code></pre> import tests from another work. <pre><code>with __import__('midgy.loader').loader.Markdown(extensions=[\".ipynb\"]):\n    from tonyfast.xxiii.__accessible_dataframes_basic_indexes import (\n     assert_has_col_scope, assert_has_row_scope, assert_no_blank_header, assert_has_caption\n    )\n</code></pre>"},{"location":"xxiii/2023-01-04-tfoot-dataframe.html#verifying-that-we-pass-our-tests","title":"verifying that we pass our tests","text":"<pre><code>    def test_basic_table_accessibility(html):\ntest for a caption, scope attributes, and populated headers\n\n        assert_has_caption(html)\n        assert_has_col_scope(html)\n        assert_has_row_scope(html)    \n        assert_no_blank_header(html)\n</code></pre> <pre><code>def test_basic_table_accessibility(html):\n</code></pre> <p>test for a caption, scope attributes, and populated headers</p> <pre><code>    assert_has_caption(html)\n    assert_has_col_scope(html)\n    assert_has_row_scope(html)    \n    assert_no_blank_header(html)\n</code></pre>"},{"location":"xxiii/2023-01-04-tfoot-dataframe.html#the-final_table","title":"the <code>final_table</code>","text":"<pre><code>    INTERACTIVE and print(\"this message means our table abides. woo!\")\n</code></pre> <pre>this message means our table abides. woo!\n</pre> <pre><code>INTERACTIVE and print(\"this message means our table abides. woo!\")\n</code></pre> <pre><code>{{final_table}}\n\nremediated `pandas.DataFrame`\n\n```html\n{{final_table}}\n```\n</code></pre> a value-less dataframe with thead, tbody and tfoot defined. tfoot are statistical descriptions of the data. indexABC 0 nan nan nan 1 nan nan nan count 0 0 0 unique 0 0 0 top nan nan nan freq nan nan nan <p>remediated <code>pandas.DataFrame</code></p> <pre><code>&lt;style type=\"text/css\"&gt;\n&lt;/style&gt;\n&lt;table id=\"T_6ae36\"&gt;\n&lt;caption&gt;a value-less dataframe with thead, tbody and tfoot defined. tfoot are statistical descriptions of the data.&lt;/caption&gt;\n&lt;thead&gt;&lt;tr&gt;&lt;th scope=\"col\"&gt;index&lt;/th&gt;&lt;th scope=\"col\" title=\"apple\"&gt;A&lt;/th&gt;&lt;th scope=\"col\" title=\"banana\"&gt;B&lt;/th&gt;&lt;th scope=\"col\" title=\"carrot\"&gt;C&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;th scope=\"row\"&gt;0&lt;/th&gt;\n&lt;td&gt;nan&lt;/td&gt;\n&lt;td&gt;nan&lt;/td&gt;\n&lt;td&gt;nan&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;th scope=\"row\"&gt;1&lt;/th&gt;\n&lt;td&gt;nan&lt;/td&gt;\n&lt;td&gt;nan&lt;/td&gt;\n&lt;td&gt;nan&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;tfoot&gt;\n&lt;tr&gt;\n&lt;th scope=\"row\"&gt;count&lt;/th&gt;\n&lt;td&gt;0&lt;/td&gt;\n&lt;td&gt;0&lt;/td&gt;\n&lt;td&gt;0&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;th scope=\"row\"&gt;unique&lt;/th&gt;\n&lt;td&gt;0&lt;/td&gt;\n&lt;td&gt;0&lt;/td&gt;\n&lt;td&gt;0&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;th scope=\"row\"&gt;top&lt;/th&gt;\n&lt;td&gt;nan&lt;/td&gt;\n&lt;td&gt;nan&lt;/td&gt;\n&lt;td&gt;nan&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;th scope=\"row\"&gt;freq&lt;/th&gt;\n&lt;td&gt;nan&lt;/td&gt;\n&lt;td&gt;nan&lt;/td&gt;\n&lt;td&gt;nan&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tfoot&gt;&lt;/table&gt;\n</code></pre>"},{"location":"xxiii/2023-01-04-using-diagrams.html","title":"diagrams in jupyter and mkdocs","text":"<p>mermaid has emerged as a community standard for diagrams. we can use it in three places relative to this content:</p> <ul> <li>mermaid can be used on github</li> <li>mermaid can be used in <code>jupyterlab</code> with <code>jupyterlab-markup</code></li> <li>mermaid can be used with <code>mkdocs-material</code></li> </ul> <pre><code>    %reload_ext pidgy\n    import requests, requests_cache, bs4\n    requests_cache.install_cache(backend=\"filesystem\")\n</code></pre> <pre><code>from the `root` page, using `beautifulsoup4` as an intermediary, we can discover that mermaid\nsupports {{len(kinds)}} chart syntaxes.\n\n```python\nsoup = bs4.BeautifulSoup((root := requests.get(\"https://mermaid.js.org/syntax/classDiagram.html\")).text, \"html.parser\")\nkinds = set(x.attrs[\"href\"]for x in soup.select(\"a\") if x.attrs[\"href\"].startswith((\"/syntax\",)))\n```\n</code></pre> <p>from the <code>root</code> page, using <code>beautifulsoup4</code> as an intermediary, we can discover that mermaid supports 13 chart syntaxes.</p> <pre><code>soup = bs4.BeautifulSoup((root := requests.get(\"https://mermaid.js.org/syntax/classDiagram.html\")).text, \"html.parser\")\nkinds = set(x.attrs[\"href\"]for x in soup.select(\"a\") if x.attrs[\"href\"].startswith((\"/syntax\",)))\n</code></pre> <p>extracting the syntaxes to build one master chart.</p> <pre><code>```python\nbaseurl = root.url.rsplit(\"/\", 2)[0]\nsyntaxes = {baseurl + x for x in kinds}\nresponses = {x: requests.get(x) for x in syntaxes}\n```\n</code></pre> <pre><code>baseurl = root.url.rsplit(\"/\", 2)[0]\nsyntaxes = {baseurl + x for x in kinds}\nresponses = {x: requests.get(x) for x in syntaxes}\n</code></pre> <pre><code>```python\ndef strip_front_matter(x):\n    fence = ('---',)\n    if x.startswith(fence):\n        y = None\n        for line in x.splitlines(1)[1:]:\n            if y is None:\n                if line.startswith(fence):\n                    y = \"\"\n            else:\n                y += line\n        return y             \n    return x\n\n```\n</code></pre> <pre><code>def strip_front_matter(x):\n    fence = ('---',)\n    if x.startswith(fence):\n        y = None\n        for line in x.splitlines(1)[1:]:\n            if y is None:\n                if line.startswith(fence):\n                    y = \"\"\n            else:\n                y += line\n        return y             \n    return x\n</code></pre> <pre><code>## all the diagram styles collection programmatically\n\n{% for syntax in syntaxes %}\n{% set page = bs4.BeautifulSoup(responses.get(syntax).text, features=\"html.parser\") %}\n{% set title = page.select_one(\"h1\").text.rstrip(\"#\") %}\n### {{title}}\n\n```mermaid\n{{textwrap.dedent(strip_front_matter(page.select_one(\"pre code\").text))}}\n```\n{% endfor %}\n</code></pre>"},{"location":"xxiii/2023-01-04-using-diagrams.html#all-the-diagram-styles-collection-programmatically","title":"all the diagram styles collection programmatically","text":""},{"location":"xxiii/2023-01-04-using-diagrams.html#mindmap","title":"Mindmap","text":"<pre><code>mindmap\n  root((mindmap))\n    Origins\n      Long history\n      ::icon(fa fa-book)\n      Popularisation\n        British popular psychology author Tony Buzan\n    Research\n      On effectiveness&lt;br/&gt;and features\n      On Automatic creation\n        Uses\n            Creative techniques\n            Strategic planning\n            Argument mapping\n    Tools\n      Pen and paper\n      Mermaid\n\n</code></pre>"},{"location":"xxiii/2023-01-04-using-diagrams.html#c4-diagrams","title":"C4 Diagrams","text":"<pre><code>C4Context\n  title System Context diagram for Internet Banking System\n  Enterprise_Boundary(b0, \"BankBoundary0\") {\n    Person(customerA, \"Banking Customer A\", \"A customer of the bank, with personal bank accounts.\")\n    Person(customerB, \"Banking Customer B\")\n    Person_Ext(customerC, \"Banking Customer C\", \"desc\")\n\n    Person(customerD, \"Banking Customer D\", \"A customer of the bank, &lt;br/&gt; with personal bank accounts.\")\n\n    System(SystemAA, \"Internet Banking System\", \"Allows customers to view information about their bank accounts, and make payments.\")\n\n    Enterprise_Boundary(b1, \"BankBoundary\") {\n\n      SystemDb_Ext(SystemE, \"Mainframe Banking System\", \"Stores all of the core banking information about customers, accounts, transactions, etc.\")\n\n      System_Boundary(b2, \"BankBoundary2\") {\n        System(SystemA, \"Banking System A\")\n        System(SystemB, \"Banking System B\", \"A system of the bank, with personal bank accounts. next line.\")\n      }\n\n      System_Ext(SystemC, \"E-mail system\", \"The internal Microsoft Exchange e-mail system.\")\n      SystemDb(SystemD, \"Banking System D Database\", \"A system of the bank, with personal bank accounts.\")\n\n      Boundary(b3, \"BankBoundary3\", \"boundary\") {\n        SystemQueue(SystemF, \"Banking System F Queue\", \"A system of the bank.\")\n        SystemQueue_Ext(SystemG, \"Banking System G Queue\", \"A system of the bank, with personal bank accounts.\")\n      }\n    }\n  }\n\n  BiRel(customerA, SystemAA, \"Uses\")\n  BiRel(SystemAA, SystemE, \"Uses\")\n  Rel(SystemAA, SystemC, \"Sends e-mails\", \"SMTP\")\n  Rel(SystemC, customerA, \"Sends e-mails to\")\n\n  UpdateElementStyle(customerA, $fontColor=\"red\", $bgColor=\"grey\", $borderColor=\"red\")\n  UpdateRelStyle(customerA, SystemAA, $textColor=\"blue\", $lineColor=\"blue\", $offsetX=\"5\")\n  UpdateRelStyle(SystemAA, SystemE, $textColor=\"blue\", $lineColor=\"blue\", $offsetY=\"-10\")\n  UpdateRelStyle(SystemAA, SystemC, $textColor=\"blue\", $lineColor=\"blue\", $offsetY=\"-40\", $offsetX=\"-50\")\n  UpdateRelStyle(SystemC, customerA, $textColor=\"red\", $lineColor=\"red\", $offsetX=\"-50\", $offsetY=\"20\")\n\n  UpdateLayoutConfig($c4ShapeInRow=\"3\", $c4BoundaryInRow=\"1\")\n\n\n</code></pre>"},{"location":"xxiii/2023-01-04-using-diagrams.html#examples","title":"Examples","text":"<pre><code>pie title NETFLIX\n         \"Time spent looking for movie\" : 90\n         \"Time spent watching it\" : 10\n</code></pre>"},{"location":"xxiii/2023-01-04-using-diagrams.html#user-journey-diagram","title":"User Journey Diagram","text":"<pre><code>journey\n    title My working day\n    section Go to work\n      Make tea: 5: Me\n      Go upstairs: 3: Me\n      Do work: 1: Me, Cat\n    section Go home\n      Go downstairs: 5: Me\n      Sit down: 5: Me\n</code></pre>"},{"location":"xxiii/2023-01-04-using-diagrams.html#sequence-diagrams","title":"Sequence diagrams","text":"<pre><code>sequenceDiagram\n    Alice-&gt;&gt;John: Hello John, how are you?\n    John--&gt;&gt;Alice: Great!\n    Alice-)John: See you later!\n</code></pre>"},{"location":"xxiii/2023-01-04-using-diagrams.html#requirement-diagram","title":"Requirement Diagram","text":"<pre><code>requirementDiagram\n\nrequirement test_req {\nid: 1\ntext: the test text.\nrisk: high\nverifymethod: test\n}\n\nelement test_entity {\ntype: simulation\n}\n\ntest_entity - satisfies -&gt; test_req\n</code></pre>"},{"location":"xxiii/2023-01-04-using-diagrams.html#flowcharts-basic-syntax","title":"Flowcharts - Basic Syntax","text":"<pre><code>flowchart LR\n    id\n</code></pre>"},{"location":"xxiii/2023-01-04-using-diagrams.html#entity-relationship-diagrams","title":"Entity Relationship Diagrams","text":"<pre><code>erDiagram\n    CUSTOMER ||--o{ ORDER : places\n    ORDER ||--|{ LINE-ITEM : contains\n    CUSTOMER }|..|{ DELIVERY-ADDRESS : uses\n</code></pre>"},{"location":"xxiii/2023-01-04-using-diagrams.html#pie-chart-diagrams","title":"Pie chart diagrams","text":"<pre><code>pie title Pets adopted by volunteers\n    \"Dogs\" : 386\n    \"Cats\" : 85\n    \"Rats\" : 15\n</code></pre>"},{"location":"xxiii/2023-01-04-using-diagrams.html#state-diagrams","title":"State diagrams","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; Still\n    Still --&gt; [*]\n\n    Still --&gt; Moving\n    Moving --&gt; Still\n    Moving --&gt; Crash\n    Crash --&gt; [*]\n</code></pre>"},{"location":"xxiii/2023-01-04-using-diagrams.html#gitgraph-diagrams","title":"Gitgraph Diagrams","text":"<pre><code>gitGraph\n   commit\n   commit\n   branch develop\n   checkout develop\n   commit\n   commit\n   checkout main\n   merge develop\n   commit\n   commit\n</code></pre>"},{"location":"xxiii/2023-01-04-using-diagrams.html#class-diagrams","title":"Class diagrams","text":"<pre><code>classDiagram\n    note \"From Duck till Zebra\"\n    Animal &lt;|-- Duck\n    note for Duck \"can fly\\ncan swim\\ncan dive\\ncan help in debugging\"\n    Animal &lt;|-- Fish\n    Animal &lt;|-- Zebra\n    Animal : +int age\n    Animal : +String gender\n    Animal: +isMammal()\n    Animal: +mate()\n    class Duck{\n        +String beakColor\n        +swim()\n        +quack()\n    }\n    class Fish{\n        -int sizeInFeet\n        -canEat()\n    }\n    class Zebra{\n        +bool is_wild\n        +run()\n    }\n</code></pre>"},{"location":"xxiii/2023-01-04-using-diagrams.html#gantt-diagrams","title":"Gantt diagrams","text":"<pre><code>gantt\n    title A Gantt Diagram\n    dateFormat  YYYY-MM-DD\n    section Section\n    A task           :a1, 2014-01-01, 30d\n    Another task     :after a1  , 20d\n    section Another\n    Task in sec      :2014-01-12  , 12d\n    another task      : 24d\n</code></pre> <pre><code>the following demos are not working, but {{len(syntaxes)-3}}/{{len(syntaxes)}} demos in one place ain't bad.\n\n- [ ] C4 Diagrams\n- [ ] Class diagrams (these work the mkdocs version)\n- [ ] Mindmap\n</code></pre> <p>the following demos are not working, but 10/13 demos in one place ain't bad.</p> <ul> <li> C4 Diagrams</li> <li> Class diagrams (these work the mkdocs version)</li> <li> Mindmap</li> </ul> <pre><code>## why did mermaid win?\n\ni &lt;3 `graphviz` and i'm curius why mermaid one.\ngraphviz is over 30 years old and written in c, but maybe the javascript was enough to win.\ndoes wasm change the game?\n\ni hope to explore this question further when i read the [graphviz authors take][mermaid-dot-author].\n\n[mermaid-dot-author]: https://forum.graphviz.org/t/github-adding-support-for-mermaid-diagrams/998\n</code></pre>"},{"location":"xxiii/2023-01-04-using-diagrams.html#why-did-mermaid-win","title":"why did mermaid win?","text":"<p>i &lt;3 <code>graphviz</code> and i'm curius why mermaid one. graphviz is over 30 years old and written in c, but maybe the javascript was enough to win. does wasm change the game?</p> <p>i hope to explore this question further when i read the graphviz authors take.</p> <pre><code>## appendix\n\n&gt; weird thing: i was only able to get mermaid to work when the title for the document did not have mermaid in it.\n</code></pre>"},{"location":"xxiii/2023-01-04-using-diagrams.html#appendix","title":"appendix","text":"<p>weird thing: i was only able to get mermaid to work when the title for the document did not have mermaid in it.</p>"},{"location":"xxiii/2023-01-07-pidgy-voila.html","title":"running <code>pidgy</code> in <code>voila</code>","text":"<p>this notebook demonstrates <code>pidgy</code> widget and voila integration.</p> <p></p> <pre><code>    # a blank line in pidgy suppressing the woven output\n    %reload_ext pidgy\n    shell.weave.template_type = \"widget\"\n</code></pre>        # a blank line in pidgy suppressing the woven output     %reload_ext pidgy     shell.weave.template_type = \"widget\""},{"location":"xxiii/2023-01-07-pidgy-voila.html#coookies","title":"COOOKIES!","text":"<p>the cookies demo is a go to demo from Bret Viktor's tanglejs.</p> <pre><code>if you eat {{cookies.value}} that you consume {{cookies.value * calories}} calories.\n</code></pre> <pre><code>    calories = 50\n    display(cookies := IntSlider(3, 1, description=\"COOKIES\"))\n</code></pre>        calories = 50     display(cookies := IntSlider(3, 1, description=\"COOKIES\"))   <pre><code>## `pidgy` widget integration\n\nout of the box, `pidgy` relies on `IPython`s markdown display, but in this document we use the `pidgy.displays.IPyWidgetsHtml` display\n\n    shell.weave.template_cls = pidgy.displays.IPyWidgetsHtml\n\nthe  reactive and asynchronous `pidgy.displays.IPyWidgetsHtml` display passes the input through a jinja environment then it is parsed into html by `shell.weave.markdown_renderer`.\n\n\nafter each exection we link undeclared variables in the jinja templates to any interactive widgets.\nwhen widgets change, the display changes as shown in the COOOKIES demo.\n</code></pre>"},{"location":"xxiii/2023-01-09-notebooks-states.html","title":"three states of python in a notebook","text":"<p>most folks are familiar with notebooks in their interactive forms. in <code>IPython</code>, we are working in python and <code>__name__ == \"__main__\"</code>. for python programs, this condition is the last stop for our program, but in notebooks it is just the beginning. i like to thing we development programs and applications in reverse in notebooks.</p> <p>with experience, it is possible to author notebooks that operate as programs/scripts. this document demonstrates some advanced usage patterns to apply to get the most out of future notebooks.</p> <pre><code>    %reload_ext pidgy\n</code></pre>        %reload_ext pidgy   <pre><code>the three python compilation states of notebooks:\n\n* an __interactive__ state when we are authoring notebooks.\n* a __script__ state when a notebook is used as procedural code.\n* a __module__ when it is imported like any python resource \n\nwe need to confer with the `__name__` and `__file__` properties of a \nmodule's runtime to know which state we are in.\n\n| state  | `__name__` | `__file__` |\n|--------|------------|------------|\n|interactive| `__name__ == \"__main__\"` | `\"__file__\" not in locals()` |\n|module| `__name__ != \"__main__\"` | `\"__file__\" in locals()` |\n|script| `__name__ == \"__main__\"` | `\"__file__\" in locals()` |\n</code></pre> <p>the three python compilation states of notebooks:</p> <ul> <li>an interactive state when we are authoring notebooks.</li> <li>a script state when a notebook is used as procedural code.</li> <li>a module when it is imported like any python resource </li> </ul> <p>we need to confer with the <code>__name__</code> and <code>__file__</code> properties of a  module's runtime to know which state we are in.</p> state <code>__name__</code> <code>__file__</code> interactive <code>__name__ == \"__main__\"</code> <code>\"__file__\" not in locals()</code> module <code>__name__ != \"__main__\"</code> <code>\"__file__\" in locals()</code> script <code>__name__ == \"__main__\"</code> <code>\"__file__\" in locals()</code> <pre><code>## python state logic\n\nthe three conditions are expressed in python code below\n\n    MAIN, FILE = __name__ == \"__main__\", \"__file__\" in locals()\n    INTERACTIVE = MAIN and not FILE\n    SCRIPT = MAIN and FILE\n    MODULE = FILE and not MAIN\n\n\nthese states let us write multi purpose documents that can be used in multiple contexts\nand sharing the benefits of all of them.\n</code></pre>"},{"location":"xxiii/2023-01-09-notebooks-states.html#python-state-logic","title":"python state logic","text":"<p>the three conditions are expressed in python code below</p> <pre><code>MAIN, FILE = __name__ == \"__main__\", \"__file__\" in locals()\nINTERACTIVE = MAIN and not FILE\nSCRIPT = MAIN and FILE\nMODULE = FILE and not MAIN\n</code></pre> <p>these states let us write multi purpose documents that can be used in multiple contexts and sharing the benefits of all of them.</p>"},{"location":"xxiii/2023-01-09-notebooks-states.html#applying-the-condition","title":"applying the condition","text":"<pre><code>    def a_bad_ass_function(who: str = \"you\"):\ntells you who the bad ass is.\n\n        &gt;&gt;&gt; a_bad_ass_function()\n        you are bad ass.\n\n        print(F\"{who} are bad ass.\")\n</code></pre> <pre><code>def a_bad_ass_function(who: str = \"you\"):\n</code></pre> <p>tells you who the bad ass is.</p> <pre><code>    &gt;&gt;&gt; a_bad_ass_function()\n    you are bad ass.\n\n    print(F\"{who} are bad ass.\")\n</code></pre> <pre><code>### the `MAIN` conditions\n\n`INTERACTIVE` notebooks and `SCRIPT`s both have `__name__ == \"__main__\"`\n</code></pre>"},{"location":"xxiii/2023-01-09-notebooks-states.html#the-main-conditions","title":"the <code>MAIN</code> conditions","text":"<p><code>INTERACTIVE</code> notebooks and <code>SCRIPT</code>s both have <code>__name__ == \"__main__\"</code></p> <pre><code>#### the `SCRIPT` conditin\n\n    if SCRIPT:\nwe import the notebook and run the command line program.\n\nbelowis a `typer` application that is only executed when the notebook is used as a script\n\n        import typer\n        typer.run(a_bad_ass_function)\n\n#### the `INTERACTIVE` condition\n\n        if INTERACTIVE:\ndata for demonstration is computed and displayed\n\n            !midgy 2023-01-09-notebooks-states.ipynb --help\n            !midgy 2023-01-09-notebooks-states.ipynb --who \"y'alls\"\n</code></pre>"},{"location":"xxiii/2023-01-09-notebooks-states.html#the-script-conditin","title":"the <code>SCRIPT</code> conditin","text":"<pre><code>if SCRIPT:\n</code></pre> <p>we import the notebook and run the command line program.</p> <p>belowis a <code>typer</code> application that is only executed when the notebook is used as a script</p> <pre><code>    import typer\n    typer.run(a_bad_ass_function)\n</code></pre>"},{"location":"xxiii/2023-01-09-notebooks-states.html#the-interactive-condition","title":"the <code>INTERACTIVE</code> condition","text":"<pre><code>    if INTERACTIVE:\n</code></pre> <p>data for demonstration is computed and displayed</p> <pre><code>        !midgy 2023-01-09-notebooks-states.ipynb --help\n        !midgy 2023-01-09-notebooks-states.ipynb --who \"y'alls\"\n</code></pre>"},{"location":"xxiii/2023-01-09-notebooks-states.html#the-module-condition","title":"the <code>MODULE</code> condition","text":"<pre><code>    if MODULE:\nwe import the notebook and avoid running an command line programs.\noften notebooks as tests are loaded under this condition.\n</code></pre> <pre><code>if MODULE:\n</code></pre> <p>we import the notebook and avoid running an command line programs. often notebooks as tests are loaded under this condition.</p> <pre><code>    if INTERACTIVE:\n        import midgy.loader\n        with midgy.loader.Markdown(extensions=[\".ipynb\"]):\n            import __notebooks_states\n\n        display(repr(__notebooks_states))\n</code></pre> <pre>\"&lt;module '2023-01-09-notebooks-states' from '/home/tbone/Documents/tonyfast/tonyfast/xxiii/2023-01-09-notebooks-states.ipynb'&gt;\"</pre> <pre><code>if INTERACTIVE:\n    import midgy.loader\n    with midgy.loader.Markdown(extensions=[\".ipynb\"]):\n        import __notebooks_states\n\n    display(repr(__notebooks_states))\n</code></pre> <pre><code>## the benefits of knowing the state\n\nknowing the state or context of a notebook's execution allows us to write logic that makes notebooks a swiss army knife.\nsome advanced patterns are include [testing notebooks] or [writing command line scripts].\n\n[testing notebooks]: https://nbviewer.org/gist/tonyfast/b617e4f87337a50e1361ab043b53c2c7\n[writing command line scripts]: https://tonyfast.github.io/tonyfast/xxii/2022-12-19-integrating-typer.html\n</code></pre>"},{"location":"xxiii/2023-01-09-notebooks-states.html#the-benefits-of-knowing-the-state","title":"the benefits of knowing the state","text":"<p>knowing the state or context of a notebook's execution allows us to write logic that makes notebooks a swiss army knife. some advanced patterns are include testing notebooks or writing command line scripts.</p> <pre><code>### applying `doctest`s\n</code></pre>"},{"location":"xxiii/2023-01-09-notebooks-states.html#applying-doctests","title":"applying <code>doctest</code>s","text":"<pre><code>`a_bad_ass_function` has a doctest in the docstring. \nwhen working interactively we might want to run these tests to verify\nour idea works.\n\n    if INTERACTIVE:\nwe only want to execute the `doctest`s in interactive mode\n\n        import doctest\n        display(doctest.testmod())\n</code></pre> <pre>TestResults(failed=0, attempted=1)</pre> <p><code>a_bad_ass_function</code> has a doctest in the docstring.  when working interactively we might want to run these tests to verify our idea works.</p> <pre><code>if INTERACTIVE:\n</code></pre> <p>we only want to execute the <code>doctest</code>s in interactive mode</p> <pre><code>    import doctest\n    display(doctest.testmod())\n</code></pre>"},{"location":"xxiii/2023-01-10-rara-gtfo.html","title":"restart and run all or it didn't happen","text":"<p>my golden rule for notebooks is Restart and run all or it didn't happen. RARA||GTFO for short.</p> <p>the RARA criteria is satisfied when:</p> <ol> <li>all of the cells are executed. conversely, there are not any unexecuted cells.</li> <li>all of the cells prompt numbers increase monotonically. out-of-order prompts means out-of-order execution and the possibility of hidden state.</li> </ol> <p></p> <pre><code>    %reload_ext pidgy\n    rara = F\"&lt;abbr&gt;RARA&lt;/abbr&gt;\"\n</code></pre>        %reload_ext pidgy     rara = F\"RARA\"   <pre><code>    RARA = \"__Restart and run all__\"\n</code></pre> <pre><code>RARA = \"__Restart and run all__\"\n</code></pre> <pre><code>## benefits of &lt;abbr title=\"{{RARA.strip(\"_\")}}\"&gt;RARA&lt;/abbr&gt;||&lt;abbr title=\"Get The Fart Out\"&gt;GTFO&lt;/abbr&gt;\n\na computational notebook is a [literate program] that composites narrative and code;\nit simultaneously has the qualities of __literature__ and a __program__.\nliterate programs introduce a computational qualities to documents,\nand the compute implied the authoring system had [state].\n\n[a common complaint is that literate notebook programs contain hidden states][complaint].\nhidden state is happens when code cells are executed out-of-order,\nor not executed at all.\nexecuting code cells ensures that code can be read by at least one machine; the code input worked at some point.\nordered execution is an objective measure of non-hidden state [^tamper].\n\nin the literature, [Exploration and Explanation in Computational Notebooks], a large scale analysis of notebooks,\nthey distinguish between linear notebooks and non-linear notebooks.\nnon-linear notebooks are most likely to have [hidden state](https://ploomber.io/blog/nbs-myths/#hidden-state).\nat scale, {{RARA.lower()}} is a distinguishing quality of computational notebooks.\n\n&gt; [The most prevalent expression of literate computing right now is the computational notebook.][landscape]\n\n[fernando perez] - co-founder of [Project Jupyter] - acknowledged that notebooks are literate programs with something extra.\nhe describes notebook authoring as [literate computing] where live computation is woven into the document.\nthe notebook document is stateful, statefulness is a quality of this new media.\n\nthe {{RARA.lower()}} criteria verifies that code inputs work and there is not hidden state.\n\n[^tamper]: it is possible that inputs were tampered with, but let us assume the best intentions.\n\n[literate computing]: https://web.archive.org/web/20220510083647/http://blog.fperez.org/2013/04/literate-computing-and-computational.html\n[landscape]: https://www.ppig.org/files/2019-PPIG-30th-fog.pdf\n[complaint]: https://towardsdatascience.com/the-case-against-the-jupyter-notebook-d4da17e97243\n[story in notebook]: https://marybethkery.com/projects/Verdant/Kery-The-Story-in-the-Notebook-Exploratory-Data-Science-using-a-Literate-Programming-Tool.pdf\n[literate program]: https://en.wikipedia.org/wiki/Literate_programming\n[fernando perez]: https://en.wikipedia.org/wiki/Fernando_P%C3%A9rez_(software_developer)\n[Project Jupyter]: https://jupyter.org/\n[Exploration and Explanation in Computational Notebooks]: https://adamrule.com/files/papers/chi_2018_computational_notebooks_camera_ready.pdf\n[state]: https://en.wikipedia.org/wiki/State_(computer_science)\n</code></pre>"},{"location":"xxiii/2023-01-10-rara-gtfo.html#benefits-of-raragtfo","title":"benefits of RARA||GTFO","text":"<p>a computational notebook is a literate program that composites narrative and code; it simultaneously has the qualities of literature and a program. literate programs introduce a computational qualities to documents, and the compute implied the authoring system had state.</p> <p>a common complaint is that literate notebook programs contain hidden states. hidden state is happens when code cells are executed out-of-order, or not executed at all. executing code cells ensures that code can be read by at least one machine; the code input worked at some point. ordered execution is an objective measure of non-hidden state 1.</p> <p>in the literature, Exploration and Explanation in Computational Notebooks, a large scale analysis of notebooks, they distinguish between linear notebooks and non-linear notebooks. non-linear notebooks are most likely to have hidden state. at scale, restart and run all is a distinguishing quality of computational notebooks.</p> <p>The most prevalent expression of literate computing right now is the computational notebook.</p> <p>fernando perez - co-founder of Project Jupyter - acknowledged that notebooks are literate programs with something extra. he describes notebook authoring as literate computing where live computation is woven into the document. the notebook document is stateful, statefulness is a quality of this new media.</p> <p>the restart and run all criteria verifies that code inputs work and there is not hidden state.</p> <pre><code>### executed code in computational notebooks\n\nwhen notebooks are observed as documents,\ncode objects are literary devices actively participating in the narrative.\nthese code objects have two distinct states:\n\n1. NOT executed code\n\n    un-executed reverses back into normal language. it is [arbitrary symbol] propping up the narrative.\n\n2. executed code\n\n    executed code encapsulates a form of pre-formatted input code and corresponding output respresentations.\n    the input and outputs cooperate - through text and form - to bring meaning to the coded object.\n\n\nNOT executed code has arbitrary meaning, trust it like you would code returned from [chatgpt](https://openai.com/blog/chatgpt/).\non the other hand, executed code has inputs, outputs and prompts.\nwhen the prompts are populated we know a cell has been executed.\nwhen all the cells execute in order we satisfy the {{RARA.lower()}} criteria.\n\n[arbitrary symbol]: https://psychologydictionary.org/arbitrary-symbol/\n</code></pre>"},{"location":"xxiii/2023-01-10-rara-gtfo.html#executed-code-in-computational-notebooks","title":"executed code in computational notebooks","text":"<p>when notebooks are observed as documents, code objects are literary devices actively participating in the narrative. these code objects have two distinct states:</p> <ol> <li> <p>NOT executed code</p> <p>un-executed reverses back into normal language. it is arbitrary symbol propping up the narrative.</p> </li> <li> <p>executed code</p> <p>executed code encapsulates a form of pre-formatted input code and corresponding output respresentations. the input and outputs cooperate - through text and form - to bring meaning to the coded object.</p> </li> </ol> <p>NOT executed code has arbitrary meaning, trust it like you would code returned from chatgpt. on the other hand, executed code has inputs, outputs and prompts. when the prompts are populated we know a cell has been executed. when all the cells execute in order we satisfy the restart and run all criteria.</p> <pre><code>## {{RARA}} criteria implementation\n\n    def restart_and_run_all(file, code_cell_count=0):\n`restart_and_run_all` is violated when we iterate through the the notebook cells\n\n        for i, cell in enumerate((notebook := read_file(file)).cells):\n            if cell[\"cell_type\"] == \"code\":\nto discover a code cell:\n\n                code_cell_count += 1\n                try:\n* that has not been executed because the prompt is not an integer\n\n                    current_count = int(cell.execution_count)\n                except ValueError: raise UnexecutedCell(F\"cell {i} not executed\")\n                if code_cell_count != current_count:\n* has cell prompts that do not align with current cell count\n\n                    raise OutOfOrderExecution(F\"cell {i} is executed out of order\")\n</code></pre>"},{"location":"xxiii/2023-01-10-rara-gtfo.html#restart-and-run-all-criteria-implementation","title":"Restart and run all criteria implementation","text":"<pre><code>def restart_and_run_all(file, code_cell_count=0):\n</code></pre> <p><code>restart_and_run_all</code> is violated when we iterate through the the notebook cells</p> <pre><code>    for i, cell in enumerate((notebook := read_file(file)).cells):\n        if cell[\"cell_type\"] == \"code\":\n</code></pre> <p>to discover a code cell:</p> <pre><code>            code_cell_count += 1\n            try:\n</code></pre> <ul> <li>that has not been executed because the prompt is not an integer<pre><code>            current_count = int(cell.execution_count)\n        except ValueError: raise UnexecutedCell(F\"cell {i} not executed\")\n        if code_cell_count != current_count:\n</code></pre> <ul> <li>has cell prompts that do not align with current cell count<pre><code>        raise OutOfOrderExecution(F\"cell {i} is executed out of order\")\n</code></pre> </li> </ul> </li> </ul> <pre><code>### {{RARA}} exceptions\n\nwe assign two formal `BaseException`s for `restart_and_run_all`: `OutOfOrderExection` and `UnexecutedCell`\n\n#### unexecuted cells\n\nunexecuted cells are representations only by the preformatted text input.\nthey lack an outputs or prompt number. \nwithout these features the code stands on its own.\nit reverts back to pseudocode.\n\n    class UnexecutedCell(BaseException):\n`UnexecutedCell`s raises when the code cell execution counts is a non-integer.\n\n\n#### out of order execution\n\nthere are some tools that are designed to be reactive or executed out of order.\nthe RARA criterion does not dismiss these cases rather it could be a starting state.\nwe may suspect hidden state\n\n    class OutOfOrderExection:\n`OutOfOrderExection` raises when code cell execution counts are not monotonically increasing.\n\n    def read_file(file):\n        if not isinstance(file, str): file = file.__file__\n        with open(file) as f: return nbformat.v4.reads(f.read())\n\n### extra preservatives\n\nnotebooks are swiss army knives documents; they have application as tests, modules, scripts and documents.\nthe {{RARA.lower()}} criteria combined with the [different cell execution states][states]: `INTERACTIVE`, `SCRIPT`, or `MODULE`.\n\n\n    assert restart_and_run_all(\"2023-01-09-notebooks-states.ipynb\") is None,\\\nerrors are raised when failing, and i don't want to demostrate failure here\n\nwhen we assert that a previous notebook will {{RARA.lower()}}\nwe become slightly more confident about the code in that document.\n\n[state]: 2023-01-09-notebooks-states.ipynb\n</code></pre>"},{"location":"xxiii/2023-01-10-rara-gtfo.html#restart-and-run-all-exceptions","title":"Restart and run all exceptions","text":"<p>we assign two formal <code>BaseException</code>s for <code>restart_and_run_all</code>: <code>OutOfOrderExection</code> and <code>UnexecutedCell</code></p>"},{"location":"xxiii/2023-01-10-rara-gtfo.html#unexecuted-cells","title":"unexecuted cells","text":"<p>unexecuted cells are representations only by the preformatted text input. they lack an outputs or prompt number.  without these features the code stands on its own. it reverts back to pseudocode.</p> <pre><code>class UnexecutedCell(BaseException):\n</code></pre> <p><code>UnexecutedCell</code>s raises when the code cell execution counts is a non-integer.</p>"},{"location":"xxiii/2023-01-10-rara-gtfo.html#out-of-order-execution","title":"out of order execution","text":"<p>there are some tools that are designed to be reactive or executed out of order. the RARA criterion does not dismiss these cases rather it could be a starting state. we may suspect hidden state</p> <pre><code>class OutOfOrderExection:\n</code></pre> <p><code>OutOfOrderExection</code> raises when code cell execution counts are not monotonically increasing.</p> <pre><code>def read_file(file):\n    if not isinstance(file, str): file = file.__file__\n    with open(file) as f: return nbformat.v4.reads(f.read())\n</code></pre>"},{"location":"xxiii/2023-01-10-rara-gtfo.html#extra-preservatives","title":"extra preservatives","text":"<p>notebooks are swiss army knives documents; they have application as tests, modules, scripts and documents. the restart and run all criteria combined with the different cell execution states: <code>INTERACTIVE</code>, <code>SCRIPT</code>, or <code>MODULE</code>.</p> <pre><code>assert restart_and_run_all(\"2023-01-09-notebooks-states.ipynb\") is None,\\\n</code></pre> <p>errors are raised when failing, and i don't want to demostrate failure here</p> <p>when we assert that a previous notebook will restart and run all we become slightly more confident about the code in that document.</p> <pre><code>## impacts of {{RARA}}-ability\n\n### {{RARA}} and reusability\n\nrestart and run all is critical to reusing python notebooks as [modules, tests or scripts].\nthere are a few ways of [testing notebooks], and none of these methods suceed without notebooks that restart and run all.\n\n{{RARA.lower()}} as a practice will encourage you to write notebooks you'll be able to return to.\n\n[modules, tests or scripts]: 2023-01-09-notebooks-states.ipynb\n[testing notebooks]: https://nbviewer.org/gist/tonyfast/e7dd7ff3d808d57b77e9765626a73a91\n</code></pre>"},{"location":"xxiii/2023-01-10-rara-gtfo.html#impacts-of-restart-and-run-all-ability","title":"impacts of Restart and run all-ability","text":""},{"location":"xxiii/2023-01-10-rara-gtfo.html#restart-and-run-all-and-reusability","title":"Restart and run all and reusability","text":"<p>restart and run all is critical to reusing python notebooks as modules, tests or scripts. there are a few ways of testing notebooks, and none of these methods suceed without notebooks that restart and run all.</p> <p>restart and run all as a practice will encourage you to write notebooks you'll be able to return to.</p> <pre><code>### &lt;abbr&gt;RARA&lt;/abbr&gt; conflicts\n\n#### too many ideas\n\nit is easy to put [too many units of thought into a notebook](#Restart-and-run-all-roots). \nthis struggle can be striking when sticking to the restart and run all principle.\nwhen we write documents about single units of thought we are treading in formal testing territory.\n\n\n#### compute intensive operations\n\na push against {{RARA.lower()}} is having large datasets or other compute intensive operations.\nwe apply the &lt;abbr title=\"cache rules everything around me\"&gt;CREAM&lt;/abbr&gt; principle and cache our \ncompute intensive tasks. \nin these situations, authors will benefit data engineering there work to avoid\ncostly repetitive tasks; you'll save your future self time.\n</code></pre>"},{"location":"xxiii/2023-01-10-rara-gtfo.html#rara-conflicts","title":"RARA conflicts","text":""},{"location":"xxiii/2023-01-10-rara-gtfo.html#too-many-ideas","title":"too many ideas","text":"<p>it is easy to put too many units of thought into a notebook.  this struggle can be striking when sticking to the restart and run all principle. when we write documents about single units of thought we are treading in formal testing territory.</p>"},{"location":"xxiii/2023-01-10-rara-gtfo.html#compute-intensive-operations","title":"compute intensive operations","text":"<p>a push against restart and run all is having large datasets or other compute intensive operations. we apply the CREAM principle and cache our  compute intensive tasks.  in these situations, authors will benefit data engineering there work to avoid costly repetitive tasks; you'll save your future self time.</p> <pre><code>## \ud83d\udce3 write notebooks that endure\n\n{{rara}} || &lt;abbr&gt;GTFO&lt;/abbr&gt; helps us trust our's and other's notebooks more.\nwe can be slightly more confident in future uses of that work.\n\n{{rara}}. i'm cheering for y'all. i see y'all beating the snot out of every line of code.\nlet's make these efforts endure. remember to tell you friends &lt;q&gt;{{RARA.strip(\"_\")}} or &lt;abbr&gt;GTFO&lt;/abbr&gt;.&lt;/q&gt;\n</code></pre>"},{"location":"xxiii/2023-01-10-rara-gtfo.html#write-notebooks-that-endure","title":"\ud83d\udce3 write notebooks that endure","text":"<p>RARA || GTFO helps us trust our's and other's notebooks more. we can be slightly more confident in future uses of that work.</p> <p>RARA. i'm cheering for y'all. i see y'all beating the snot out of every line of code. let's make these efforts endure. remember to tell you friends Restart and run all or GTFO.</p> <pre><code>## devils \ud83d\ude08 share\n### {{RARA}} roots\n\npaco nathan was the first person i heard this concept from.\nat [Jupyter Day 2016], at the time, he was using notebooks as medium\nfor immersive professional publications. these oriole notebooks\nwere educational tools that embedded the teacher and the runtime together.\nthere were some beautiful videos produced with some big names like:...\n\n[paco] presented what his team learned when [producing teaching videos with notebooks][oriole].\n\n&gt; 1. focus on a concise \"unit of thought\"\n&gt; 1. invest the time and editorial effort to create a good introduction\n&gt; 1. keep your narrative simple and reasonably linear\n&gt; 1. \"chunk\" both the text and the code into understandable parts\n&gt; 1. alternate between text, code, output, further links, etc.\n&gt; 1. leverage markdown by providing interesting links for background, deep-dive, etc.\n&gt; 1. code cells should not be long, &lt; 10 lines\n&gt; 1. code cells must show that they've run, producing at least some output\n&gt; 1. load data from the container, not the network\n&gt; 1. __clear all output then \"Run All\" -- or it didn't happen__\n&gt; 1. video narratives: there's text, and there's subtext...\n&gt; 1. pause after each \"beat\" -- smile, breathe, allow people to follow you\n\nand there, clear as day, in the tenth bullet, we find __clear all output then \"Run All\" -- or it didn't happen__.\ni love that this pattern was discovered when producing video content.\nit means that {{RARA}} is critical to communicating our ideas with notebooks as the substrate.\n\n[oriole]: https://github.com/ceteri/oriole_jupyterday_atl/blob/master/oriole_talk.ipynb\n[paco]: https://github.com/ceteri\n[Jupyter Day 2016]: https://jupyterday-atlanta-2016.github.io/#paconathan\n</code></pre>"},{"location":"xxiii/2023-01-10-rara-gtfo.html#devils-share","title":"devils \ud83d\ude08 share","text":""},{"location":"xxiii/2023-01-10-rara-gtfo.html#restart-and-run-all-roots","title":"Restart and run all roots","text":"<p>paco nathan was the first person i heard this concept from. at Jupyter Day 2016, at the time, he was using notebooks as medium for immersive professional publications. these oriole notebooks were educational tools that embedded the teacher and the runtime together. there were some beautiful videos produced with some big names like:...</p> <p>paco presented what his team learned when producing teaching videos with notebooks.</p> <ol> <li>focus on a concise \"unit of thought\"</li> <li>invest the time and editorial effort to create a good introduction</li> <li>keep your narrative simple and reasonably linear</li> <li>\"chunk\" both the text and the code into understandable parts</li> <li>alternate between text, code, output, further links, etc.</li> <li>leverage markdown by providing interesting links for background, deep-dive, etc.</li> <li>code cells should not be long, &lt; 10 lines</li> <li>code cells must show that they've run, producing at least some output</li> <li>load data from the container, not the network</li> <li>clear all output then \"Run All\" -- or it didn't happen</li> <li>video narratives: there's text, and there's subtext...</li> <li>pause after each \"beat\" -- smile, breathe, allow people to follow you</li> </ol> <p>and there, clear as day, in the tenth bullet, we find clear all output then \"Run All\" -- or it didn't happen. i love that this pattern was discovered when producing video content. it means that Restart and run all is critical to communicating our ideas with notebooks as the substrate.</p> <ol> <li> <p>it is possible that inputs were tampered with, but let us assume the best intentions.\u00a0\u21a9</p> </li> </ol>"},{"location":"xxiii/2023-01-11-duckdb-search.html","title":"full text search for notebooks and files using duckdb","text":"<p><code>duckdb</code> is great for moderate sized data. maybe it would be good for searching notebooks. i know <code>pandas</code> so we are going to use <code>pandas</code> to load in our data</p> <ol> <li>reads files</li> <li>load contents in the <code>nbformat</code></li> <li>create the table on a in memory duckdb</li> <li>at full text search the columns</li> <li>search the source</li> </ol> <pre><code>    import pandas, duckdb, functools\n</code></pre>"},{"location":"xxiii/2023-01-11-duckdb-search.html#search-is-our-database-goal","title":"<code>search</code> is our database goal","text":"<p>the use of the <code>search</code> is demonstrated at the end of the document</p> <pre><code>    def search(q) -&gt; pandas.DataFrame:\n        return (get_db().execute(F\"\"\"\n        SELECT * FROM\n        (\n            SELECT *, fts_main_cells.match_bm25(path, '{q}', fields:='source') AS score FROM cells\n        )\n        WHERE score IS NOT NULL\n        ORDER BY score DESC;\n        \"\"\")).df()\n</code></pre> <p>https://duckdb.org/docs/extensions/full_text_search</p> <pre><code>    @functools.lru_cache # this makes our function a singleton\n    def get_db() -&gt; duckdb.DuckDBPyConnection:\n        con = duckdb.connect()\n        con.execute(\"CREATE TABLE cells AS SELECT * FROM sources\")\n        con.execute(\"INSERT INTO cells SELECT * FROM sources\")\n        con.execute(\"\"\"PRAGMA create_fts_index('cells', 'path', 'source');\"\"\")\n        return con    \n</code></pre> <p>create a shape of the cells that duckdb can use. we ignore metadata, attachments and outputs.</p> <pre><code>    def get_fts_sources(cells):\n        sources = cells.drop(columns=[\"metadata\", \"attachments\", \"outputs\"])\n        sources.source = sources.source.str.join(\"\")\n        sources = sources.set_index(sources.index.map(compose_left(map(str), \"#/cells/\".join)).rename(\"path\")).reset_index()\n        sources.execution_count = sources.execution_count.fillna(-1)\n        return sources\n</code></pre>"},{"location":"xxiii/2023-01-11-duckdb-search.html#load-all-the-documents-in-as-cells","title":"load all the documents in as cells","text":"<pre><code>    def get_cells(docs):    \n        return (\n            docs[\"cells\"].apply(\n                compose_left(enumerate, list)\n            ).explode().apply(pandas.Series)\n            .rename(columns={0: \"cell_ct\", 1: \"cell\"})\n            .set_index(\"cell_ct\", append=True)[\"cell\"]\n            .apply(pandas.Series)\n        )\n</code></pre> <p><code>get_files</code> creates our first dataframes</p> <pre><code>    def get_files(dir) -&gt; pandas.DataFrame:\n        files = pandas.DataFrame(index=pandas.Index(iter_files(dir), name=\"file\"))\n        return files.assign(suffix=files.index.map(operator.attrgetter(\"suffix\")))\n</code></pre> <p><code>get_markdown_file</code> reads a markdown file as a markdown notebook cell.</p> <pre><code>    def get_markdown_file(md):\n        import nbformat\n        return nbformat.v4.new_notebook(cells=[nbformat.v4.new_markdown_cell(md)])    \n</code></pre> <pre><code>    def get_docs(files: pandas.DataFrame) -&gt; pandas.DataFrame:\n        files = files.assign(text=files.index.map(pathlib.Path.read_text))\n        return pandas.concat([\n            files[files.suffix.eq(\".ipynb\")].text.apply(compose_left(orjson.loads, pandas.Series)),\n            files[files.suffix.eq(\".md\")].text.apply(compose_left(get_markdown_file, pandas.Series)),        \n        ])\n</code></pre> <pre><code>    def get_cells_frame(dir): return get_cells(get_docs(get_files(dir))) \n</code></pre> <p><code>iter_files</code> finds files matching an include pattern, and not matching an exclude pattern</p> <pre><code>    def iter_files(dir=None, exclude=\".nox\\n.ipynb_checkpoints\\n\", include=\"*.md\\n*.ipynb\"):\n        import pathspec\n        exclude_spec = pathspec.PathSpec.from_lines(pathspec.GitIgnorePattern, exclude.splitlines())\n        include_spec = pathspec.PathSpec.from_lines(pathspec.GitIgnorePattern, include.splitlines())            \n        dir = pathlib.Path(dir or pathlib.Path.cwd())\n        for f in dir.iterdir():\n            if f.is_dir():\n                if not exclude_spec.match_file(f):\n                    yield from iter_files(f)\n            if f.is_file():\n                if include_spec.match_file(f):\n                    if not exclude_spec.match_file(f):\n                        yield f\n</code></pre> <p><code>iter_files</code> uses a pattern i like where <code>pathspec</code> defines the files included and excluded. sometimes include/exclude logic can be confusing. the <code>.gitignore</code> convention is adopted to rely on that and point someone else's docs.</p>"},{"location":"xxiii/2023-01-11-duckdb-search.html#using-our-search-function","title":"using our search function","text":"<pre><code>    import pathspec, dataclasses, orjson, pathlib; from toolz.curried import *\n</code></pre> <p>initialize the <code>pandas.DataFrame</code> so <code>duckdb</code> can use it. our table in this work is <code>cells</code></p>"},{"location":"xxiii/2023-01-11-duckdb-search.html#initialize-the-duckdb-tables-from-pandas","title":"initialize the <code>duckdb</code> tables from pandas","text":"<p>https://duckdb.org/docs/guides/python/import_pandas.html</p> <pre><code>    if (I := \"__file__\" not in locals()):\n        sources = get_fts_sources(get_cells_frame(\"..\"))\n        display(get_db().execute(\"DESCRIBE cells\").df())\n</code></pre> column_name column_type null key default extra 0 path VARCHAR YES NaN NaN NaN 1 cell_type VARCHAR YES NaN NaN NaN 2 id VARCHAR YES NaN NaN NaN 3 source VARCHAR YES NaN NaN NaN 4 execution_count DOUBLE YES NaN NaN NaN"},{"location":"xxiii/2023-01-11-duckdb-search.html#sample-searches","title":"sample searches","text":"<pre><code>    I and display(search(\"pandas\").head())\n</code></pre> path cell_type id source execution_count score 0 ../xxii/oct/2022-10-29-metadata-formatter.ipyn... code e3a8b43e-aaeb-4b7a-9ccb-4485ae0689a0 if ACTIVE:\\n        import pandas\\n       ... 8.0 1.718594 1 ../xxii/oct/2022-10-29-metadata-formatter.ipyn... code e3a8b43e-aaeb-4b7a-9ccb-4485ae0689a0 if ACTIVE:\\n        import pandas\\n       ... 8.0 1.718594 2 ../xxiii/2023-01-02-accessible-dataframes-basi... code 401913ff-534f-4659-aec5-0784b1f1f34c (df := pandas.DataFrame(\\n        columns=... 2.0 1.679535 3 ../xxiii/2023-01-11-accessible-dataframes-comp... code 401913ff-534f-4659-aec5-0784b1f1f34c (df := pandas.DataFrame(\\n        columns=... 2.0 1.679535 4 ../xxiii/2023-01-02-accessible-dataframes-basi... code 401913ff-534f-4659-aec5-0784b1f1f34c (df := pandas.DataFrame(\\n        columns=... 2.0 1.679535 <pre><code>    I and display(search(\"toolz\").head(4))\n</code></pre> path cell_type id source execution_count score 0 ../xxii/oct/colormap-dataframes/2021-10-11-col... code 391cab50-209e-4843-8bea-0405f6734e6f import pandas, numpy, toolz.curried as toolz 1.0 3.776350 1 ../xxii/oct/colormap-dataframes/2021-10-11-col... code 391cab50-209e-4843-8bea-0405f6734e6f import pandas, numpy, toolz.curried as toolz 1.0 3.776350 2 ../xxiii/2023-01-11-duckdb-search.ipynb#/cells/20 code d3a6ca2a-7b1d-4f0a-a86c-9345913468c0 import pathspec, dataclasses, orjson, path... -1.0 3.340617 3 ../xxiii/2023-01-11-duckdb-search.ipynb#/cells/26 code 589d3fb6-a4bb-434f-a06e-05d57fe57f09 I and display(search(\"toolz\").head(4)) -1.0 3.340617"},{"location":"xxiii/2023-01-11-extensible-metadata.html","title":"extensible metadata in the notebook format","text":"<p>this document is the minimum schema to make metadata extensible. it makes clearer distinctions between the notebook, cell and display metadata.</p> <p>new metadata schema are combined using the <code>allOf</code> key that references schema from other places.</p> <pre><code>    %reload_ext pidgy\n    from midgy.utils import *; import tomli\n</code></pre>        %reload_ext pidgy     from midgy.utils import *; import tomli   <p>the extended schema is written below in toml.</p> <pre><code>    schema = strip_fence | tomli.loads | \\\n```toml\ndescription = \"extensible metadata for the notebook schema.\"\n\n[\"$defs\".notebook-meta]\n\"$anchor\" = \"notebook-meta\"\nallOf = [\n    {\"$ref\" = \"kernelspec.json\"}\n]\n\n[\"$defs\".code-meta]\n\"$anchor\" = \"code-meta\"\nallOf = [\n    {\"$ref\" = \"#slides\"}\n]\n\n[\"$defs\".display-meta]\n\"$anchor\" = \"display-meta\"\nallOf = [\n    {\"$ref\" = \"#images\"},\n    {\"$ref\" = \"#json\"}\n]\n\n[\"$defs\".slides]\n\"$anchor\" = \"slides\"\nproperties.slides.enum = [\"slide\", \"subslide\", \"fragment\"]\n\n[properties]\nmetadata.\"$ref\" = \"#notebook-meta\"\n\n[properties.cells.items.properties.metadata]\n\"$ref\" = \"#cell-meta\"\n\n[properties.cells.items.properties.outputs.items.properties.metadata]\noutputs.items.properties.metadata.\"$ref\" = \"#display-meta\"\n\n\n```\n</code></pre> <pre><code>schema = strip_fence | tomli.loads | \\\n</code></pre> <p><code>toml description = \"extensible metadata for the notebook schema.\"  [\"$defs\".notebook-meta] \"$anchor\" = \"notebook-meta\" allOf = [     {\"$ref\" = \"kernelspec.json\"} ]  [\"$defs\".code-meta] \"$anchor\" = \"code-meta\" allOf = [     {\"$ref\" = \"#slides\"} ]  [\"$defs\".display-meta] \"$anchor\" = \"display-meta\" allOf = [     {\"$ref\" = \"#images\"},     {\"$ref\" = \"#json\"} ]  [\"$defs\".slides] \"$anchor\" = \"slides\" properties.slides.enum = [\"slide\", \"subslide\", \"fragment\"]  [properties] metadata.\"$ref\" = \"#notebook-meta\"  [properties.cells.items.properties.metadata] \"$ref\" = \"#cell-meta\"  [properties.cells.items.properties.outputs.items.properties.metadata] outputs.items.properties.metadata.\"$ref\" = \"#display-meta\"</code></p> <p>it is shown in json below.</p> <pre><code>    pprint.pprint(schema)\n    JSON(schema, expanded=False)\n</code></pre> <pre>{'$defs': {'code-meta': {'$anchor': 'code-meta',\n                         'allOf': [{'$ref': '#slides'}]},\n           'display-meta': {'$anchor': 'display-meta',\n                            'allOf': [{'$ref': '#images'}, {'$ref': '#json'}]},\n           'notebook-meta': {'$anchor': 'notebook-meta',\n                             'allOf': [{'$ref': 'kernelspec.json'}]},\n           'slides': {'$anchor': 'slides',\n                      'properties': {'slides': {'enum': ['slide',\n                                                         'subslide',\n                                                         'fragment']}}}},\n 'description': 'extensible metadata for the notebook schema.',\n 'properties': {'cells': {'items': {'properties': {'metadata': {'$ref': '#cell-meta'},\n                                                   'outputs': {'items': {'properties': {'metadata': {'outputs': {'items': {'properties': {'metadata': {'$ref': '#display-meta'}}}}}}}}}}},\n                'metadata': {'$ref': '#notebook-meta'}}}\n</pre> <pre>&lt;IPython.core.display.JSON object&gt;</pre> <pre><code>pprint.pprint(schema)\nJSON(schema, expanded=False)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"xxiii/2023-01-12-giscus-comments.html","title":"adding giscus comments to this blog","text":"<p>i've wanted comments for a bit. i didn't realize what a can of worms this decision was. during the day i implemented:</p> <ul> <li>disqus after finding that <code>mkdocs-material</code> deprecated it. https://github.com/squidfunk/mkdocs-material/pull/3329</li> <li>then i tried utterances, but i guess that is old hat.</li> <li>now we have giscus because it is successor of utterances. https://yihui.org/en/2022/12/disqus-to-giscus/</li> </ul>"},{"location":"xxiii/2023-01-12-giscus-comments.html#the-diff","title":"the diff","text":"<p>the new comment system was added by overriding the <code>commments.html</code> partial.</p> <pre><code>    if I := \"__file__\" not in locals():\n        !cd ../.. &amp;&amp; git log --name-only --pretty=oneline 8f808b9208e8226b68a243882b5738258d1a6c72..c184b6d10b3405b2b0e227b21dc37c5285800214\n</code></pre>"},{"location":"xxiii/2023-01-12-giscus-comments.html#the-commentshtml-file","title":"the <code>comments.html</code> file","text":"<p>the snippet in generated by the giscus app. everything needs to be filled out!</p> <pre><code>    if I:\n        import pathlib, IPython\n        display(IPython.display.Code(pathlib.Path(\"../../overrides/partials/comments.html\").read_text(), language=\"html\"))\n</code></pre>"},{"location":"xxiii/2023-01-12-tree-sitter.html","title":"getting start with tree sitter","text":""},{"location":"xxiii/2023-01-12-tree-sitter.html#installing-tree-sitter-for-python","title":"installing tree sitter for python","text":"<pre><code>    def task_setup_tree_sitter():\n        import tree_sitter, pathlib, shutil\n        target = pathlib.Path(\"vendor/tree-sitter-python/.git/HEAD\")\n        yield dict(\n            name=\"clone\",\n            actions=[\n                \"git clone https://github.com/tree-sitter/tree-sitter-python vendor/tree-sitter-python --depth 1\"\n            ], targets=[target], uptodate=[target.exists], clean=[\"rm -rf vendor\"]\n        )\n        yield dict(\n            name=\"compile\",\n            actions=[(tree_sitter.Language.build_library, ('build/my-languages.so', ['vendor/tree-sitter-python']))],\n            file_dep=[target], targets=[\"build/my-languages.so\"], clean=[\"rm build/my-languages.so\"]\n        )\n</code></pre> <pre><code>    if I := __name__ == \"__main__\":\n        %reload_ext doit\n        %doit setup_tree_sitter\n</code></pre> <pre>-- setup_tree_sitter:clone\n-- setup_tree_sitter:compile\n</pre>"},{"location":"xxiii/2023-01-12-tree-sitter.html#loading-a-bunch-of-python-code","title":"loading a bunch of python code","text":"<p>we have some nice dataframes in a prior post that we'll use for demonstration</p> <pre><code>    with __import__(\"importnb\").Notebook(): from tonyfast.xxiii.__duckdb_search import *\n</code></pre> <pre><code>    if I := \"__file__\" not in locals():\n        cells = get_cells_frame(\"..\")\n        cells.source = cells.source.apply(\"\".join)\n</code></pre> <p>some of the cells might have <code>pidgy</code> syntax so lets sort that otu.</p> <pre><code>    if I:\n        import midgy\n        cells = cells.source.str.contains(\"%(re)?load_ext\\s+(pidgy)\").groupby(\"file\").any().rename(\"pidgy\").pipe(cells.join)\n        cells.loc[cells[cells.pidgy].index, \"source\"] = cells[cells.pidgy].source.apply(midgy.Python().render)\n</code></pre> <pre>/tmp/ipykernel_994317/2050936253.py:3: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n  cells = cells.source.str.contains(\"%(re)?load_ext\\s+(pidgy)\").groupby(\"file\").any().rename(\"pidgy\").pipe(cells.join)\n</pre>"},{"location":"xxiii/2023-01-12-tree-sitter.html#tree-sitting-parser","title":"tree sitting parser","text":"<pre><code>    if I:\n        import tree_sitter\n        parser = tree_sitter.Parser()\n        parser.set_language(language := tree_sitter.Language(\"build/my-languages.so\", \"python\"))\n        display(parser)\n</code></pre> <pre>&lt;tree_sitter.Parser at 0x7f5d2b29cc70&gt;</pre>"},{"location":"xxiii/2023-01-12-tree-sitter.html#tree-sitting-parsed","title":"tree sitting parsed","text":"<pre><code>    if I:\n        sitter = cells.source.apply(compose_left(str.encode, parser.parse))\n        sexp = sitter.apply(compose_left(operator.attrgetter(\"root_node\"), operator.methodcaller(\"sexp\")))\n        display(sexp.to_frame(\"s-expression\"))\n</code></pre> s-expression file cell_ct ../regexs.ipynb 0 (module (comment)) 1 (module (import_statement name: (dotted_name (... 2 (module (comment) (expression_statement (compa... 3 (module (expression_statement (assignment left... 4 (module) ... ... ... ../xxii/2022-12-23-mkdocs-plugin.ipynb 8 (module (ERROR (identifier) (identifier) (stri... 9 (module (expression_statement (augmented_assig... ../xxiii/vendor/tree-sitter-python/README.md 0 (module (expression_statement (binary_operator... ../xxiii/vendor/tree-sitter-python/bindings/rust/README.md 0 (module (comment) (ERROR (identifier) (identif... ../README.md 0 (module (ERROR (UNEXPECTED '-')) (expression_s... <p>866 rows \u00d7 1 columns</p>"},{"location":"xxiii/2023-01-14-links-in-markdown-tokens.html","title":"where do all the good links go?","text":"<p>extractling links and definitions from markdown using <code>markdown_it</code> tokens</p> <pre><code>    def get_exporter(key=\"mkdocs\", **kw):\n        with __import__(\"importnb\").Notebook():\n            from tonyfast.xxii.__markdownish_notebook import template, HEAD, replace_attachments, PidgyExporter\n        kw.setdefault(\"template_file\", key)\n        exporter = PidgyExporter(**kw)\n        exporter.environment.filters.setdefault(\"attachment\", replace_attachments)\n        from jinja2 import DictLoader\n        for loader in exporter.environment.loader.loaders:\n            if isinstance(loader, DictLoader):\n                loader.mapping[key] = template\n                loader.mapping[\"HEAD\"] = HEAD\n                break\n        return exporter\n</code></pre> <pre><code>    with __import__(\"importnb\").Notebook():\n        from tonyfast.xxiii.__duckdb_search import *\n        from tonyfast.xxii.__markdownish_notebook import PidgyExporter, template   \n\n    from midgy import Python\n    import nbformat\n    from markdown_it.tree import SyntaxTreeNode\n</code></pre> <pre><code>    @dataclasses.dataclass\n    class Finder:\n        dir: str = \"..\"\n        include: str = \"*.ipynb\\n*.md\"\n        exclude: str = \".ipynb_checkpoints\"\n\n        def get_files_stats(self, path):\n            stat = path.stat()\n            return dict(path=path, suffix=path.suffix, created_at=stat.st_ctime, modified_at=stat.st_mtime, size=stat.st_size)\n\n        def get_files(self) -&gt; list[dict]:\n            return list(map(self.get_files_stats, iter_files(self.dir, self.include, self.exclude)))\n\n        def __iter__(self):\n            yield from self.get_files()\n\n        def to_frame(self, updated_from=None):\n            df = pandas.DataFrame(self).set_index(\"path\")\n            if updated_from is not None:\n                return df[df.modified_at.ne(updated_from.modified_at)]\n            return df\n\n        def to_dask(self):\n            from dask.dataframe import from_pandas\n            return from_pandas(df := self.to_frame(), npartitions=len(df))\n</code></pre> <pre><code>    order = dict([(\"cells\", \"O\"), (\"metadata\", \"O\"), (\"nbformat\", int), (\"nbformat_minor\", int)])\n</code></pre> <pre><code>    (\n        ddf := Finder().to_dask()\n    )\n    ddf = ddf.assign(loader=ddf.suffix.apply({\".md\": get_markdown_file, \".ipynb\": nbformat.v4.reads}.get, meta=(\"loader\", \"O\")))\n    ddf = ddf.assign(\n        data=ddf.apply(lambda s: s.loader(s.name.read_text()), axis=1, meta=(\"data\", \"O\"))\n    )\n    ddf = ddf.assign(md = ddf.data.apply(\n        compose_left(get_exporter().from_notebook_node, first), meta=(\"md\", \"O\")))\n    ddf = ddf.assign(tokens=ddf.md.apply(Python().parse, meta=(\"tokens\", \"O\")))\n    ddf\n</code></pre> Dask DataFrame Structure: suffix created_at modified_at size loader data md tokens npartitions=50 ../xxii/2022-11-12-async-import.ipynb object float64 float64 int64 object object object object ../xxii/2022-11-12-pluggy-experiments.ipynb ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ../xxiii/vendor/tree-sitter-python/bindings/rust/README.md ... ... ... ... ... ... ... ... ../xxiii/vendor/tree-sitter-python/bindings/rust/README.md ... ... ... ... ... ... ... ... Dask Name: assign, 12 graph layers"},{"location":"xxiii/2023-01-14-links-in-markdown-tokens.html#how-many-tokens-are-there","title":"how many tokens are there?","text":"<pre><code>    s = ddf.tokens.apply(compose_left(\n        SyntaxTreeNode, operator.methodcaller(\"walk\"), list\n    ), meta=(\"token\", \"O\")).explode()\n    s.apply(operator.attrgetter(\"type\"), meta=(\"type\", \"O\")).value_counts().compute()\n</code></pre> <pre>text                  4663\nhtml_inline           3739\ninline                1023\nparagraph              768\nsoftbreak              615\ncode_inline            574\nfence                  353\nhtml_block             310\nheading                242\ncode_block             204\nlist_item              186\nlink                   101\nbullet_list             61\ndefinition              50\nroot                    50\nstrong                  41\nem                      16\nblockquote              13\ntd                       9\nordered_list             8\nimage                    7\ntr                       4\nth                       3\ndd                       2\nfootnote_reference       1\nfootnote_ref             1\ndt                       1\ntable                    1\ntbody                    1\ndl                       1\nthead                    1\nName: type, dtype: int64</pre>"},{"location":"xxiii/2023-01-14-links-in-markdown-tokens.html#all-the-links","title":"all the links","text":"<pre><code>    links = s[\n        s.apply(compose_left(operator.attrgetter(\"type\"), \"link image definition\".split().__contains__), meta=(\"link\", bool))\n    ].compute()\n</code></pre> <pre><code>    links.apply(compose_left(operator.attrgetter(\"attrs\", \"meta\"), merge, pandas.Series))\n</code></pre> href title id url label src alt path ../xxii/2022-11-12-async-import.ipynb https://gist.github.com/Rich-Harris/0b6f317657... NaN NaN NaN NaN NaN NaN ../xxii/2022-11-12-async-import.ipynb https://docs.python.org/3/library/ast.html#ast... NaN NaN NaN NaN NaN NaN ../xxii/2022-11-12-pluggy-experiments.ipynb https://pluggy.readthedocs.io/ NaN NaN NaN NaN NaN NaN ../xxii/2022-11-17-assignment-expression-display.ipynb https://peps.python.org/pep-0572/ NaN NaN NaN NaN NaN NaN ../xxii/2022-11-23-better-dask-shape.ipynb oct/2022-10-05-dask-search.ipynb NaN NaN NaN NaN NaN NaN ... ... ... ... ... ... ... ... ../xxiii/vendor/tree-sitter-python/bindings/rust/README.md NaN LANGUAGE FUNC https://docs.rs/tree-sitter-python/*/tree_sitt... language func NaN NaN ../xxiii/vendor/tree-sitter-python/bindings/rust/README.md NaN PARSER https://docs.rs/tree-sitter/*/tree_sitter/stru... Parser NaN NaN ../xxiii/vendor/tree-sitter-python/bindings/rust/README.md NaN TREE-SITTER https://tree-sitter.github.io/ tree-sitter NaN NaN ../xxiii/vendor/tree-sitter-python/bindings/rust/README.md NaN TREE-SITTER CRATE https://crates.io/crates/tree-sitter tree-sitter crate NaN NaN ../xxiii/vendor/tree-sitter-python/bindings/rust/README.md NaN TREE-SITTER DISCUSSIONS https://github.com/tree-sitter/tree-sitter/dis... tree-sitter discussions NaN NaN <p>159 rows \u00d7 7 columns</p>"},{"location":"xxiii/2023-01-16-inspector-hack.html","title":"customizing the <code>IPython</code> contextual help","text":"<p>an original feature of <code>pidgy</code> is the use <code>jupyter</code>s contextual help to provide wysiwyg experience.</p> <p>as author's write <code>pidgy</code> they reveal a preview of the output and explore variables in the workspace.</p> <p></p> <ul> <li>when source is found show help</li> <li>when inspection is found show the found results</li> <li>when is not found show the markdown preview</li> </ul> <p>the inspector uses <code>jupyter</code>s rich display system. we can send html and markdown to the contextual help.</p> <p>we create an ipython extension that modifies the <code>IPython</code> contextual help using rich displays. we are going to create a wsyiwyg for </p> <pre><code>    def load_ipython_extension(shell):\n        __import__(\"nest_asyncio\").apply() # just in case\n        shell.enable_html_pager = True\n        shell.kernel.do_inspect = types.MethodType(do_inspect, shell)\n</code></pre> <pre><code>    %reload_ext pidgy\n    import pandas\n</code></pre>        %reload_ext pidgy     import pandas   <p>for any of this to work need to enable the html pager <code>shell.enable_html_pager</code></p> <pre><code>    shell.enable_html_pager = True\n</code></pre> <pre><code>shell.enable_html_pager = True\n</code></pre> <p><code>do_inspect</code> will be our new contextual help completer. it provides completion when:</p> <ul> <li>there is no content to inspect</li> <li>there was no result found</li> <li>you found the bangs</li> </ul> <pre><code>    def do_inspect(self, cell, cursor_pos, detail_level=1, omit_sections=(), *, cache={}):\n        post = post_bangs(cell, get_bangs(cell, cursor_pos))\n        if post:\n            data = _do_inspect(\"\", 0, detail_level=0, omit_sections=())\n            data[\"data\"]= post\n            data[\"found\"] = True\n        else:\n            data = _do_inspect(cell, cursor_pos, detail_level=0, omit_sections=())\n            if not data[\"found\"]:\n                data.update(inspect_weave(cell, cursor_pos))\n        return data    \n</code></pre> <pre><code>def do_inspect(self, cell, cursor_pos, detail_level=1, omit_sections=(), *, cache={}):\n    post = post_bangs(cell, get_bangs(cell, cursor_pos))\n    if post:\n        data = _do_inspect(\"\", 0, detail_level=0, omit_sections=())\n        data[\"data\"]= post\n        data[\"found\"] = True\n    else:\n        data = _do_inspect(cell, cursor_pos, detail_level=0, omit_sections=())\n        if not data[\"found\"]:\n            data.update(inspect_weave(cell, cursor_pos))\n    return data\n</code></pre> <pre><code>    def inspect_weave(code, cursor_pos, cache={}):\n        data = dict(found=True)\n        if not code.strip(): \n            data[\"data\"] = {\"text/markdown\": help}\n        else:\n            tokens = cache.get(code)\n            line, offset= lineno_at_cursor(code, cursor_pos)\n            if tokens is None:               \n                cache.clear()\n                tokens = cache[code] = shell.tangle.parse(code)\n            where = get_md_pointer(tokens, line, offset)\n            data[\"data\"] = {\"text/markdown\": F\"\"\"`{\"/\".join(where)}`\\n\\n{code}\"\"\"}\n        return data\n</code></pre> <pre><code>def inspect_weave(code, cursor_pos, cache={}):\n    data = dict(found=True)\n    if not code.strip(): \n        data[\"data\"] = {\"text/markdown\": help}\n    else:\n        tokens = cache.get(code)\n        line, offset= lineno_at_cursor(code, cursor_pos)\n        if tokens is None:               \n            cache.clear()\n            tokens = cache[code] = shell.tangle.parse(code)\n        where = get_md_pointer(tokens, line, offset)\n        data[\"data\"] = {\"text/markdown\": F\"\"\"`{\"/\".join(where)}`\\n\\n{code}\"\"\"}\n    return data\n</code></pre> <p>this is a hack! we'll hold the original inspect function and monkey patch it.</p> <pre><code>    locals().setdefault(\"_do_inspect\", shell.kernel.do_inspect)\n</code></pre> <pre>&lt;bound method IPythonKernel.do_inspect of &lt;ipykernel.ipkernel.IPythonKernel object at 0x7fd8eb2b0fa0&gt;&gt;</pre> <pre><code>locals().setdefault(\"_do_inspect\", shell.kernel.do_inspect)\n</code></pre> <pre><code>    if I := (\"__file__\" not in locals()): load_ipython_extension(shell)\n</code></pre> <pre><code>if I := (\"__file__\" not in locals()): load_ipython_extension(shell)\n</code></pre>"},{"location":"xxiii/2023-01-16-inspector-hack.html#line-positions-and-tokenization","title":"line positions and tokenization","text":"<p>it seemed important to have line and column numbers that align exactly with the code mirror line numbers and the line/column number in the bottom inspector ribbon. for extra confidence when writing pidgy we include the markdown block token the cursor is within.</p> <pre><code>    def lineno_at_cursor(cell, cursor_pos=0):\n        offset = 0\n        for i, line in enumerate(cell.splitlines(True)):\n            next_offset = offset + len(line)\n            if not line.endswith('\\n'): next_offset += 1\n            if next_offset &gt; cursor_pos:  break\n            offset = next_offset\n        col = cursor_pos-offset\n        return i, col\n\n    def get_md_pointer(tokens, line, offset):\n        where = [F\"L{line+1}:{offset+1}\"]\n        for node in tokens:\n            if node.type == \"root\": continue\n            if node.map:\n                if line &lt; node.map[0]: break\n                elif node.map[0] &lt;= line &lt; node.map[1]: where.append(node.type)\n        return where\n</code></pre> <pre><code>def lineno_at_cursor(cell, cursor_pos=0):\n    offset = 0\n    for i, line in enumerate(cell.splitlines(True)):\n        next_offset = offset + len(line)\n        if not line.endswith('\\n'): next_offset += 1\n        if next_offset &gt; cursor_pos:  break\n        offset = next_offset\n    col = cursor_pos-offset\n    return i, col\n\ndef get_md_pointer(tokens, line, offset):\n    where = [F\"L{line+1}:{offset+1}\"]\n    for node in tokens:\n        if node.type == \"root\": continue\n        if node.map:\n            if line &lt; node.map[0]: break\n            elif node.map[0] &lt;= line &lt; node.map[1]: where.append(node.type)\n    return where\n</code></pre>"},{"location":"xxiii/2023-01-16-inspector-hack.html#the-bangs","title":"the bangs","text":"<p>the bangs give extra interactivity. when inspecting code a group of exclamation <code>!!!</code> points with template the woven source, or with enough emphasism <code>!!!!!!</code> we'll actually run code. consider these easter eggs cause i want them.</p> <pre><code>    def get_bangs(cell, cursor_pos):\n        if cell[cursor_pos-1] == \"!\":\n            l, r = cell[:cursor_pos], cell[cursor_pos:]\n            return len(l) - len(l.rstrip(\"!\")) + len(r) - len(r.strip(\"!\"))\n        return 0\n</code></pre> <pre><code>def get_bangs(cell, cursor_pos):\n    if cell[cursor_pos-1] == \"!\":\n        l, r = cell[:cursor_pos], cell[cursor_pos:]\n        return len(l) - len(l.rstrip(\"!\")) + len(r) - len(r.strip(\"!\"))\n    return 0\n</code></pre> <pre><code>    def post_bangs(cell, bangs):\n        if bangs&gt;=6:\n            result = shell.run_cell(cell, store_history=False, silent=True)\n            error = result.error_before_exec or result.error_in_exec\n            if error: return {\"text/markdown\": F\"\"\"```pycon\\n{\"\".join(\ntraceback.format_exception(type(error), error, error.__traceback__)\n)}\\n```\"\"\"}\n            else: shell.weave.update()\n        if bangs &gt;=3:\n            result = shell.environment.from_string(cell, None, pidgy.environment.IPythonTemplate)\n            return {\"text/markdown\": result.render()}\n</code></pre> <pre><code>def post_bangs(cell, bangs):\n    if bangs&gt;=6:\n        result = shell.run_cell(cell, store_history=False, silent=True)\n        error = result.error_before_exec or result.error_in_exec\n        if error: return {\"text/markdown\": F\"\"\"```pycon\\n{\"\".join(\n                traceback.format_exception(type(error), error, error.__traceback__)\n            )}\\n```\"\"\"}\n        else: shell.weave.update()\n    if bangs &gt;=3:\n        result = shell.environment.from_string(cell, None, pidgy.environment.IPythonTemplate)\n        return {\"text/markdown\": result.render()}\n</code></pre>"},{"location":"xxiii/2023-01-16-inspector-hack.html#the-opportunity-in-the-misses","title":"the opportunity in the misses","text":"<p>the contextual help renders on keypress when a result is found.</p> <pre><code>{% set help_hits = inspection.found.mean().round(2) * 100 %}\n\nwhen we use the normal inspection. we find that there is a lot of time where the contextual help is not found.\nfor example, when we process all the code inputs in this document the inspector finds information {{help_hits}}% of the time,\nmeaning {{100-help_hits}}% opportunity!!!\n\n    def measure(x): yield from (shell.kernel.do_inspect(x, i) for i in range(len(x)))\n    shell.kernel.do_inspect = _do_inspect\n    inspection = pandas.Series(In).apply(measure).apply(list).explode().dropna().apply(pandas.Series)\n    load_ipython_extension(shell)\n</code></pre> <p>when we use the normal inspection. we find that there is a lot of time where the contextual help is not found. for example, when we process all the code inputs in this document the inspector finds information 36.0% of the time, meaning 64.0% opportunity!!</p> <pre><code>def measure(x): yield from (shell.kernel.do_inspect(x, i) for i in range(len(x)))\nshell.kernel.do_inspect = _do_inspect\ninspection = pandas.Series(In).apply(measure).apply(list).explode().dropna().apply(pandas.Series)\nload_ipython_extension(shell)\n</code></pre> <pre><code>a use is the blank screen is to provide a help interface for people to learn our new tool.\nwith links to good docs.\n\n    help =\\\n`pidgy` is markdown/python literate programming language.\n\n* indented code and fenced code are executed\n\n## documentation \n\n* jinja2 documentation\n* markdown documentation\n* python documentation\n</code></pre> <p>a use is the blank screen is to provide a help interface for people to learn our new tool. with links to good docs.</p> <pre><code>help =\\\n</code></pre> <p><code>pidgy</code> is markdown/python literate programming language.</p> <ul> <li>indented code and fenced code are executed</li> </ul>"},{"location":"xxiii/2023-01-16-inspector-hack.html#documentation","title":"documentation","text":"<ul> <li>jinja2 documentation</li> <li>markdown documentation</li> <li>python documentation</li> </ul>"},{"location":"xxiii/2023-01-16-inspector-hack.html#including-the-current-markdown-token","title":"including the current markdown token","text":"<p>sometimes when writing <code>pidgy</code> its possible to lose your you position. we include the line number and token the cursor is in</p> <p>an accidental outcome is this hack adds contextual help to markdown cells. its good.</p>"},{"location":"xxiii/2023-01-18-voila-pidgy-integration.html","title":"cleaner integration of <code>pidgy</code> &amp; <code>voila</code>","text":"<p><code>pidgy</code> works great with widgets, so it should rock with <code>voila</code>. the default display for pidgy does NOT use widgets by default, the author would have to opt into widgets in development. however, if we detect that <code>voila</code> is driving our notebook then we should use the <code>pidgy.displays.IPyWidgetsHtml</code> display.</p> <p></p> <ul> <li>activate <code>pidgy</code></li> </ul> <pre><code>    %reload_ext pidgy\n</code></pre> <pre><code>%reload_ext pidgy\n</code></pre> <pre><code>## the cookies demo\n\nthe cookies demo is inspired by the original [tanglejs](http://worrydream.com/Tangle/).\n</code></pre>"},{"location":"xxiii/2023-01-18-voila-pidgy-integration.html#the-cookies-demo","title":"the cookies demo","text":"<p>the cookies demo is inspired by the original tanglejs.</p> <ul> <li>run the demo</li> </ul> <pre><code> ---\n\nwhen you eat {{cookies.value}} cookies you consume {{cookies.value * 75}} calories.\n\n\n&lt;div hidden&gt;\n\n        display(cookies:=IntSlider(3, description=\"cookies\"))\n&lt;/div&gt;\n\n ---\n</code></pre> <p>when you eat 3 cookies you consume 225 calories.</p>           display(cookies:=IntSlider(3, description=\"cookies\"))  <pre><code>## state information\n\nthe display class in this verison is {{shell.weave.template_cls}}\nbecause voila is{% if not pidgy.weave.is_voila() %} not{% endif %} running.\n</code></pre>"},{"location":"xxiii/2023-01-18-voila-pidgy-integration.html#state-information","title":"state information","text":"<p>the display class in this verison is  because voila is not running."},{"location":"xxiii/2023-01-24-lite-build.html","title":"including development builds in jupyter lite","text":"<p>this work augments our existing lite build by vendoring things that i'm actively working on for demonstration.</p> <p>https://jupyterlite.readthedocs.io/en/latest/howto/python/wheels.html#adding-pyolite-wheels</p> <pre><code>    if __name__ == \"__main__\":\n        if \"INIT\" not in locals():\n            %pushd ../..\n            INIT = True\n\n        with __import__(\"importnb\").imports(\"ipynb\"):\n            import tonyfast.xxii.__lite_build as prior\n\n        %reload_ext doit\n        %reload_ext pidgy.extras\n\n    from doit import task_params\n    from pathlib import Path\n    import os, doit\n\n    TARGET = Path(\"tonyfast\")\n    SITE = Path(\"site\", \"run\")\n    PYPI = SITE / \"pypi\"\n</code></pre> <pre>/home/tbone/Documents/tonyfast\n</pre> <pre><code>    @task_params([dict(name=\"pypi\", type=list, default=[\n        \"https://github.com/deathbeds/midgy\",\n        \"https://github.com/deathbeds/pidgy\",\n        \"https://github.com/deathbeds/importnb\"\n    ])])\n    def task_lite(pypi):\n        with __import__(\"importnb\").imports(\"ipynb\"):\n            from tonyfast.xxii.__lite_build import set_files_imports\n\n        env = os.environ.copy()\n        env[\"SETUPTOOLS_SCM_PRETEND_VERSION\"] = \"6.6.6\"\n        hatch = list(filter(lambda x: x.startswith(\"HATCH\"), env))\n        for x in hatch:\n            env.pop(x)\n        wheels = []\n        for repo in pypi:\n            org, _, name = repo.rpartition(\"/\")\n            target = TARGET / name\n            yield dict(\n                name=F\"clone:{repo}\",\n                actions=[F\"git clone --depth 1 {repo} {target}\"],\n                targets=[HEAD := (target / \".git\" / \"HEAD\")],\n                clean=[F\"rm -rf {target}\"],\n                uptodate=[target.exists()]\n            )\n            pypi = Path(\"pypi\").absolute() # this directory needs to relative to build directory\n            wheel = pypi / F\"{name}-6.6.6-py3-none-any.whl\"\n            wheels.append(wheel)\n            yield dict(\n                name=F\"build:{name}\",\n                actions=[\n                    (doit.tools.create_folder, [pypi]),\n                    doit.tools.CmdAction(F\"python -m build --wheel --outdir {pypi}\", cwd=target, env=env)\n                ],\n                clean=True,\n                targets=[wheel],\n                uptodate=[False]\n            )\n        yield dict(\n            name=\"build\",\n            file_dep=wheels,\n            actions=[\n                \"rm -rf tonyfast/pidgy/lite tonyfast/pidgy/.binder\",\n                \"pip install --pre --upgrade notebook\", # development version of notebook for v7\n                \"jupyter lite build --apps repl --apps notebook --apps lab --contents tonyfast --output-dir site/run\",\n                # voici is activated here when it works\n                (set_files_imports, (Path(\"site/run/files\"),))\n            ],\n            targets=[\"site/run/index.html\"],\n            clean=[\"rm -rf site/run\"]\n        )\n</code></pre>"},{"location":"xxiii/2023-01-24-system-dependency-graphs.html","title":"extracting a dependency graph from <code>importlib_metadata</code>","text":"<pre><code>    %reload_ext pidgy\n    import importlib_metadata, pandas, networkx\n    from toolz.curried import *    \n</code></pre>        %reload_ext pidgy     import importlib_metadata, pandas, networkx     from toolz.curried import *       <pre><code>    @functools.lru_cache # cache this because the result will always be the same and parsing can be costly\n    def get_tidy_dist() -&gt; pandas.DataFrame:\n`get_tidy_dist` creates a tidy dataframe of the required distributions in this environment\n\n        return get_dists().loc[\"Requires-Dist\"].apply(\n            compose_left(pkg_resources.parse_requirements, first, vars, pandas.Series)\n        )\n</code></pre> <pre><code>@functools.lru_cache # cache this because the result will always be the same and parsing can be costly\ndef get_tidy_dist() -&gt; pandas.DataFrame:\n</code></pre> <p><code>get_tidy_dist</code> creates a tidy dataframe of the required distributions in this environment</p> <pre><code>    return get_dists().loc[\"Requires-Dist\"].apply(\n        compose_left(pkg_resources.parse_requirements, first, vars, pandas.Series)\n    )\n</code></pre> <pre><code>    def get_dists():\n`get_dists` iterates through the `importlib_metadata.distributions` extracting the known metadata.\n\n        return pandas.Series(\n            dict((x.name, x.metadata._headers) for x in importlib_metadata.distributions())\n        ).rename_axis(index=[\"project\"]).explode().apply(\n            pandas.Series, index=[\"key\", \"value\"]\n        ).set_index(\"key\", append=True).reorder_levels((1, 0), 0)[\"value\"]\n</code></pre> <pre><code>def get_dists():\n</code></pre> <p><code>get_dists</code> iterates through the <code>importlib_metadata.distributions</code> extracting the known metadata.</p> <pre><code>    return pandas.Series(\n        dict((x.name, x.metadata._headers) for x in importlib_metadata.distributions())\n    ).rename_axis(index=[\"project\"]).explode().apply(\n        pandas.Series, index=[\"key\", \"value\"]\n    ).set_index(\"key\", append=True).reorder_levels((1, 0), 0)[\"value\"]\n</code></pre>"},{"location":"xxiii/2023-01-24-system-dependency-graphs.html#applying-the-functionss","title":"applying the functionss","text":"<p>generate the <code>pandas.DataFrame</code> of the dependency graph and metadata</p> <pre><code>    (df := get_tidy_dist()).head().style.set_caption(\"the metadata associated with my known python dependecies\")\n</code></pre> the metadata associated with my known python dependecies name url extras specifier marker unsafe_name project_name key specs hashCmp _Requirement__hash project retrolab jupyterlab None () ~=3.3.0 None jupyterlab jupyterlab jupyterlab [('~=', '3.3.0')] ('jupyterlab', None, , frozenset(), None) -7176474069730581504 retrolab jupyterlab-server None () ~=2.3 None jupyterlab-server jupyterlab-server jupyterlab-server [('~=', '2.3')] ('jupyterlab-server', None, , frozenset(), None) 4027949953799964160 retrolab jupyter-server None () ~=1.4 None jupyter-server jupyter-server jupyter-server [('~=', '1.4')] ('jupyter-server', None, , frozenset(), None) -3631246956991118336 retrolab nbclassic None () ~=0.2 None nbclassic nbclassic nbclassic [('~=', '0.2')] ('nbclassic', None, , frozenset(), None) 6600834436348797952 retrolab tornado None () &gt;=6.1.0 None tornado tornado tornado [('&gt;=', '6.1.0')] ('tornado', None, =6.1.0')&gt;, frozenset(), None) 8619901927024904192 <pre><code>(df := get_tidy_dist()).head().style.set_caption(\"the metadata associated with my known python dependecies\")\n</code></pre> <p>cast the tidy data as a <code>networkx</code> graph</p> <pre><code>    G =df.reset_index().pipe(networkx.from_pandas_edgelist, source=\"project\", target=\"name\")\n</code></pre> <pre><code>G =df.reset_index().pipe(networkx.from_pandas_edgelist, source=\"project\", target=\"name\")\n</code></pre> <pre><code>    df.name.value_counts().to_frame(\"count\").head(20).T.style.set_caption(\"a table counting the frequency of specific distributions.\")\n</code></pre> a table counting the frequency of specific distributions. pytest sphinx pytest-cov matplotlib flake8 numpy coverage requests pre-commit typing-extensions pandas importlib-metadata ipython six packaging black pyyaml jinja2 click ipywidgets count 147 78 70 55 51 48 45 41 36 34 33 32 31 30 30 29 28 27 25 25 <pre><code>df.name.value_counts().to_frame(\"count\").head(20).T.style.set_caption(\"a table counting the frequency of specific distributions.\")\n</code></pre> <p>draw the graph n matplotlib</p> <pre><code>    matplotlib.pyplot.gcf().set_size_inches((20, 20))\n    networkx.draw_networkx(G)\n</code></pre> <pre><code>matplotlib.pyplot.gcf().set_size_inches((20, 20))\nnetworkx.draw_networkx(G)\n</code></pre>"},{"location":"xxiii/2023-01-24-whoosh-search.html","title":"use <code>whoosh</code> to search cells/articles on disk","text":"<p>https://whoosh.readthedocs.io/en/latest/</p> <pre><code>!pip install  whoosh\n</code></pre> <pre><code>    import whoosh.fields, whoosh.index, whoosh.qparser, whoosh.writing\n    import pathlib, shutil\n</code></pre> <pre><code>    from tonyfast import nbframe\n    __import__(\"nest_asyncio\").apply()\n    self = nbframe.Documents(nbframe.Finder(dir=\"..\")).load()    \n</code></pre>"},{"location":"xxiii/2023-01-24-whoosh-search.html#initialize-the-search-index","title":"initialize the search index","text":"<pre><code>    INDEX = pathlib.Path(\"search_index\")\n    INDEX.mkdir(exist_ok=True)\n\n    whoosh.index.create_in(INDEX, schema := whoosh.fields.Schema(source=whoosh.fields.TEXT, path=whoosh.fields.ID(stored=True)))\n    index=whoosh.index.open_dir(INDEX)\n</code></pre> <pre><code>    from tonyfast import nbframe\n    self = nbframe.Documents(nbframe.Finder(dir=\"..\")).load()    \n</code></pre> <p><code>self.articles</code> is a dataframe containing notebooks and files cast to the notebook schema. the dask and dataframes are shown below.</p> <pre><code>    display(self.articles, self.articles.head(10, 5))\n</code></pre> Dask DataFrame Structure: cell_type execution_count id metadata outputs source cell_ct attachments npartitions=85 ../2023-01-19-.ipynb object int64 object object object object int64 object ../2023-01-19-pidgy-afforndances.ipynb ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ../xxiii/vendor/tree-sitter-python/test/highlight/pattern_matching.py ... ... ... ... ... ... ... ... ../xxiii/what.md ... ... ... ... ... ... ... ... Dask Name: apply, 1 graph layer cell_type execution_count id metadata outputs source cell_ct attachments path ../2023-01-19-.ipynb code None ad5f3630-daac-4b8b-95b0-22f27ea47af2 {} [] 0 None ../2023-01-19-pidgy-afforndances.ipynb code 1.0 409a2348-866f-4127-a25b-7fc0adcac5fc {} [{'ename': 'SyntaxError', 'evalue': 'invalid s... when i program in `pidgy`\\n\\n* `sys.modules` a... 0 None ../2023-01-19-pidgy-afforndances.ipynb code 1.0 45c4aa5d-e53d-4a02-82b2-8f872906ceba {} [{'data': {'text/markdown': '    %reload_ext p... %reload_ext pidgy\\n    from toolz.curried ... 1 None ../2023-01-19-pidgy-afforndances.ipynb markdown NaN 87b3dd7c-3b9a-406d-b39c-547c69a938f7 {} None &lt;iframe src=\"http://127.0.0.1:8787/status\"... 2 None ../2023-01-19-pidgy-afforndances.ipynb markdown NaN d3d234cd-7d46-44b2-b26f-a80e524764ec {} None # start the contents finder 3 None ../2023-01-19-pidgy-afforndances.ipynb code 1.0 3563e7c1-6f4f-4774-84c9-f2db766238cb {} [{'data': {'text/html': '&lt;div&gt;     &lt;div style=... \\n    %reload_ext pidgy\\n    import nbfram... 4 None ../2023-01-19-pidgy-afforndances.ipynb code 11.0 4b4f8e4c-d192-4dd8-818e-b728d4b6673e {} [{'data': {'text/html': '&lt;div&gt; &lt;style scoped&gt; ... result 5 None ../2023-01-19-pidgy-afforndances.ipynb code 21.0 1fba636a-14c1-4011-8af1-5d54452f7e36 {} [{'data': {'text/markdown': ' pretty neat that... {{asyncio.sleep(1) or \"\"}} pretty neat that we... 6 None ../2023-01-19-pidgy-afforndances.ipynb code 18.0 efdfc300-da33-40d5-b1ea-8636e8e1a001 {} [{'data': {'text/markdown': '    docs= 2', 'te... docs= 2 7 None ../2023-01-19-pidgy-afforndances.ipynb markdown NaN bad77dd2-294b-4f6a-a520-4ff25be27d41 {} None load and persist the data 8 None <pre><code>    def get_article_path(s): return str(s.name) + \"#/cells/\" + str(s.cell_ct)\n    self.articles[\"path\"] = self.articles.apply(get_article_path, meta=(\"path\", \"O\"), axis=1)\n</code></pre> <pre><code>    def write_documents(df):\n        with whoosh.writing.AsyncWriter(index) as w:\n            for _, x in df.iterrows(): w.add_document(**x)\n    self.articles[[\"source\", \"path\"]].applymap(\"\".join).groupby(self.articles.index).apply(write_documents, meta=(\"none\", int)).compute()\n</code></pre> <pre>Series([], Name: none, dtype: int64)</pre>"},{"location":"xxiii/2023-01-24-whoosh-search.html#querying-the-documents","title":"querying the documents","text":"<pre><code>    query = whoosh.qparser.QueryParser(\"source\", schema)\n</code></pre> <pre><code>    with index.searcher() as search:\n        print(search.search(query.parse(\"literate computing\")))\n</code></pre> <pre>&lt;Top 0 Results for And([Term('source', 'literate'), Term('source', 'computing')]) runtime=9.207999937643763e-05&gt;\n</pre>"},{"location":"xxiii/2023-02-19-semantic.html","title":"semantic notebook structure","text":"<p>sketches of semantic notebook structures considering cells as form inputs.</p> <pre><code>    %reload_ext pidgy\n</code></pre>        %reload_ext pidgy   <pre><code>    def jade(body):\n        lines = body.splitlines(True)\n        if body.startswith(\"```\"):\n            lines.pop(0)\n        if body.rstrip().endswith(\"```\"):\n            lines.pop()\n        return __import__(\"pyjade\").process(\"\".join(lines))\n</code></pre> <pre><code>def jade(body):\n    lines = body.splitlines(True)\n    if body.startswith(\"```\"):\n        lines.pop(0)\n    if body.rstrip().endswith(\"```\"):\n        lines.pop()\n    return __import__(\"pyjade\").process(\"\".join(lines))\n</code></pre> <pre><code>    shape =\\\n```jade\nmain\n    head\n    section(role=\"feed\")\n        article(aria-posinset=1, aria-setsize=12)\n            form(id, aria)\n                fieldset(name=cell)\n                    legend input\n                    label(for=\"cell-input\")\n                    div.source(id=\"cell-input\", contenteditable=\"false\", role=\"textbox\").\n                        some code that we will \n                        compute with\n                    fieldset(name=\"commands\", form)\n                        legend commands\n                        button \u23ea\n                        button \u23f9\ufe0f\n                        button \u25b6\ufe0f\n                        button \u23e9\n                    fieldset(name=\"metadata\", form)\n                        legend information\n                        label in\n                        input(type=\"number\", disabled=\"\", value=2)\n                        label start\n                        input(type=\"time\", disabled=\"\", value=\"14:32\")\n                        label stop\n                        input(type=\"time\", disabled=\"\", value=\"14:33\")\n                        fieldset(name=\"tags\")\n                            legend tags\n                            label  slide\n\n                    fieldset(name=\"outputs\", form)\n                        legend outputs\n                        fieldset.stderr\n                            label \u26a0\n                            output.warning \n                                samp warning\n                        fieldset.stderr\n                            label \u2718\n                            output.error\n                                samp error\n                        fieldset.stdout\n                            label \u2611\n                            output.stdout\n                                samp \"hello world\"\n                        fieldset.display-data\n                            fieldset(name=\"metadata\")\n                                label out\n                                input(type=\"number\", disabled=\"\", value=2)\n                            output(markdown=\"true\").\n                                # some markdown \n                                to remember\n```\n\n    ...\n\n{% set html = jade(shape) %}\n```html\n{{html}}\n```\n\n{{html}}\n</code></pre> <pre><code>shape =\\\n</code></pre> <p><code>jade main     head     section(role=\"feed\")         article(aria-posinset=1, aria-setsize=12)             form(id, aria)                 fieldset(name=cell)                     legend input                     label(for=\"cell-input\")                     div.source(id=\"cell-input\", contenteditable=\"false\", role=\"textbox\").                         some code that we will                          compute with                     fieldset(name=\"commands\", form)                         legend commands                         button \u23ea                         button \u23f9\ufe0f                         button \u25b6\ufe0f                         button \u23e9                     fieldset(name=\"metadata\", form)                         legend information                         label in                         input(type=\"number\", disabled=\"\", value=2)                         label start                         input(type=\"time\", disabled=\"\", value=\"14:32\")                         label stop                         input(type=\"time\", disabled=\"\", value=\"14:33\")                         fieldset(name=\"tags\")                             legend tags                             label  slide                      fieldset(name=\"outputs\", form)                         legend outputs                         fieldset.stderr                             label \u26a0                             output.warning                                  samp warning                         fieldset.stderr                             label \u2718                             output.error                                 samp error                         fieldset.stdout                             label \u2611                             output.stdout                                 samp \"hello world\"                         fieldset.display-data                             fieldset(name=\"metadata\")                                 label out                                 input(type=\"number\", disabled=\"\", value=2)                             output(markdown=\"true\").                                 # some markdown                                  to remember</code></p> <pre><code>...\n</code></pre> <pre><code>&lt;main&gt;\n  &lt;head&gt;&lt;/head&gt;\n  &lt;section role=\"feed\"&gt;\n    &lt;article aria-posinset=\"1\" aria-setsize=\"12\"&gt;\n      &lt;form id=\"id\" aria=\"aria\"&gt;\n        &lt;fieldset&gt;\n          &lt;legend&gt;input&lt;/legend&gt;\n          &lt;label for=\"cell-input\"&gt;&lt;/label&gt;\n          &lt;div id=\"cell-input\" contenteditable=\"false\" role=\"textbox\" class=\"source\"&gt;some code that we will \ncompute with\n          &lt;/div&gt;\n          &lt;fieldset name=\"commands\" form=\"form\"&gt;\n            &lt;legend&gt;commands&lt;/legend&gt;\n            &lt;button&gt;\u23ea&lt;/button&gt;\n            &lt;button&gt;\u23f9\ufe0f&lt;/button&gt;\n            &lt;button&gt;\u25b6\ufe0f&lt;/button&gt;\n            &lt;button&gt;\u23e9&lt;/button&gt;\n          &lt;/fieldset&gt;\n          &lt;fieldset name=\"metadata\" form=\"form\"&gt;\n            &lt;legend&gt;information&lt;/legend&gt;\n            &lt;label&gt;in&lt;/label&gt;\n            &lt;input type=\"number\" disabled=\"\" value=\"2\"/&gt;\n            &lt;label&gt;start&lt;/label&gt;\n            &lt;input type=\"time\" disabled=\"\" value=\"14:32\"/&gt;\n            &lt;label&gt;stop&lt;/label&gt;\n            &lt;input type=\"time\" disabled=\"\" value=\"14:33\"/&gt;\n            &lt;fieldset name=\"tags\"&gt;\n              &lt;legend&gt;tags&lt;/legend&gt;\n              &lt;label&gt;slide&lt;/label&gt;\n            &lt;/fieldset&gt;\n          &lt;/fieldset&gt;\n          &lt;fieldset name=\"outputs\" form=\"form\"&gt;\n            &lt;legend&gt;outputs&lt;/legend&gt;\n            &lt;fieldset class=\"stderr\"&gt;\n              &lt;label&gt;\u26a0&lt;/label&gt;\n              &lt;output class=\"warning\"&gt;&lt;samp&gt;warning&lt;/samp&gt;\n              &lt;/output&gt;\n            &lt;/fieldset&gt;\n            &lt;fieldset class=\"stderr\"&gt;\n              &lt;label&gt;\u2718&lt;/label&gt;\n              &lt;output class=\"error\"&gt;&lt;samp&gt;error&lt;/samp&gt;\n              &lt;/output&gt;\n            &lt;/fieldset&gt;\n            &lt;fieldset class=\"stdout\"&gt;\n              &lt;label&gt;\u2611&lt;/label&gt;\n              &lt;output class=\"stdout\"&gt;&lt;samp&gt;\"hello world\"&lt;/samp&gt;\n              &lt;/output&gt;\n            &lt;/fieldset&gt;\n            &lt;fieldset class=\"display-data\"&gt;\n              &lt;fieldset name=\"metadata\"&gt;\n                &lt;label&gt;out&lt;/label&gt;\n                &lt;input type=\"number\" disabled=\"\" value=\"2\"/&gt;\n              &lt;/fieldset&gt;\n              &lt;output markdown=\"true\"&gt;# some markdown \nto remember\n              &lt;/output&gt;\n            &lt;/fieldset&gt;\n          &lt;/fieldset&gt;\n        &lt;/fieldset&gt;\n      &lt;/form&gt;\n    &lt;/article&gt;\n  &lt;/section&gt;\n&lt;/main&gt;\n</code></pre> input some code that we will  compute with            commands \u23ea \u23f9\ufe0f \u25b6\ufe0f \u23e9 information in start stop tags slide outputs \u26a0 warning \u2718 error \u2611 \"hello world\" out # some markdown  to remember"},{"location":"xxiii/2023-02-28-community-demo.html","title":"<code>pidgy</code> literate computing","text":"<p>you've heard of interactive computing, we'll call <code>pidgy</code> hyperactive computing. </p> \ud83c\udfc3run all \ud83d\uddb9document mode \ud83d\udcfdpresentation mode \u229fcollapse all the code \u229eexpand all the code <code>jupyterlab-deck</code> <code>voila</code> \ud83d\udd0dinspector \ud83d\udc6fside-by-side <p>this presentation is written for the february 2023 jupyter community call.2</p> <p>restart and run allor it didn't happen</p> <pre><code>    # my pidgy practices always have me indenting cells.\n    # this habit means code will be rendered as code in markdown.\n    # https://nbviewer.org/github/deathbeds/deathbeds.github.io/blob/master/deathbeds/2018-08-03-A-case-for-indented-code.ipynb\n\n    # this is a presentation about pidgy so we start by loading the extension.\n    # there is a pidgy kernel for the hardcore. \n    # in that case we recommend the hybrid `.md.ipynb` extension.\n\n    if LITE := (__import__(\"sys\").platform == \"emscripten\"): # compatability for jupyterlite\n        %pip install pandas pidgy matplotlib ipywidgets toolz\n\n    # activate pidgy\n    %reload_ext pidgy\n    from toolz.curried import *\n</code></pre> <pre><code># my pidgy practices always have me indenting cells.\n# this habit means code will be rendered as code in markdown.\n# https://nbviewer.org/github/deathbeds/deathbeds.github.io/blob/master/deathbeds/2018-08-03-A-case-for-indented-code.ipynb\n\n# this is a presentation about pidgy so we start by loading the extension.\n# there is a pidgy kernel for the hardcore. \n# in that case we recommend the hybrid `.md.ipynb` extension.\n\nif LITE := (__import__(\"sys\").platform == \"emscripten\"): # compatability for jupyterlite\n    %pip install pandas pidgy matplotlib ipywidgets toolz\n\n# activate pidgy\n%reload_ext pidgy\nfrom toolz.curried import *\n</code></pre>"},{"location":"xxiii/2023-02-28-community-demo.html#the-pidgy-polyglot-metalanguage","title":"the <code>pidgy</code> polyglot metalanguage","text":"<p><code>pidgy</code> is a pidgin of python programming and jinja templates embedded inside markdown. literate programming is that aim to craft documentation and code at the same time. literate computing is when we do this interactively, and weave live computing into the narrative.</p> <pre><code>&lt;figure&gt;\n&lt;figcaption&gt;\n\nthe REPL overlayed with a [literate computing] workflow of tangle and weave.\n\n&lt;/figcaption&gt;\n\n{% set repl %}\n    input[markdown]--tangle\\nread--&gt;IPython\n    IPython--eval/template--&gt;jinja\n    jinja--weave\\nprint--&gt;output[markdown]\n    output[markdown]-.loop-.-&gt;input\n    html ---&gt; input; css ---&gt; input; javascript ---&gt; input\n    julia ---&gt; magics; r---&gt; magics; fortran ---&gt; magics; magics ---&gt; IPython\n{% endset %}\n```mermaid\nflowchart LR\n{% for i, line in enumerate(repl.splitlines()) %}\n{% if i &gt; extra.value %}%%{% endif %}{{line}}\n{% endfor %}\n```\n&lt;figcaption&gt;mermaid graph syntax uses extended markdown syntax provided by &lt;code&gt;jupyterlab-markup&lt;/code&gt;&lt;/figcaption&gt;\n&lt;/figure&gt;\n\n        display(extra := IntSlider(6, min=1, max=6, description=\"show more languages\")) # 6 lines in the graph\n\n`pidgy` is interested in exploring the interfaces of languages in computational essays. each language provides extra syntax for telling your story. with markdown we can include html, css, and javascript; code blocks can include more languages like mermaid. [IPython is our polyglot glue language][polyglot notebook]. \n\n[literate computing]: #\n[polyglot notebook]: https://gist.github.com/fperez/5b49246af4e340c37549265a90894ce6 \"fperez's polyglot juypyter demo\"\n\n[fperez lc]: https://web.archive.org/web/20220510083647/http://blog.fperez.org/2013/04/literate-computing-and-computational.html\n</code></pre>   the REPL overlayed with a [literate computing] workflow of tangle and weave.   <pre><code>flowchart LR\n\n\n\n    input[markdown]--tangle\\nread--&gt;IPython\n\n    IPython--eval/template--&gt;jinja\n\n    jinja--weave\\nprint--&gt;output[markdown]\n\n    output[markdown]-.loop-.-&gt;input\n\n    html ---&gt; input; css ---&gt; input; javascript ---&gt; input\n\n    julia ---&gt; magics; r---&gt; magics; fortran ---&gt; magics; magics ---&gt; IPython\n</code></pre> mermaid graph syntax uses extended markdown syntax provided by <code>jupyterlab-markup</code> <pre><code>    display(extra := IntSlider(6, min=1, max=6, description=\"show more languages\")) # 6 lines in the graph\n</code></pre> <p><code>pidgy</code> is interested in exploring the interfaces of languages in computational essays. each language provides extra syntax for telling your story. with markdown we can include html, css, and javascript; code blocks can include more languages like mermaid. IPython is our polyglot glue language. </p>"},{"location":"xxiii/2023-02-28-community-demo.html#inspecting-and-doing-more-with-a-keypress","title":"inspecting and doing more with a keypress","text":"<p>Ctrl + I open inspector \u26d4<code>jupyterlab-deck</code></p>"},{"location":"xxiii/2023-02-28-community-demo.html#translating-markdown-to-python","title":"translating markdown to python","text":"<p>the <code>%%tangle</code> magic tangles markdown to python code for previewing and debugging. this magic will help you learn <code>pidgy</code>s indenting heuristics and language features provided by <code>midgy</code>.</p> <pre><code>%%tangle\nwe use the `%%tangle` magic interactively translate the document into code.\n\nsome `pidgy` features are shown below like:\n\n* markdown docstrings\n\n        def my_function():\nfunctions with markdown docstrings\n\n            ...\n        ...\n\n* defining blocks of markdown as variables\n\n        my_url =\\\nhttps://api.github.com\n</code></pre> <pre>\"\"\"we use the `%%tangle` magic interactively translate the document into code.\n\nsome `pidgy` features are shown below like:\n* markdown docstrings\"\"\"\n\ndef my_function():\n\"\"\"functions with markdown docstrings\"\"\"\n\n    ...\n...\n\"\"\"* defining blocks of markdown as variables\"\"\"\n\nmy_url =\\\n\"\"\"https://api.github.com\"\"\";\n</pre>"},{"location":"xxiii/2023-02-28-community-demo.html#an-homage-knuths-literate-programming-language","title":"an homage knuth's literate programming language","text":"<pre><code>&lt;figure&gt;\n&lt;figcaption&gt;\n\na mermaid homage to the dual usage of the WEB file format being translated to a document and programming language.\n\n&lt;/figcaption&gt; \n\n```mermaid\nflowchart LR\n    WEB--WEAVE--&gt;TEX--TeX--&gt;DVI\n    WEB--TANGLE--&gt;PAS--PASCAL--&gt;REL\n```\n&lt;/figure&gt;\n\n&lt;figure markdown&gt;\n&lt;figcaption&gt;knuth's rational for choosing Pascal; the same motivation applies to python.&lt;/figcaption&gt;\n\n&gt; I chose PASCAL as the programming language because it has\nreceived such widespread support from educational  in-\nstitutions all over the world; it is not my favorite language for system programming, but it has become a\n\"second language\" for so many programmers that it\nprovides an exceptionally effective medium of communication.\n&lt;/figure&gt;\n</code></pre>   a mermaid homage to the dual usage of the WEB file format being translated to a document and programming language.   <pre><code>flowchart LR\n    WEB--WEAVE--&gt;TEX--TeX--&gt;DVI\n    WEB--TANGLE--&gt;PAS--PASCAL--&gt;REL</code></pre> knuth's rational for choosing Pascal; the same motivation applies to python. <p>I chose PASCAL as the programming language because it has received such widespread support from educational  in- stitutions all over the world; it is not my favorite language for system programming, but it has become a \"second language\" for so many programmers that it provides an exceptionally effective medium of communication.</p> <pre><code>## reactive `jinja2` templates\n\n&lt;label for=\"deck\"&gt;open&lt;/label&gt;\n&lt;button id=\"deck\" data-commandlinker-command=\"deck:toggle\"&gt;&lt;code&gt;jupyterlab-deck&lt;/code&gt;&lt;/button&gt;\n\n`pidgy` relies on a `midgy` to tangle markdown to code, it does not doing any work on displaying the input markdown. including the templating language is the innovation of `pidgy` that inlines live computation.\n\n\n`pidgy` templates are asynchronous reactive display objects that place live computation directly into the narrative.\n</code></pre>"},{"location":"xxiii/2023-02-28-community-demo.html#reactive-jinja2-templates","title":"reactive <code>jinja2</code> templates","text":"<p>open <code>jupyterlab-deck</code></p> <p><code>pidgy</code> relies on a <code>midgy</code> to tangle markdown to code, it does not doing any work on displaying the input markdown. including the templating language is the innovation of <code>pidgy</code> that inlines live computation.</p> <p><code>pidgy</code> templates are asynchronous reactive display objects that place live computation directly into the narrative.</p> <pre><code>### worrydream's cookies demo[^inventing]\n\n&lt;!---![](https://media3.giphy.com/media/BsUORZkF3gBqg/giphy.gif \"cookie monster happy as fuck eating cookies\")---&gt;\n\n&lt;blockquote cite=\"https://worrydream.com/Tangle/\"&gt;\n\n[Tangle] is a JavaScript library for creating reactive documents. Your readers can interactively explore possibilities, play with parameters, and see the document update immediately. Tangle is super-simple and easy to learn.\n\n&lt;/blockquote&gt;\n\n&lt;figure&gt;\n&lt;figcaption&gt;\n\nthe source code for the first [TangleJs][tangle] demo\n\n&lt;/figcaption&gt;\n\n```html\nWhen you eat &lt;span data-var=\"cookies\" class=\"TKAdjustableNumber\"&gt; cookies&lt;/span&gt;,\nyou consume &lt;span data-var=\"calories\"&gt; calories&lt;/span&gt;. \n```\n\n```javascript\nvar tangle = new Tangle(document, {\n    initialize: function () { this.cookies = 3; },\n    update:     function () { this.calories = this.cookies * 50; }\n});\n\n```\n&lt;/figure&gt;\n\n[tangle]: http://worrydream.com/Tangle/\n[inventing on principle]: https://www.youtube.com/watch?v=PUv66718DII\n[^inventing]: many folks working on computational interfaces are inspired by Bret Victor's [inventing on principle]\n</code></pre>"},{"location":"xxiii/2023-02-28-community-demo.html#worrydreams-cookies-demo3","title":"worrydream's cookies demo3","text":"[Tangle] is a JavaScript library for creating reactive documents. Your readers can interactively explore possibilities, play with parameters, and see the document update immediately. Tangle is super-simple and easy to learn.     the source code for the first [TangleJs][tangle] demo   <pre><code>When you eat &lt;span data-var=\"cookies\" class=\"TKAdjustableNumber\"&gt; cookies&lt;/span&gt;,\nyou consume &lt;span data-var=\"calories\"&gt; calories&lt;/span&gt;. \n</code></pre> <pre><code>var tangle = new Tangle(document, {\ninitialize: function () { this.cookies = 3; },\nupdate:     function () { this.calories = this.cookies * 50; }\n});\n</code></pre> <pre><code>{% set calories = 50 %}&lt;!--- we can shield variables from the global scope --&gt;\nWhen you eat {{cookies.value}} cookies,\nyou consume {{cookies.value * calories}} calories. \n\n&lt;div hidden&gt;&lt;!--indented code is python--&gt;\n\n        display(cookies := IntSlider(3, description=\"\ud83c\udf6a\"))\n&lt;/div&gt;\n\n{{\"\ud83c\udf6a\" * cookies.value}}\n\n\n&lt;figure&gt;\n&lt;figcaption&gt;\n\n`pidgy` source code using html, markdown, jinja, and ipywidgets to create interactions\n\n&lt;/figcaption&gt;\n\n```markdown\n{% raw %}\n{% set calories = 50 %}&lt;!--- we can shield variables from the global scope --&gt;\nWhen you eat {{cookies.value}} cookies,\nyou consume {{cookies.value * calories}} calories. \n\n&lt;div hidden&gt;&lt;!--indented code is python--&gt;\n\n        display(cookies := IntSlider(3, description=\"\ud83c\udf6a\"))\n&lt;/div&gt;\n\n{{\"\ud83c\udf6a\" * cookies.value}}\n{% endraw %}\n```\n\n&lt;/figure&gt;\n</code></pre> <p>When you eat 3 cookies, you consume 150 calories. </p>           display(cookies := IntSlider(3, description=\"\ud83c\udf6a\"))  <p>\ud83c\udf6a\ud83c\udf6a\ud83c\udf6a</p>   `pidgy` source code using html, markdown, jinja, and ipywidgets to create interactions   <pre><code>{% set calories = 50 %}&lt;!--- we can shield variables from the global scope --&gt;\nWhen you eat {{cookies.value}} cookies,\nyou consume {{cookies.value * calories}} calories. \n\n&lt;div hidden&gt;&lt;!--indented code is python--&gt;\n\n        display(cookies := IntSlider(3, description=\"\ud83c\udf6a\"))\n&lt;/div&gt;\n\n{{\"\ud83c\udf6a\" * cookies.value}}\n</code></pre> <pre><code>### live data in your document\n\n&lt;details markdown&gt;\n&lt;summary&gt;imports for the pandas matplotlib demo&lt;/summary&gt;\n\n    import pandas\n    from pidgy import get_cell_id\n    %matplotlib agg\n\n&lt;/details&gt;\n\n&lt;details markdown open&gt;\n&lt;summary&gt;supporting methods for the interactive demo&lt;/summary&gt;`\n\n    @functools.lru_cache\n    def get_gist(x, max=100):\n[gather gist from the github api][gist].\n\n        return pandas.read_json(F\"https://api.github.com/users/{x}/gists?per_page={max}\")\n\n[gist]: https://docs.github.com/en/rest/gists?apiVersion=2022-11-28\n\n    def tidy_gist(x):\nexplode the gist repsonse into a dataframe of gist files\n\n        gists = get_gist(x).set_index(\"id\")\n        return gists.files.apply(compose_left(dict.values, list)).explode().apply(pandas.Series).join(gists)\n\n&lt;/details&gt;\n</code></pre>"},{"location":"xxiii/2023-02-28-community-demo.html#live-data-in-your-document","title":"live data in your document","text":"imports for the pandas matplotlib demo <pre><code>import pandas\nfrom pidgy import get_cell_id\n%matplotlib agg\n</code></pre> supporting methods for the interactive demo <p>`</p> <pre><code>@functools.lru_cache\ndef get_gist(x, max=100):\n</code></pre> <p>gather gist from the github api.</p> <pre><code>    return pandas.read_json(F\"https://api.github.com/users/{x}/gists?per_page={max}\")\n\ndef tidy_gist(x):\n</code></pre> <p>explode the gist repsonse into a dataframe of gist files</p> <pre><code>    gists = get_gist(x).set_index(\"id\")\n    return gists.files.apply(compose_left(dict.values, list)).explode().apply(pandas.Series).join(gists)\n</code></pre> <pre><code>#### an application in a cell.\n\n{% set gists = tidy_gist(_github_user.value) %}\n{% set lang = gists.language.dropna().value_counts() %}\n\nwe've found information on {{gists.index.unique().shape[0]}} github gists, and {{len(gists)}} files, for @{{_github_user.value}}.\nin this collection, there are {{len(lang)}} different languages included. their most common language is {{lang.index[0]}}.\n\n{{gists.sample(2)}}\n\n    display(\n        _github_user := Text(\"tonyfast\"), button := Button(description=\"submit\"))\n    button.on_click(lambda x, id=get_cell_id(): print(id) or shell.weave.displays[id].update())\n{{lang.to_frame(\"ct\").T}}\n</code></pre>"},{"location":"xxiii/2023-02-28-community-demo.html#an-application-in-a-cell","title":"an application in a cell.","text":"<p>we've found information on 100 github gists, and 121 files, for @tonyfast. in this collection, there are 6 different languages included. their most common language is Jupyter Notebook.</p> filename type language raw_url size url forks_url commits_url node_id git_pull_url ... files public created_at updated_at description comments user comments_url owner truncated id 3181cb04cad6e16a2add26c646893db7 moi.ipynb text/plain Jupyter Notebook https://gist.githubusercontent.com/tonyfast/31... 4814 https://api.github.com/gists/3181cb04cad6e16a2... https://api.github.com/gists/3181cb04cad6e16a2... https://api.github.com/gists/3181cb04cad6e16a2... MDQ6R2lzdDMxODFjYjA0Y2FkNmUxNmEyYWRkMjZjNjQ2OD... https://gist.github.com/3181cb04cad6e16a2add26... ... {'moi.ipynb': {'filename': 'moi.ipynb', 'type'... True 2021-05-05 16:06:56+00:00 2021-05-05 16:07:29+00:00 0 NaN https://api.github.com/gists/3181cb04cad6e16a2... {'login': 'tonyfast', 'id': 4236275, 'node_id'... False 82e8b9744c139a63febb1a3280e91cec pluck-attachments.ipynb text/plain Jupyter Notebook https://gist.githubusercontent.com/tonyfast/82... 4843 https://api.github.com/gists/82e8b9744c139a63f... https://api.github.com/gists/82e8b9744c139a63f... https://api.github.com/gists/82e8b9744c139a63f... MDQ6R2lzdDgyZThiOTc0NGMxMzlhNjNmZWJiMWEzMjgwZT... https://gist.github.com/82e8b9744c139a63febb1a... ... {'collection-ouputs.ipynb': {'filename': 'coll... True 2021-07-02 17:01:42+00:00 2021-07-05 17:52:46+00:00 0 NaN https://api.github.com/gists/82e8b9744c139a63f... {'login': 'tonyfast', 'id': 4236275, 'node_id'... False <p>2 rows \u00d7 22 columns</p> <pre><code>display(\n    _github_user := Text(\"tonyfast\"), button := Button(description=\"submit\"))\nbutton.on_click(lambda x, id=get_cell_id(): print(id) or shell.weave.displays[id].update())\n</code></pre> language Jupyter Notebook Python Text Markdown HTML JSON ct 84 15 9 8 2 1 <pre><code>### et `voila`\n\n{% if LITE %}\n&gt; \ud83d\ude1e unforntunately, this part of the demo is not available on jupyter lite.\n{% endif %}\n\n&lt;button data-commandlinker-command=\"notebook:render-with-voila\" {% if  LITE %}disabled{% endif %}&gt;et &lt;code&gt;voila&lt;/code&gt;&lt;/button&gt;\n</code></pre>"},{"location":"xxiii/2023-02-28-community-demo.html#et-voila","title":"et <code>voila</code>","text":"<p>et <code>voila</code></p> <pre><code>## wrap up\n\n* this presentation had a number of incidental demos.\n    * jupyterlab-deck\n    * jupyterlab-markup\n    * voila\n    * mermaid\n    * midgy\n\n\n* we have on and off cells now that all of the sources are markdown \n* the template syntax is a powerful way to include python variables inline. the traditional notebook format only allows for block level literate programs.\n* since literate programs are pidgin languages we can't expect them to be formalized. there are a lot of inconsistencies with the languages combined.\njinja2 template implementations vary. markdown renderers implementation vary. python keeps adding language features. \n\n{% set sz = 3 %}\n{% set h = 60 %}\n&lt;form style=\"font-size: {{sz}}rem; line-height: {{h}}%;\"&gt;\n&lt;label for=\"rara\"&gt;\ud83c\udf97\ud83c\udf97\ud83c\udf97\ud83c\udf97\ud83c\udf97\ud83c\udf97\ud83c\udf97\ud83c\udf97&lt;/label&gt;&lt;br/&gt;&lt;button id=\"rara\" data-commandlinker-command=\"runmenu:restart-and-run-all\" style=\"font-size: {{sz}}rem; line-height: {{h}}%;\"&gt;restart and run all&lt;/button&gt;&lt;br/&gt;&lt;label for=\"rara\"&gt;or it didn't happen&lt;/label&gt;\n&lt;/form&gt;\n</code></pre>"},{"location":"xxiii/2023-02-28-community-demo.html#wrap-up","title":"wrap up","text":"<ul> <li> <p>this presentation had a number of incidental demos.</p> <ul> <li>jupyterlab-deck</li> <li>jupyterlab-markup</li> <li>voila</li> <li>mermaid</li> <li>midgy</li> </ul> </li> <li> <p>we have on and off cells now that all of the sources are markdown </p> </li> <li>the template syntax is a powerful way to include python variables inline. the traditional notebook format only allows for block level literate programs.</li> <li>since literate programs are pidgin languages we can't expect them to be formalized. there are a lot of inconsistencies with the languages combined. jinja2 template implementations vary. markdown renderers implementation vary. python keeps adding language features. </li> </ul> \ud83c\udf97\ud83c\udf97\ud83c\udf97\ud83c\udf97\ud83c\udf97\ud83c\udf97\ud83c\udf97\ud83c\udf97restart and run allor it didn't happen <p>https://monoskop.org/images/b/be/Nelson_Ted_Literary_Machines_c1987_chs_0-1.pdf https://pure.au.dk/ws/files/173226224/PPIG_2019_camera_ready.pdf</p> <ol> <li> <p>there is massive adoption of markdown as a tool for programmers. folks can use markdown and jekyll templating languages on github pages. github profiles are written in markdown. markdown is a gateway drug to html, javascript, and css.\u00a0\u21a9</p> </li> <li> <p>jupyter community calls are a monthly series of events to showcase what you are doing in and with jupyter. please consider submitting to or hosting a future community call sometime\u00a0\u21a9</p> </li> <li> <p>many folks working on computational interfaces are inspired by Bret Victor's inventing on principle \u21a9</p> </li> </ol>"},{"location":"xxiii/2023-03-04-computational-notebooks-history.html","title":"a sprint through history toward computional notebooks","text":"<p>history helps us understand science and software. in this presentation, we see how Project Jupyter and computational notebooks interfaces fit into their larger context of computing history. </p> <p>we'll begin with user interfaces at the dawn of post modernity then trawl through the early-web, then we'll run smack into the modern web, and finally landing in inaccessible pandemic hellscape that manufactures disability.</p> \ud83c\udfc3run all \ud83d\uddb9document mode \ud83d\udcfdpresentation mode \u229fcollapse all the code \u229eexpand all the code <code>jupyterlab-deck</code> <code>voila</code> \ud83d\udd0dinspector \ud83d\udc6fside-by-side <p>restart and run allor it didn't happen</p> <pre><code>    if __import__(\"sys\").platform == \"emscripten\":\n        %pip install pidgy\n    %reload_ext pidgy\n</code></pre>        if __import__(\"sys\").platform == \"emscripten\":         %pip install pidgy     %reload_ext pidgy"},{"location":"xxiii/2023-03-04-computational-notebooks-history.html#computational-notebooks-and-the-award-winning-project-jupyter","title":"computational notebooks  and the \ud83c\udfc6 award winning Project Jupyter","text":"Free software, open standards, and web services for interactive computing across all programming languages. <p>A tagline from the official Project Jupyter home page indicating the values and reach of its technology.     </p> <p></p> <p>Jupyter is a critical software system for interactive computing that makes it possible read and write code in many languages. Most of we find Python and Markdown, but we are not limited to these languages.</p> <p>Follow me through the olds.</p> <pre><code>## Xerox Alto\n\n\n&lt;figure markdown&gt;\n&lt;figcaption markdown&gt;\n\n&lt;blockquote cite=\"https://en.wikipedia.org/wiki/Xerox_Alto\"&gt;\nThe Xerox Alto is a computer designed from its inception to support &lt;b&gt;an operating system based on a graphical user interface (GUI)&lt;/b&gt;, later using the desktop metaphor. The first machines were introduced on 1 March 1973, a decade before mass-market GUI machines became available. \n&lt;/blockquote&gt;\n\n![xero alto](https://upload.wikimedia.org/wikipedia/commons/thumb/5/5e/Xerox_Alto_mit_Rechner.JPG/480px-Xerox_Alto_mit_Rechner.JPG \"A Xerox Alto cabinet computer\")\n\n&lt;/figcaption&gt;\n\n&lt;/figure&gt;\n\n\n[alto]: https://en.wikipedia.org/wiki/Xerox_Alto\n</code></pre>"},{"location":"xxiii/2023-03-04-computational-notebooks-history.html#xerox-alto","title":"Xerox Alto","text":"The Xerox Alto is a computer designed from its inception to support an operating system based on a graphical user interface (GUI), later using the desktop metaphor. The first machines were introduced on 1 March 1973, a decade before mass-market GUI machines became available."},{"location":"xxiii/2023-03-04-computational-notebooks-history.html#the-computer-mouse-and-interactive-computing","title":"The computer mouse and interactive computing","text":"<p>at the dawn of post modernity, Doug Engelbart's X-Y Position Indicator for a Display System changed the way we interact with computers.</p> <p></p> <pre><code>## the [mother of all demos]\n\n\n&lt;figure markdown&gt;\n&lt;figcaption markdown&gt;\n\nDoug Englebart's [Mother of all Demos] presentation that changed computing forever.\n&lt;/figcaption&gt;\n\n&lt;iframe width=\"629\" height=\"472\" src=\"https://www.youtube.com/embed/yJDv-zdhzMY\" title=\"The Mother of All Demos, presented by Douglas Engelbart (1968)\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;\n\n&lt;/figure&gt;\n\n&gt; The live demonstration featured the introduction of a complete computer hardware and software system called\nthe oN-Line System or, more commonly, NLS. The 90-minute presentation demonstrated for the first time \nmany of the fundamental elements of modern personal computing: &lt;b&gt;windows, hypertext, graphics, efficient navigation and command input, video conferencing, the computer mouse, word processing, dynamic file linking, revision control, and a collaborative real-time editor.&lt;/b&gt; Engelbart's presentation was the first to publicly demonstrate all of these elements in a single system. The demonstration was highly influential and spawned similar projects at Xerox PARC in the early 1970s. The underlying concepts and technologies influenced both the Apple Macintosh and Microsoft Windows graphical user interface operating systems in the 1980s and 1990s. \n\n[mother of all demos]: https://en.wikipedia.org/wiki/The_Mother_of_All_Demos \"the wiki page for the mother of all demos\"\n[moad transcript]: https://github.com/atduskgreg/MoAD-Transcript \"a repository hosting the mother of all demos transcripts\"\n</code></pre>"},{"location":"xxiii/2023-03-04-computational-notebooks-history.html#the-mother-of-all-demos","title":"the mother of all demos","text":"<p>Doug Englebart's Mother of all Demos presentation that changed computing forever.</p> <p>The live demonstration featured the introduction of a complete computer hardware and software system called the oN-Line System or, more commonly, NLS. The 90-minute presentation demonstrated for the first time  many of the fundamental elements of modern personal computing: windows, hypertext, graphics, efficient navigation and command input, video conferencing, the computer mouse, word processing, dynamic file linking, revision control, and a collaborative real-time editor. Engelbart's presentation was the first to publicly demonstrate all of these elements in a single system. The demonstration was highly influential and spawned similar projects at Xerox PARC in the early 1970s. The underlying concepts and technologies influenced both the Apple Macintosh and Microsoft Windows graphical user interface operating systems in the 1980s and 1990s. </p>"},{"location":"xxiii/2023-03-04-computational-notebooks-history.html#50-years-later-were-still-living-in-the-xerox-altos-world","title":"50 Years Later, We\u2019re Still Living in the Xerox Alto\u2019s World","text":"<p>the impact of the Xerox Alto still ripples through the world as we build shiners systems than the mother of all demos. the Alto was a glimpse into the future of personal computing.</p> <p></p> <pre><code>## Mathematica's computational essays\n\n&lt;figure markdown&gt; \n\n&lt;blockquote cite=\"https://www.theatlantic.com/science/archive/2018/04/the-scientific-paper-is-obsolete/556676/\" markdown&gt;\n\nThe notebook interface was the brainchild of Theodore Gray, who was inspired while working with an \nold Apple code editor. Where most programming environments either had you run code one line at a \ntime, or all at once as a big blob, the Apple editor let you highlight any part of your code and run\njust that part. Gray brought the same basic concept to Mathematica, with help refining the design\nfrom none other than Steve Jobs. __The notebook is designed to turn scientific programming into an \ninteractive exercise, where individual commands were tweaked and rerun, perhaps dozens or hundreds \nof times, as the author learned from the results of their little computational experiments, and \ncame to a more intimate understanding of their data.__\n\n&lt;/blockquote&gt;\n\n![mathematica version 2](https://winworldpc.com/res/img/screenshots/Mathematica%202.1%20-%20About.png \"a screenshot of mathematica version 2\")\n\n&lt;/figure&gt;\n</code></pre>"},{"location":"xxiii/2023-03-04-computational-notebooks-history.html#mathematicas-computational-essays","title":"Mathematica's computational essays","text":"<p>The notebook interface was the brainchild of Theodore Gray, who was inspired while working with an  old Apple code editor. Where most programming environments either had you run code one line at a  time, or all at once as a big blob, the Apple editor let you highlight any part of your code and run just that part. Gray brought the same basic concept to Mathematica, with help refining the design from none other than Steve Jobs. The notebook is designed to turn scientific programming into an  interactive exercise, where individual commands were tweaked and rerun, perhaps dozens or hundreds  of times, as the author learned from the results of their little computational experiments, and  came to a more intimate understanding of their data.</p> <p></p>"},{"location":"xxiii/2023-03-04-computational-notebooks-history.html#computer-programning-for-everybody","title":"computer programning for everybody","text":"<p>cp4e is the darpa proposal that contributed to early python development.</p> <p>it begins ...</p> <p>In the seventies, Xerox PARC asked: \"Can we have a computer on every desk?\" We now know this is possible, but those computers haven't necessarily empowered their users. Today's computers are often inflexible: the average computer user can typically only change a limited set of options configurable via a \"wizard\" (a lofty word for a canned dialog), and is dependent on expert programmers for everything else.</p> <p>and continues ...</p> <p>We compare mass ability to read and write software with mass literacy, and predict equally pervasive changes to society. Hardware is now sufficiently fast and cheap to make mass computer education possible: the next big change will happen when most computer users have the knowledge and power to create and modify software. </p>"},{"location":"xxiii/2023-03-04-computational-notebooks-history.html#interactive-python","title":"Interactive Python","text":"<p>IPython grew to have a lot of features in a monolith</p> <ul> <li>an interactive shell</li> <li>a REPL protocol</li> <li>a notebook document fromat</li> <li>a notebook document conversion tool</li> <li>a web-based notebook authoring tool</li> <li>tools for building interactive UI (widgets)</li> <li>interactive parallel Python based on the above REPL protocol    </li> </ul>"},{"location":"xxiii/2023-03-04-computational-notebooks-history.html#2015-project-jupyter-the-big-split","title":"2015 Project Jupyter The Big Split","text":"<p>Jupyter is like IPython, but language agnostic</p> <pre><code>&lt;abbr title=\"julia\"&gt;Ju&lt;/abbr&gt;\n&lt;abbr title=\"python\"&gt;py&lt;/abbr&gt;\n                   te\n&lt;abbr title=\"R\"&gt;r&lt;/abbr&gt;\n</code></pre> <p>jupyter enables polyglot programming in many languages at the same time.</p> <pre><code>## 2017 ACM Software System Award\n\n&lt;figure markdown&gt;\n&lt;figcaption&gt;\njupyter is recognized as a critical systems software.\n\n&lt;/figcaption&gt;\n&lt;blockquote cite=\"https://awards.acm.org/software-system\"&gt;\n\nJupyter has also gained wide industry adoption. Since 2015, Jupyter-based products have been released by several companies including Google (Cloud DataLab), Microsoft (AzureML, HDInsight), Intel (Trusted Analytics Platform), and IBM (IBM Watson Studio). Bloomberg and Anaconda Inc. have partnered with Project Jupyter to develop the next-generation web interface, JupyterLab.\n\n&lt;/blockquote&gt;\n&lt;/figure&gt;\n\n\n&lt;blockquote cite=\"https://blog.jupyter.org/jupyter-receives-the-acm-software-system-award-d433b0dfe3a2\"&gt;\n\nSimilarly, there exist multiple client applications in addition to the Jupyter Notebook and JupyterLab to create and execute notebooks, each with its own use case and focus: the open source nteract project develops a lightweight desktop application to run notebooks; CoCalc, a startup founded by William Stein, the creator of SageMath, offers a web-based client with real-time collaboration that includes Jupyter alongside SageMath, LaTeX, and tools focused on education; and Google now provides Colaboratory, another web notebook frontend that runs alongside the rest of the Google Documents suite, with execution in the Google Cloud.\n\n&lt;/blockquote&gt;\n</code></pre>"},{"location":"xxiii/2023-03-04-computational-notebooks-history.html#2017-acm-software-system-award","title":"2017 ACM Software System Award","text":"jupyter is recognized as a critical systems software.     Jupyter has also gained wide industry adoption. Since 2015, Jupyter-based products have been released by several companies including Google (Cloud DataLab), Microsoft (AzureML, HDInsight), Intel (Trusted Analytics Platform), and IBM (IBM Watson Studio). Bloomberg and Anaconda Inc. have partnered with Project Jupyter to develop the next-generation web interface, JupyterLab.     Similarly, there exist multiple client applications in addition to the Jupyter Notebook and JupyterLab to create and execute notebooks, each with its own use case and focus: the open source nteract project develops a lightweight desktop application to run notebooks; CoCalc, a startup founded by William Stein, the creator of SageMath, offers a web-based client with real-time collaboration that includes Jupyter alongside SageMath, LaTeX, and tools focused on education; and Google now provides Colaboratory, another web notebook frontend that runs alongside the rest of the Google Documents suite, with execution in the Google Cloud.   <pre><code>## jupyter is in good company\n\n&lt;figure markdown&gt;\n&lt;figcaption markdown&gt;\n\nProject Jupyter wins the 2017 ACM Software System Award, sharing a similar prestige as the Xerox Alto 30 years later.\n&lt;/figcaption&gt;\n\n\n&lt;iframe src=\"https://en.m.wikipedia.org/wiki/ACM_Software_System_Award#Recipients\" height=\"600\" width=\"100%\"&gt;&lt;/iframe&gt;\n&lt;/figure&gt;\n</code></pre>"},{"location":"xxiii/2023-03-04-computational-notebooks-history.html#jupyter-is-in-good-company","title":"jupyter is in good company","text":"<p>Project Jupyter wins the 2017 ACM Software System Award, sharing a similar prestige as the Xerox Alto 30 years later.</p> <pre><code>### there many notebook implementations and user interfaces\n\n&lt;figure markdown&gt;\n&lt;figcaption markdown&gt;\n\nthe notebook is a style of interface, collections of input forms and outputs repeated to weave a narrative and tangle code. there are open source and closed source options, along with language specific and agnostic implementations.\n\n&lt;/figcaption&gt;\n&lt;iframe src=\"https://en.m.wikipedia.org/wiki/Notebook_interface#Free/open-source_notebooks\" height=\"600\" width=\"100%\"&gt;&lt;/iframe&gt;    \n&lt;/figure&gt;\n\nwith over [10 million notebooks][nbestimate], there are now large scale studies of notebook and literate computing interfaces:\n\n* [Design and Use of Computational Notebooks](https://adamrule.com/files/dissertation/rule_dissertation.pdf)\n* [Mapping the Landscape of Literate Computing](https://pure.au.dk/ws/files/173226224/PPIG_2019_camera_ready.pdf)\n* [The Story in the Notebook: Exploratory Data Science using a Literate Programming Tool](https://marybethkery.com/projects/Verdant/Kery-The-Story-in-the-Notebook-Exploratory-Data-Science-using-a-Literate-Programming-Tool.pdf)\n\n[nbestimate]: https://github.com/parente/nbestimate/blob/master/estimate.ipynb \"a github project that estimates the number of notebooks on github\"\n</code></pre>"},{"location":"xxiii/2023-03-04-computational-notebooks-history.html#there-many-notebook-implementations-and-user-interfaces","title":"there many notebook implementations and user interfaces","text":"<p>the notebook is a style of interface, collections of input forms and outputs repeated to weave a narrative and tangle code. there are open source and closed source options, along with language specific and agnostic implementations.</p> <p>with over 10 million notebooks, there are now large scale studies of notebook and literate computing interfaces:</p> <ul> <li>Design and Use of Computational Notebooks</li> <li>Mapping the Landscape of Literate Computing</li> <li>The Story in the Notebook: Exploratory Data Science using a Literate Programming Tool</li> </ul> <pre><code>## notebooks and cells are increasingly more common forms\n\n&lt;figure markdown&gt; \n&lt;figcaption&gt;Observable's description of notebooks and cells.&lt;/figcaption&gt;\n\n&lt;blockquote cite=\"https://observablehq.com/@observablehq/notebooks-cells\"&gt;\nObservable is a platform for exploring data and code, visually, live in your browser. And &lt;b&gt;the central component of that platform is what we call a \"notebook\": an interactive, editable document defined by chunks of code called \"cells\".&lt;/b&gt; Observable notebooks help you explore live data, prototype visualizations, make interactive art, understand algorithms, collaborate on reports, and much more. Join Anjana Vakil, Observable Developer Advocate, in diving into Observable and understanding the basic mechanics of working with notebooks &amp; cells. \n&lt;/blockquote&gt;\n&lt;/figure&gt;\n\n&lt;iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/M1xMRkb89oM\" title=\"Observable: Notebooks &amp;amp; Cells\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"xxiii/2023-03-04-computational-notebooks-history.html#notebooks-and-cells-are-increasingly-more-common-forms","title":"notebooks and cells are increasingly more common forms","text":"Observable's description of notebooks and cells.  Observable is a platform for exploring data and code, visually, live in your browser. And the central component of that platform is what we call a \"notebook\": an interactive, editable document defined by chunks of code called \"cells\". Observable notebooks help you explore live data, prototype visualizations, make interactive art, understand algorithms, collaborate on reports, and much more. Join Anjana Vakil, Observable Developer Advocate, in diving into Observable and understanding the basic mechanics of working with notebooks &amp; cells.   <pre><code>## &lt;abbr title=\"web content accessibility guidelines\"&gt;WCAG&lt;/abbr&gt;: we circumvented accessibility guidelines\n\n&lt;blockquote cite=\"https://en.wikipedia.org/wiki/Web_Content_Accessibility_Guidelines\"&gt;\n\nThe **Web Content Accessibility Guidelines (WCAG)** are part of a series of web accessibility guidelines published by the Web Accessibility Initiative (WAI) of the World Wide Web Consortium (W3C), the main international standards organization for the Internet. They are a set of recommendations for making Web content more accessible, primarily for people with disabilities\u2014but also for all user agents, including highly limited devices, such as mobile phones.\n&lt;/blockquote&gt;\n\n&lt;blockquote cite=\"https://www.boia.org/blog/history-of-the-web-content-accessibility-guidelines-wcag\" markdown&gt;\n\n### wcag drafts\n\n* May 5, 1999: WCAG 1.0 is born. It included 14 guidelines, ranging from the need to provide text equivalents to considering clarity and simplicity on the web. Each guideline had between one and 10 supporting checkpoints.\n* December 11, 2008: WCAG 2.0 broadens scope and offers the four principles. The early 2000s were years of unbelievable changes in technology, so WCAG evolved to keep up. WCAG 2.0 was an incredible follow-up to its predecessor and was intended to be applied to almost all things digital (including documents and apps). WCAG 2.0 also introduced the four guiding principles of accessibility, stating content must be perceivable, operable, understandable, and robust, supported by success criteria for meeting those principles. WCAG 2.0 reigned as the gold standard for a long time.\n* June 5, 2018: WCAG 2.1 builds on but does not replace WCAG 2.0. The latest version of WCAG is backwards-compatible with the previous, which means if you comply with WCAG 2.1, you automatically comply with WCAG 2.0 \u2014 great news for website and app creators. WCAG 2.1 came as a highly-welcomed update, after the decade-old WCAG 2.0 could no longer completely account for advancements in technology and web use. The new WCAG 2.1 standards include several success criteria for improving web accessibility on mobile devices, as well as for people with low vision and cognitive disabilities.\n\n&lt;/blockquote&gt;\n</code></pre>"},{"location":"xxiii/2023-03-04-computational-notebooks-history.html#wcag-we-circumvented-accessibility-guidelines","title":"WCAG: we circumvented accessibility guidelines","text":"The **Web Content Accessibility Guidelines (WCAG)** are part of a series of web accessibility guidelines published by the Web Accessibility Initiative (WAI) of the World Wide Web Consortium (W3C), the main international standards organization for the Internet. They are a set of recommendations for making Web content more accessible, primarily for people with disabilities\u2014but also for all user agents, including highly limited devices, such as mobile phones."},{"location":"xxiii/2023-03-04-computational-notebooks-history.html#wcag-drafts","title":"wcag drafts","text":"<ul> <li>May 5, 1999: WCAG 1.0 is born. It included 14 guidelines, ranging from the need to provide text equivalents to considering clarity and simplicity on the web. Each guideline had between one and 10 supporting checkpoints.</li> <li>December 11, 2008: WCAG 2.0 broadens scope and offers the four principles. The early 2000s were years of unbelievable changes in technology, so WCAG evolved to keep up. WCAG 2.0 was an incredible follow-up to its predecessor and was intended to be applied to almost all things digital (including documents and apps). WCAG 2.0 also introduced the four guiding principles of accessibility, stating content must be perceivable, operable, understandable, and robust, supported by success criteria for meeting those principles. WCAG 2.0 reigned as the gold standard for a long time.</li> <li>June 5, 2018: WCAG 2.1 builds on but does not replace WCAG 2.0. The latest version of WCAG is backwards-compatible with the previous, which means if you comply with WCAG 2.1, you automatically comply with WCAG 2.0 \u2014 great news for website and app creators. WCAG 2.1 came as a highly-welcomed update, after the decade-old WCAG 2.0 could no longer completely account for advancements in technology and web use. The new WCAG 2.1 standards include several success criteria for improving web accessibility on mobile devices, as well as for people with low vision and cognitive disabilities.</li> </ul>"},{"location":"xxiii/2023-03-04-computational-notebooks-history.html#accessible-notebook-interfaces","title":"accessible notebook interfaces","text":"<p>recently, Jupyter developers were able to remove accessibility violations caught be axe. read the blog post. </p> <p></p> <pre><code>### automated testing\n\n&lt;figure markdown&gt;\n&lt;figcaption markdown&gt;\n\n[axe core][axe]'s is the open source industry standard for accessibility testing.\ncaveat emptor...\n&lt;/figcaption&gt;\n\n&gt; With [axe-core][axe], you can find **on average 57% of WCAG issues automatically**. Additionally, axe-core will return elements as \"incomplete\" where axe-core could not be certain, and manual review is needed.\n\n&lt;/figure&gt;\n\n\n[axe]: https://github.com/dequelabs/axe-core\n\n#### using axe\n\n* https://github.com/dequelabs/axe-core\n* [firefox axe extension]\n* [chrome axe extension]\n\n\n[firefox axe extension]: https://addons.mozilla.org/en-US/firefox/addon/axe-devtools/\n[chrome axe extension]: https://chrome.google.com/webstore/detail/axe-devtools-web-accessib/lhdoppojpmngadmnindnejefpokejbdd \n</code></pre>"},{"location":"xxiii/2023-03-04-computational-notebooks-history.html#automated-testing","title":"automated testing","text":"<p>axe core's is the open source industry standard for accessibility testing. caveat emptor...</p> <p>With axe-core, you can find on average 57% of WCAG issues automatically. Additionally, axe-core will return elements as \"incomplete\" where axe-core could not be certain, and manual review is needed.</p>"},{"location":"xxiii/2023-03-04-computational-notebooks-history.html#using-axe","title":"using axe","text":"<ul> <li>https://github.com/dequelabs/axe-core</li> <li>firefox axe extension</li> <li>chrome axe extension</li> </ul>"},{"location":"xxiii/2023-03-04-computational-notebooks-history.html#manual-testing","title":"manual testing","text":"<ul> <li>WCAG </li> <li>ACT rules</li> <li>WAI patterns</li> </ul> <p>nothing will replace the experiences of disabled people! \ud83d\ude4c jenn and isabela for making sure the testers got paid!</p> <p></p> <pre><code>## all hands on deck\n\nwe're responsible for accessible corridors and y'all are responsible accessible rooms.\njupyter can do a lot, which means you can do to. writing accessible notebooks means \nconsistenty adhering to standard patterns that will make information most usable by assist tech.\njupyter is only responsible the pixels it makes, less the ones your make.\n\n1. have fun learning how to write accessible notebooks\n1. explore the world of accessibility resources [^resources]\n1. listen to the experiences of disabled people\n1. abide standards\n1. join our [jupyter accessibility community meetings]\n\n[^resources]: \n    * https://www.technica11y.org/\n    * https://a11y.coffee/dig-in/\n    * https://www.a11yproject.com/\n\n[jupyter accessibility community meetings]: https://github.com/jupyter/accessibility/\n</code></pre>"},{"location":"xxiii/2023-03-04-computational-notebooks-history.html#all-hands-on-deck","title":"all hands on deck","text":"<p>we're responsible for accessible corridors and y'all are responsible accessible rooms. jupyter can do a lot, which means you can do to. writing accessible notebooks means  consistenty adhering to standard patterns that will make information most usable by assist tech. jupyter is only responsible the pixels it makes, less the ones your make.</p> <ol> <li>have fun learning how to write accessible notebooks</li> <li>explore the world of accessibility resources 1</li> <li>listen to the experiences of disabled people</li> <li>abide standards</li> <li>join our jupyter accessibility community meetings</li> </ol> <pre><code>&lt;style&gt;\narticle &gt; .highlight {\n    display: none;\n}\n&lt;/style&gt;\n</code></pre> <ol> <li> <ul> <li>https://www.technica11y.org/</li> <li>https://a11y.coffee/dig-in/</li> <li>https://www.a11yproject.com/</li> </ul> <p>\u21a9</p> </li> </ol>"},{"location":"xxiii/2023-03-18-pycascades-ally-talk.html","title":"A Crash Course in Digital Accessibility","text":"<p>this document is full of links for you to visit later, and learn at your own pace. this is a 5 minute link dump about my special interest. with a surprise demo!</p> <ul> <li>w3c accessibility standards</li> <li>accessibility auditing tools and practices</li> <li>language used in the accessibility circles</li> <li>how disability impacts us all.</li> </ul> <p></p> <p>original content developed for pycascades 2023 lightning talks</p> \ud83c\udfc3run all \ud83d\uddb9document mode \ud83d\udcfdpresentation mode \u229fcollapse all the code \u229eexpand all the code <code>jupyterlab-deck</code> <code>voila</code> \ud83d\udd0dinspector \ud83d\udc6fside-by-side <pre><code>    %reload_ext pidgy\n</code></pre>        %reload_ext pidgy   <pre><code>## WHO global disability stats\n\n&lt;blockquote markdown cite=\"https://www.who.int/news-room/fact-sheets/detail/disability-and-health\"&gt;\n\n* An estimated 1.3 billion people experience significant disability. This represents 16% of the world\u2019s population, or 1 in 6 of us.\n* Some persons with disabilities die up to 20 years earlier than those without disabilities.\n* Persons with disabilities have twice the risk of developing conditions such as depression, asthma, diabetes, stroke, obesity or poor oral health.\n* Persons with disabilities face many health inequities.\n* Persons with disabilities find inaccessible and unaffordable transportation 15 times more difficult than for those without disabilities.\n* Health inequities arise from unfair conditions faced by persons with disabilities, including stigma, discrimination, poverty, exclusion from education and employment, and barriers faced in the health system itself.\n\n&lt;/blockquote&gt;\n</code></pre>"},{"location":"xxiii/2023-03-18-pycascades-ally-talk.html#who-global-disability-stats","title":"WHO global disability stats","text":"<ul> <li>An estimated 1.3 billion people experience significant disability. This represents 16% of the world\u2019s population, or 1 in 6 of us.</li> <li>Some persons with disabilities die up to 20 years earlier than those without disabilities.</li> <li>Persons with disabilities have twice the risk of developing conditions such as depression, asthma, diabetes, stroke, obesity or poor oral health.</li> <li>Persons with disabilities face many health inequities.</li> <li>Persons with disabilities find inaccessible and unaffordable transportation 15 times more difficult than for those without disabilities.</li> <li>Health inequities arise from unfair conditions faced by persons with disabilities, including stigma, discrimination, poverty, exclusion from education and employment, and barriers faced in the health system itself.</li> </ul>"},{"location":"xxiii/2023-03-18-pycascades-ally-talk.html#forms-of-disability","title":"forms of disability","text":"<p>from microsoft inclusive design</p> <pre><code>### wcag __principles__ and _guidelines_\n\n&lt;figure markdown&gt;\n\n&lt;figcaption&gt;\n\n&lt;abbr title=\"percievable operable understandable robust\"&gt;POUR&lt;/abbr&gt; principles and guidelines for accessible applications\n\n&lt;/figcaption&gt;\n\n* Operable\n  * _Keyboard Accessible_\n  * _Enough Time_\n  * _Seizures_\n  * _Navigable_\n  * _Input Modalities_\n* Perceivable\n  * _Text Alternatives_\n  * _Time-based Media_\n  * _Adaptable_\n  * _Distinguishable_\n* Robust\n  * _Compatible_\n* Understandable\n  * _Readable_\n  * _Predictable_\n  * _Input Assistance_\n\n&lt;/figure&gt;\n</code></pre>"},{"location":"xxiii/2023-03-18-pycascades-ally-talk.html#wcag-principles-and-guidelines","title":"wcag principles and guidelines","text":"POUR principles and guidelines for accessible applications   <ul> <li>Operable</li> <li>Keyboard Accessible</li> <li>Enough Time</li> <li>Seizures</li> <li>Navigable</li> <li>Input Modalities</li> <li>Perceivable</li> <li>Text Alternatives</li> <li>Time-based Media</li> <li>Adaptable</li> <li>Distinguishable</li> <li>Robust</li> <li>Compatible</li> <li>Understandable</li> <li>Readable</li> <li>Predictable</li> <li>Input Assistance</li> </ul> <pre><code>### practical wuh-cag guidelines\n\n&lt;figure markdown&gt;\n&lt;figcaption&gt;\n\nsummarized guidelines on the [wcag wikipedia](https://en.wikipedia.org/wiki/Web_Content_Accessibility_Guidelines)\n\n&lt;/figcaption&gt;\n&lt;blockquote markdown cite=\"https://en.wikipedia.org/wiki/Web_Content_Accessibility_Guidelines\"&gt;\n\n* Guideline 1: Provide equivalent alternatives to auditory and visual content\n* Guideline 2: Don't rely on colour alone\n* Guideline 3: Use markup and style sheets, and do so properly\n* Guideline 4: Clarify natural language usage\n* Guideline 5: Create tables that transform gracefully\n* Guideline 6: Ensure that pages featuring new technologies transform gracefully\n* Guideline 7: Ensure user control of time sensitive content changes\n* Guideline 8: Ensure direct accessibility of embedded user interfaces\n* Guideline 9: Design for device independence\n* Guideline 10: User interim solutions\n* Guideline 11: Use W3C technologies and guidelines\n* Guideline 12: Provide context and orientation information\n* Guideline 13: Provide clear navigation mechanisms\n* Guideline 14: Ensure that documents are clear and simple\n\n&lt;/blockquote&gt;\n</code></pre>"},{"location":"xxiii/2023-03-18-pycascades-ally-talk.html#practical-wuh-cag-guidelines","title":"practical wuh-cag guidelines","text":"summarized guidelines on the [wcag wikipedia](https://en.wikipedia.org/wiki/Web_Content_Accessibility_Guidelines)   <ul> <li>Guideline 1: Provide equivalent alternatives to auditory and visual content</li> <li>Guideline 2: Don't rely on colour alone</li> <li>Guideline 3: Use markup and style sheets, and do so properly</li> <li>Guideline 4: Clarify natural language usage</li> <li>Guideline 5: Create tables that transform gracefully</li> <li>Guideline 6: Ensure that pages featuring new technologies transform gracefully</li> <li>Guideline 7: Ensure user control of time sensitive content changes</li> <li>Guideline 8: Ensure direct accessibility of embedded user interfaces</li> <li>Guideline 9: Design for device independence</li> <li>Guideline 10: User interim solutions</li> <li>Guideline 11: Use W3C technologies and guidelines</li> <li>Guideline 12: Provide context and orientation information</li> <li>Guideline 13: Provide clear navigation mechanisms</li> <li>Guideline 14: Ensure that documents are clear and simple</li> </ul> <pre><code>## alphabet soup of accessibility web standards\n\ndocumentation! web apps! reports! anything in the browser!\n\n* &lt;abbr title=\"web accessibility initiative\"&gt;WAI&lt;/abbr&gt; [web accessibility initiative](https://www.w3.org/WAI/)\n* &lt;abbr title=\"web content accessibility guidelines\"&gt;WCAG&lt;/abbr&gt; [web content accessibility guidelines](https://www.w3.org/WAI/standards-guidelines/)\n* &lt;abbr title=\"accessible rich internet applications\"&gt;ARIA&lt;/abbr&gt; [accessible rich internet applications](https://www.w3.org/WAI/standards-guidelines/aria/)\n\n  &gt; [no aria is better than bad aria.](https://www.w3.org/WAI/ARIA/apg/practices/read-me-first/)\n* &lt;abbr title=\"accessibility conformance testing\"&gt;ACT&lt;/abbr&gt; [accessibility conformance testing](https://www.w3.org/WAI/standards-guidelines/act/rules/)\n* &lt;abbr title=\"accessibility object model\"&gt;AOM&lt;/abbr&gt; [accessibility object model](https://wicg.github.io/aom/spec/)\n* \ud83c\udd95 [Cognitive Accessibility at W3C](https://www.w3.org/WAI/cognitive/)\n</code></pre>"},{"location":"xxiii/2023-03-18-pycascades-ally-talk.html#alphabet-soup-of-accessibility-web-standards","title":"alphabet soup of accessibility web standards","text":"<p>documentation! web apps! reports! anything in the browser!</p> <ul> <li>WAI web accessibility initiative</li> <li>WCAG web content accessibility guidelines</li> <li>ARIA accessible rich internet applications</li> </ul> <p>no aria is better than bad aria. * ACT accessibility conformance testing * AOM accessibility object model * \ud83c\udd95 Cognitive Accessibility at W3C</p> <pre><code>## auditting accessibility\n\nwhere applicable, build the accessibility floor by using these in ci.\n\n* \ud83d\udc4b [Deque Labs Axe](https://github.com/dequelabs/axe-core)\n* \ud83d\udc4b [IBM Equal Access](https://github.com/IBMa/equal-access/tree/master)\n* \ud83d\udc4b [WAVE accessibility evaluator](https://wave.webaim.org/extension/)\n* [Check the markup of web documentats](https://validator.w3.org/)\n</code></pre>"},{"location":"xxiii/2023-03-18-pycascades-ally-talk.html#auditting-accessibility","title":"auditting accessibility","text":"<p>where applicable, build the accessibility floor by using these in ci.</p> <ul> <li>\ud83d\udc4b Deque Labs Axe</li> <li>\ud83d\udc4b IBM Equal Access</li> <li>\ud83d\udc4b WAVE accessibility evaluator</li> <li>Check the markup of web documentats</li> </ul>"},{"location":"xxiii/2023-03-18-pycascades-ally-talk.html#accessible-notebook-interfaces","title":"accessible notebook interfaces","text":"<p>recently, Jupyter developers were able to remove accessibility violations caught be axe. read the blog post. </p> <p></p>"},{"location":"xxiii/2023-03-18-pycascades-ally-talk.html#manually-reviewing-accessibility","title":"manually reviewing accessibility","text":"<p>there are a lot of dimensions to digital accessibility. here are some things i thought worth noting.</p> <ul> <li>reviewing accessible design principles<ul> <li>Think about focus order</li> <li>Examine copy</li> <li>Pay attention to colors</li> <li>Look at page context and components</li> <li>Annotate the designs</li> </ul> </li> <li>The A11Y Project is an open source community about accessibility with tons of resources</li> </ul> <p></p> <ul> <li>no mouse days</li> <li>technica11y produces first hand accounts of disabled develops</li> <li> <p>community events</p> <ul> <li>collaborative alt text documentation events</li> </ul> <p></p> <ul> <li>keyboard navigation events</li> </ul> </li> <li> <p>meet your screen reader</p> </li> </ul>"},{"location":"xxiii/2023-03-18-pycascades-ally-talk.html#other-useful-sources-sources","title":"other useful sources sources","text":"<ul> <li>chartability</li> <li>wai patterns</li> <li>diagram center general guidelines</li> <li>Frameworks? Modern Health, frameworks, performance, and harm Modern Health, frameworks, performance, and harm </li> <li>Do No Harm Guide: Applying Equity Awareness in Data Visualization</li> <li>accessible pygments themes for code</li> </ul> <pre><code>## conclusion\n\n* diversity of thought and experience\n* [inclusive design](https://en.wikipedia.org/wiki/Inclusive_design) practices and accessible principles are beacons for design\n* include (and pay) disabled people - [nothing about us without us](https://en.wikipedia.org/wiki/Nothing_about_us_without_us)\n    * [Why Underemployment Plagues People With Disabilities Even In A Strong Economy](https://www.forbes.com/sites/denisebrodey/2019/10/26/why-underemployment-plagues-people-with-disabilities-even-in-a-strong-economy/?sh=44006eeb693d)\n</code></pre>"},{"location":"xxiii/2023-03-18-pycascades-ally-talk.html#conclusion","title":"conclusion","text":"<ul> <li>diversity of thought</li> <li>inclusive design practices and accessible principles are beacons for design</li> <li>include (and pay) disabled people - nothing about us without us<ul> <li>Why Underemployment Plagues People With Disabilities Even In A Strong Economy</li> </ul> </li> </ul>"},{"location":"xxiii/2023-03-18-pycascades-ally-talk.html#whats-the-deal-with-the-demo","title":"whats the deal with the demo??","text":"<ul> <li>running the browser with jupyterlite</li> </ul> <ul> <li> <p>programmined in markdown with pidgy [ ]pidgy</p> </li> <li> <p>presented with jupyterlab-deck</p> </li> </ul> <p></p>"},{"location":"xxiii/2023-06-21-v7-aom.html","title":"jupyter notebook v7 remediations","text":"<p>this document provides more structure to the annotation object model in the interactive jupyter notebook v7 experience. this effort is an extension of the notebooks for all effort to establish a minimum, semantic html5 footprint for a rendered notebook. the originial hypothesis still stands that an accessible reference implementation of the rendered notebook will extend to an assistive interactive experience. </p> <p>i think this remediation is 4 primary tasks - [ ] improved notebook level semantics for landmarks and initial APG recommendations - [ ] introduce feed semantics for the cells     - [ ] establish input group semantics     - [ ] establish preliminary group semantics</p> <p>our goal is presentation an assistive experience that can be extended with feedback from users. this will drastically improve the assistive tech experience through improvements to the annotation object model.</p> <p>Note: all labels will need to be internationalized.</p>"},{"location":"xxiii/2023-06-21-v7-aom.html#out-of-scope","title":"out of scope","text":"<p>this documents focus on non-visual changes that improve the quality of Annotation Objective Model so the following important topics are out of scope: </p> <ul> <li> the split panel handler has an APG Window Splitter Pattern that should be implemented.</li> <li> tab traps are bad for keyboard users. tab in cell mode should not enter edit mode automatically. the assistive experience hinges on https://github.com/jupyterlab/jupyterlab/pull/14115.</li> <li> modifying the native find experience without an escape hatch is super dangerous; so i'm real worried about <code>.jp-DocumentSearch-overlay</code>.</li> </ul> <p>click \"trust notebook\" in the File Menu to execute this code yourself.</p>"},{"location":"xxiii/2023-06-21-v7-aom.html#application-level-semantics","title":"application level semantics","text":"<p>ARIA modifications to the first landmarks we encounter.</p> <pre><code>    %%javascript\n    document.querySelectorAll(\"#top-panel\").forEach((x,i) =&gt;{x.setAttribute(\"aria-label\", \"Notebook Menu\");});\n    document.querySelectorAll(\"#main-panel\").forEach((x,i) =&gt;{x.setAttribute(\"aria-labelledby\", \"jp-title\");});\n    document.querySelectorAll(\"#menu-panel\").forEach((x,i) =&gt;{\n        x.setAttribute(\"role\", \"banner\"); \n        x.setAttribute(\"aria-label\", \"Notebook Menu\");\n    });\n</code></pre> <p>the application can't own the first <code>h1</code>. we've been suggesting notebooks begin with a markdown cell and <code>h1</code> as a best practice.</p> <pre><code>    %%javascript\n    for (x in document.querySelectorAll(\"#top-panel #jp-title h1\").children){\n        // we can't set our own h1 as that will mess up custom content.\n        // the css depends on the h1, but the screen reader won't find it this way.\n        x.setAttribute(\"role\", \"presentation\");\n    };\n</code></pre>"},{"location":"xxiii/2023-06-21-v7-aom.html#application-label-concerns","title":"application label concerns.","text":"<pre><code>    %%javascript\n    // a user should be able to trigger the logo dialog by clicking on .jp-NotebookKernelLogo\n    // the trusted status button needs alt and a clearer title .jp-NotebookTrustedStatus\n    // the button.jp-Notebook-footer semantics are wrong. the button should be inside a footer, or role=contentinfo\n</code></pre> <p>i'm surprised everytime the jupyter logo sends me to the file tree. right now, the first thing you tab to tries to send you to another page. feels weird.</p> <p>the changes below communicate the current semantics, but the feel of this experience should be reconsidered.</p> <pre><code>    %%javascript\n    // it is going to make no sense to anyone that the jupyter label sends you to open files\n    document.querySelectorAll(\"#top-panel #jp-NotebookLogo\").forEach((x,i) =&gt;{\n        x.setAttribute(\"title\", \"Open File Browser in a New Tab\");\n        x.setAttribute(\"alt\", \"Open File Browser in a New Tab\");\n    });\n</code></pre> <p>label the main notebook area.</p> <pre><code>    %%javascript\n    document.querySelectorAll(\"#spacer-widget-top\").forEach((x,i) =&gt;{x.setAttribute(\"role\", \"presentation\");});\n    document.querySelectorAll(\".jp-Notebook\").forEach((x,i) =&gt;{x.setAttribute(\"aria-label\", \"Notebook Cells\");});\n</code></pre> <p>the toolbar is banner, not navigation.</p> <pre><code>    %%javascript\n    // role navigation -&gt; banner, this is a landmark inside of main\n    document.querySelectorAll(\".jp-Toolbar\").forEach((x,i) =&gt;{\n        x.setAttribute(\"role\", \"banner\"); x.setAttribute(\"aria-label\", \"Notebook Actions\");\n    });    \n</code></pre>"},{"location":"xxiii/2023-06-21-v7-aom.html#the-notebook-feed-and-cell-articles","title":"the notebook feed and cell articles","text":"<p>the feed pattern is read mode pattern for identifying units of content is a potentially infinite scrolling element. we use this pattern because it introduces the minimal aria semantics to add order.</p> <pre><code>    %%javascript\n    document.querySelectorAll(\".jp-WindowedPanel-window\").forEach((x,i) =&gt;{\n        x.setAttribute(\"role\", \"feed\"); x.setAttribute(\"aria-label\", \"Cells\");\n    });\n</code></pre> <p>for each of the cells, we give them an article role. each cell is labelled by their name with information about the cell type.</p> <p>some assistive tech can quickly nagivate articles.</p> <pre><code>    %%javascript\n    var cells = document.querySelectorAll(\".jp-Cell\");\n    cells.forEach((x,i) =&gt;{\n        x.setAttribute(\"role\", \"article\"); \n        x.setAttribute(\"aria-posinset\", i+1); \n        x.setAttribute(\"aria-setsize\", cells.length); \n        var MD = x.className.includes(\"jp-MarkdownCell\");\n        var CODE = x.className.includes(\"jp-CodeCell\");\n        if (CODE){\n            x.setAttribute(\"aria-label\", `Code Cell ${i+1}`);\n        } else if (MD){\n            x.setAttribute(\"aria-label\", `Markdown Cell ${i+1}`);\n        } else {\n            x.setAttribute(\"aria-label\", `Cell ${i+1}`);\n        };\n\n        // i cant directly know the input number. semantically it is some kind of label.\n        // this effort is concerned with the AOM, not WCAG. \n        // we do have a visible label so this should satisfy the visible label\n        prompt = x.querySelectorAll(\".jp-InputPrompt\")[0];\n        prompt.setAttribute(\"aria-hidden\", \"true\");\n\n        // STILL NEED TO ADD A LANDMARK FOR THE CELL\n    });\n</code></pre>"},{"location":"xxiii/2023-06-21-v7-aom.html#input-area-fixes","title":"input area fixes","text":"<pre><code>    %%javascript\n    var cells = document.querySelectorAll(\".jp-Cell\");\n    cells.forEach((x,i) =&gt;{\n        var MD = x.className.includes(\"jp-MarkdownCell\");\n        var CODE = x.className.includes(\"jp-CodeCell\");\n\n        // code, markdown, raw cells need different groupings.\n        x.querySelectorAll(\".jp-Cell-inputWrapper\").forEach(\n            (y)=&gt;{\n                y.setAttribute(\"role\", \"group\");\n                var label = prompt.textContent.slice(1, -2).trim();\n                if (CODE){\n                    if (label.length){\n                        y.setAttribute(\"aria-label\", `In ${label}`);\n                    } else {\n                        y.setAttribute(\"aria-label\", `New Code Input`);\n                    }\n                } else if (MD){\n                    y.setAttribute(\"aria-label\", `Markdown Input`);\n                } else {\n                    y.setAttribute(\"aria-label\", `Input`);\n                }\n            }\n        );\n        // make the cell toolbar an APG styled toolbar. this is the most cursory modification.\n        x.querySelectorAll(\".jp-cell-toolbar\").forEach(\n            (y)=&gt;{\n                // https://www.w3.org/WAI/ARIA/apg/patterns/toolbar/examples/toolbar/\n                y.setAttribute(\"role\", \"toolbar\");\n                y.setAttribute(\"aria-label\", `Cell ${i+1} Toolbar`);\n                y.setAttribute(\"aria-controls\", `cell-input-${i}`);\n            }\n        )\n    });\n</code></pre>"},{"location":"xxiii/2023-06-21-v7-aom.html#output-area-fixes","title":"output area fixes","text":"<p>i am very not confident about the output semantics. my efforts were to understand the rendered cell's landmarks. the output semantics are pure presentation in reading mode, but editting mode is several HCI PhDs.</p> <p>right now, i'm only comfortable calling the outputs a group, this means they may be announced by a screen reader to provide some relative position. on disk, in the notebook format, outputs are a list of structures, as are cells, and it might make the most sense to employ a nested feed pattern. when you start to thinking about async updates then ordering is out the window.</p> <pre><code>    %%javascript\n    var cells = document.querySelectorAll(\".jp-Cell\");\n    cells.forEach((x,i) =&gt;{\n        x.querySelectorAll(\".jp-Cell-outputWrapper\").forEach(\n            (y)=&gt;{\n                // this will only be encountered on code cells.\n                // i have no invested significant time into the semantics of the outputs\n                // group is a fine semantic, but it is non specific.\n                // increasingly i feel like the output is nested feed because it \n                // would allow outputs to be indexed. need more testing.\n                y.setAttribute(\"role\", \"group\");\n                var label = prompt.textContent.slice(1, -2).trim();\n                if (label.length){\n                    y.setAttribute(\"aria-label\", `Output ${label}`);\n                } else {\n                    // no need to worry about the output label when there is not execution\n                    // aria hidden might be appropriate without testing on a screen reader.\n                };\n            }\n        );\n        x.querySelectorAll(\".jp-OutputCollapser\").forEach(\n            (y)=&gt;{\n                // the collapser button has no semantics or visible label.\n                // this feature is not accessible, but should because for folks using screen magnification.\n            }\n        )\n    });\n</code></pre>"},{"location":"xxiii/2023-06-21-v7-aom.html#conclusion","title":"conclusion","text":"<ul> <li>the output area is where the research stops. it is less though out than the others. announcements are part of the equation too for the proper assistive experience.</li> <li>there are significant follow up work to improve the whole experience.</li> </ul>"}]}
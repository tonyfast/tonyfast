{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a4e3ff4-63fb-4d2f-bee2-58fdeec8375f",
   "metadata": {},
   "source": [
    "# formatting markdown it tokens as python `doctests`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8f6891-aa67-4baf-8bd3-15d6841d1c50",
   "metadata": {},
   "source": [
    "`midgy` is a tool i've been crafting that translates markdown to valid python.\n",
    "this concept might sound perculiar from a programming perspective,\n",
    "but it was designed as a [literate programming] tool.\n",
    "\n",
    "to avoid feature creep, `midgy` tries to stick fairly close to the commonspec\n",
    "when tokenizing markdown. `midgy` adds a _doctest_ token to the parser.\n",
    "we make this addition because `doctest` is a _[literate programming]_\n",
    "considered in the core python language.\n",
    "\n",
    "in this document, we convert the `markdown_it` tokens into valid `doctest.DocTest` runners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec117ee0-dc94-4712-bce3-5e6c4353ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "    import midgy, doctest, unittest, typing\n",
    "    from textwrap import dedent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a254db-2c48-4830-9af3-f48b5c78f307",
   "metadata": {},
   "source": [
    "write some sample doctests to parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75838a6e-257b-404f-a1c7-e266d43e134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def a_testable_function():\n",
    "        \"\"\"\n",
    "        >>> range(1)\n",
    "        range(0, 1)\n",
    "        \n",
    "        >>> assert False\n",
    "        Traceback (most recent call last):\n",
    "        ...\n",
    "        AssertionError\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9226c90c-9399-4990-b20b-cb9924c095f3",
   "metadata": {},
   "source": [
    "verify that these tests pass. `doctest.testmod` runs `doctest` on the `__main__` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94e39d27-349d-489d-9d96-09a23b76b850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    doctest.testmod(optionflags=doctest.ELLIPSIS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a458059b-66c8-4bc1-ba69-3b6f12d7d7ce",
   "metadata": {},
   "source": [
    "make some `markdown_it` tokens from the doctests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f209901-896d-41c6-9253-4b405e465e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token(type='code_block', tag='code', nesting=0, attrs={}, map=[1, 3], level=0, children=None, content='    >>> range(1)\\n    range(0, 1)\\n', markup='', info='', meta={'first_indent': 4, 'last_indent': 4, 'min_indent': 4, 'is_magic': False, 'is_doctest': True, 'input': [1, 2], 'output': [2, 3]}, block=True, hidden=False),\n",
       " Token(type='code_block', tag='code', nesting=0, attrs={}, map=[4, 8], level=0, children=None, content='    >>> assert False\\n    Traceback (most recent call last):\\n    ...\\n    AssertionError\\n', markup='', info='', meta={'first_indent': 4, 'last_indent': 4, 'min_indent': 4, 'is_magic': False, 'is_doctest': True, 'input': [4, 5], 'output': [5, 8]}, block=True, hidden=False)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    (tokens := (parser := midgy.Python()).parse(a_testable_function.__doc__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43b0421-67b5-44f5-96b6-5f2974fb22a6",
   "metadata": {},
   "source": [
    "`get_example_from_token` translates a markdown token to a `doctest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "287d97ef-004e-444f-80ce-eaa3810e5bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_example_from_token(token) -> typing.Iterable[doctest.Example]:\n",
    "        m = doctest.DocTestParser._EXAMPLE_RE.match(token.content)\n",
    "        want = dedent(m.group(\"want\"))\n",
    "        exc = doctest.DocTestParser._EXCEPTION_RE.match(want)\n",
    "        source = \"\".join(x.lstrip()[4:] for x in m.group(\"source\").splitlines(1))\n",
    "        yield doctest.Example(\n",
    "            source=source, want=want, lineno=token.map[0],\n",
    "            exc_msg=exc.group(\"msg\") if exc else None, indent=len(m.group(\"indent\"))\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c462d899-ab1e-4315-b3c7-2095f37fce5e",
   "metadata": {},
   "source": [
    "`get_examples_from_tokens` aggregates the `doctest.Example`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee040771-f719-4de8-baa9-c7a144f2db26",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_examples_from_tokens(tokens) -> typing.Iterable[doctest.Example]:\n",
    "        for token in tokens:\n",
    "            if token.meta.get(\"is_doctest\"):\n",
    "                yield from get_example_from_token(token)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a21587-4d95-4674-b030-1eca173e10f3",
   "metadata": {},
   "source": [
    "finally we generate a `unittest.TestSuite`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74b65b4b-c497-4b93-a2e0-49bdeeee59f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_suite_from_tokens(tokens) -> unittest.TestSuite:\n",
    "        suite = unittest.TestSuite()            \n",
    "        for example in get_examples_from_tokens(tokens):\n",
    "            suite.addTest(doctest.DocTestCase(\n",
    "                doctest.DocTest([example], globals(), __name__, None, example.lineno, None),\n",
    "                optionflags=doctest.ELLIPSIS\n",
    "            ))\n",
    "        return suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b22769d2-5565-4b36-b54e-06ede8cd46ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def run_suite(suite=(suite:=get_suite_from_tokens(tokens))) -> unittest.TestResult:\n",
    "        suite.run(result:= unittest.TestResult())\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf6679c-f868-4c73-b32a-5570a0585912",
   "metadata": {},
   "source": [
    "run our generated `doctest` suite to verify that it doesn't fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a9889ac-92d3-4a81-904a-88c4310d7f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<unittest.result.TestResult run=2 errors=0 failures=0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    run_suite(suite)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
